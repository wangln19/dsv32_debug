INFO 11-04 09:31:46 [__init__.py:216] Automatically detected platform cuda.
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:32:14 [api_server.py:1839] vLLM API server version 0.11.0
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:32:14 [utils.py:233] non-default args: {'model_tag': '/dev/shm/DeepSeek-V3.2-Exp', 'model': '/dev/shm/DeepSeek-V3.2-Exp', 'max_model_len': 5000, 'enforce_eager': True, 'data_parallel_size': 16, 'data_parallel_size_local': 8, 'data_parallel_address': '10.64.27.139', 'data_parallel_rpc_port': 29550, 'enable_expert_parallel': True, 'gpu_memory_utilization': 0.95, 'swap_space': 32.0}
[1;36m(APIServer pid=178162)[0;0m You are using a model of type deepseek_v32 to instantiate a model of type deepseek_v3. This is not supported for all configurations of models and can yield errors.
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:32:14 [config.py:617] Detected quantization_config.scale_fmt=ue8m0; enabling Hopper UE8M0.
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:32:14 [config.py:388] Replacing legacy 'type' key with 'rope_type'
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:32:14 [model.py:547] Resolved architecture: DeepseekV32ForCausalLM
[1;36m(APIServer pid=178162)[0;0m `torch_dtype` is deprecated! Use `dtype` instead!
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:32:14 [model.py:1510] Using max model len 5000
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:32:18 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:32:18 [config.py:422] Using custom fp8 kv-cache format for DeepSeekV3.2
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:32:19 [__init__.py:381] Cudagraph is disabled under eager mode
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:32:19 [cuda.py:166] Forcing kv cache block size to 64 for FlashMLA backend.
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:32:19 [utils.py:651] Started DP Coordinator process (PID: 178298)
INFO 11-04 09:32:30 [__init__.py:216] Automatically detected platform cuda.
INFO 11-04 09:32:30 [__init__.py:216] Automatically detected platform cuda.
INFO 11-04 09:32:31 [__init__.py:216] Automatically detected platform cuda.
INFO 11-04 09:32:31 [__init__.py:216] Automatically detected platform cuda.
INFO 11-04 09:32:31 [__init__.py:216] Automatically detected platform cuda.
INFO 11-04 09:32:31 [__init__.py:216] Automatically detected platform cuda.
INFO 11-04 09:32:31 [__init__.py:216] Automatically detected platform cuda.
INFO 11-04 09:32:31 [__init__.py:216] Automatically detected platform cuda.
INFO 11-04 09:32:31 [__init__.py:216] Automatically detected platform cuda.
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:32:47 [core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:32:47 [core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:32:47 [core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:32:48 [core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:32:48 [core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:32:48 [core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:32:48 [core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:32:48 [core.py:644] Waiting for init message from front-end.
[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:33:03 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='/dev/shm/DeepSeek-V3.2-Exp', speculative_config=None, tokenizer='/dev/shm/DeepSeek-V3.2-Exp', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=16, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=fp8_ds_mla, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/dev/shm/DeepSeek-V3.2-Exp, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:33:03 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='/dev/shm/DeepSeek-V3.2-Exp', speculative_config=None, tokenizer='/dev/shm/DeepSeek-V3.2-Exp', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=16, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=fp8_ds_mla, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/dev/shm/DeepSeek-V3.2-Exp, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:33:03 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='/dev/shm/DeepSeek-V3.2-Exp', speculative_config=None, tokenizer='/dev/shm/DeepSeek-V3.2-Exp', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=16, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=fp8_ds_mla, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/dev/shm/DeepSeek-V3.2-Exp, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:33:03 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='/dev/shm/DeepSeek-V3.2-Exp', speculative_config=None, tokenizer='/dev/shm/DeepSeek-V3.2-Exp', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=16, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=fp8_ds_mla, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/dev/shm/DeepSeek-V3.2-Exp, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:33:03 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='/dev/shm/DeepSeek-V3.2-Exp', speculative_config=None, tokenizer='/dev/shm/DeepSeek-V3.2-Exp', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=16, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=fp8_ds_mla, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/dev/shm/DeepSeek-V3.2-Exp, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:33:03 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='/dev/shm/DeepSeek-V3.2-Exp', speculative_config=None, tokenizer='/dev/shm/DeepSeek-V3.2-Exp', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=16, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=fp8_ds_mla, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/dev/shm/DeepSeek-V3.2-Exp, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:33:03 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='/dev/shm/DeepSeek-V3.2-Exp', speculative_config=None, tokenizer='/dev/shm/DeepSeek-V3.2-Exp', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=16, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=fp8_ds_mla, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/dev/shm/DeepSeek-V3.2-Exp, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:33:03 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='/dev/shm/DeepSeek-V3.2-Exp', speculative_config=None, tokenizer='/dev/shm/DeepSeek-V3.2-Exp', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=5000, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=16, disable_custom_all_reduce=False, quantization=fp8, enforce_eager=True, kv_cache_dtype=fp8_ds_mla, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/dev/shm/DeepSeek-V3.2-Exp, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:33:10 [parallel_state.py:1047] Adjusting world_size=16 rank=5 distributed_init_method=tcp://10.64.27.139:35185 for DP
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:33:10 [parallel_state.py:1047] Adjusting world_size=16 rank=3 distributed_init_method=tcp://10.64.27.139:35185 for DP
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:33:10 [parallel_state.py:1047] Adjusting world_size=16 rank=1 distributed_init_method=tcp://10.64.27.139:35185 for DP
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:33:10 [parallel_state.py:1047] Adjusting world_size=16 rank=2 distributed_init_method=tcp://10.64.27.139:35185 for DP
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:33:10 [parallel_state.py:1047] Adjusting world_size=16 rank=4 distributed_init_method=tcp://10.64.27.139:35185 for DP
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:33:10 [parallel_state.py:1047] Adjusting world_size=16 rank=7 distributed_init_method=tcp://10.64.27.139:35185 for DP
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:33:10 [parallel_state.py:1047] Adjusting world_size=16 rank=6 distributed_init_method=tcp://10.64.27.139:35185 for DP
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:33:10 [parallel_state.py:1047] Adjusting world_size=16 rank=0 distributed_init_method=tcp://10.64.27.139:35185 for DP
[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0[Gloo] Rank 
0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0[Gloo] Rank  peer ranks. Expected number of connected peer ranks is : 0
0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:33:11 [__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:33:11 [pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:33:11 [__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:33:11 [__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:33:11 [__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:33:11 [pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:33:11 [pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:33:11 [pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:33:11 [__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:33:11 [__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:33:11 [__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:33:11 [__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:33:11 [pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:33:11 [pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:33:11 [pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:33:11 [pynccl.py:103] vLLM is using nccl==2.27.3
[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:33:18 [__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:33:18 [pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:33:18 [__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:33:18 [pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:33:18 [__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:33:18 [__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:33:18 [pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:33:18 [__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:33:18 [pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:33:18 [pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:33:18 [__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:33:18 [pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:33:18 [__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:33:18 [pynccl.py:103] vLLM is using nccl==2.27.3
[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:33:18 [__init__.py:1384] Found nccl from library libnccl.so.2
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:33:18 [pynccl.py:103] vLLM is using nccl==2.27.3
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:33:24 [cuda_communicator.py:100] Using AllGather-ReduceScatter all2all manager.
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:33:24 [cuda_communicator.py:100] Using AllGather-ReduceScatter all2all manager.
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:33:24 [cuda_communicator.py:100] Using AllGather-ReduceScatter all2all manager.
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:33:24 [cuda_communicator.py:100] Using AllGather-ReduceScatter all2all manager.
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:33:24 [cuda_communicator.py:100] Using AllGather-ReduceScatter all2all manager.
[1;36m(EngineCore_DP5 pid=178306)[0;0m [1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:33:24 [parallel_state.py:1208] rank 5 in world size 16 is assigned as DP rank 5, PP rank 0, TP rank 0, EP rank 5
INFO 11-04 09:33:24 [parallel_state.py:1208] rank 2 in world size 16 is assigned as DP rank 2, PP rank 0, TP rank 0, EP rank 2
[1;36m(EngineCore_DP0 pid=178301)[0;0m [1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:33:24 [parallel_state.py:1208] rank 0 in world size 16 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:33:24 [parallel_state.py:1208] rank 1 in world size 16 is assigned as DP rank 1, PP rank 0, TP rank 0, EP rank 1
INFO 11-04 09:33:24 [cuda_communicator.py:100] Using AllGather-ReduceScatter all2all manager.
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:33:24 [cuda_communicator.py:100] Using AllGather-ReduceScatter all2all manager.
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:33:24 [parallel_state.py:1208] rank 4 in world size 16 is assigned as DP rank 4, PP rank 0, TP rank 0, EP rank 4
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:33:24 [parallel_state.py:1208] rank 3 in world size 16 is assigned as DP rank 3, PP rank 0, TP rank 0, EP rank 3
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:33:24 [parallel_state.py:1208] rank 6 in world size 16 is assigned as DP rank 6, PP rank 0, TP rank 0, EP rank 6
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:33:24 [cuda_communicator.py:100] Using AllGather-ReduceScatter all2all manager.
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:33:24 [parallel_state.py:1208] rank 7 in world size 16 is assigned as DP rank 7, PP rank 0, TP rank 0, EP rank 7
[1;36m(EngineCore_DP7 pid=178308)[0;0m WARNING 11-04 09:33:24 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP4 pid=178305)[0;0m WARNING 11-04 09:33:24 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP3 pid=178304)[0;0m WARNING 11-04 09:33:24 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP1 pid=178302)[0;0m WARNING 11-04 09:33:24 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP2 pid=178303)[0;0m WARNING 11-04 09:33:24 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP5 pid=178306)[0;0m WARNING 11-04 09:33:24 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP6 pid=178307)[0;0m WARNING 11-04 09:33:24 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=178301)[0;0m WARNING 11-04 09:33:24 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:33:25 [gpu_model_runner.py:2602] Starting to load model /dev/shm/DeepSeek-V3.2-Exp...
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:33:25 [gpu_model_runner.py:2602] Starting to load model /dev/shm/DeepSeek-V3.2-Exp...
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:33:25 [gpu_model_runner.py:2602] Starting to load model /dev/shm/DeepSeek-V3.2-Exp...
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:33:25 [gpu_model_runner.py:2602] Starting to load model /dev/shm/DeepSeek-V3.2-Exp...
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:33:25 [gpu_model_runner.py:2602] Starting to load model /dev/shm/DeepSeek-V3.2-Exp...
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:33:25 [gpu_model_runner.py:2602] Starting to load model /dev/shm/DeepSeek-V3.2-Exp...
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:33:25 [gpu_model_runner.py:2602] Starting to load model /dev/shm/DeepSeek-V3.2-Exp...
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:33:25 [gpu_model_runner.py:2602] Starting to load model /dev/shm/DeepSeek-V3.2-Exp...
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:33:25 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:33:25 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:33:25 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:33:25 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:33:25 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:33:25 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:33:25 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:33:25 [cuda.py:253] Using Sparse MLA backend on V1 engine.
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:33:25 [cuda.py:253] Using Sparse MLA backend on V1 engine.
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:33:26 [cuda.py:253] Using Sparse MLA backend on V1 engine.
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:33:26 [gpu_model_runner.py:2634] Loading model from scratch...
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:33:26 [cuda.py:253] Using Sparse MLA backend on V1 engine.
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:33:26 [cuda.py:253] Using Sparse MLA backend on V1 engine.
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:33:26 [layer.py:1052] [EP Rank 4/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->64, 1->65, 2->66, 3->67, 4->68, 5->69, 6->70, 7->71, 8->72, 9->73, 10->74, 11->75, 12->76, 13->77, 14->78, 15->79.
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:33:26 [cuda.py:253] Using Sparse MLA backend on V1 engine.
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:33:26 [layer.py:1052] [EP Rank 2/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->32, 1->33, 2->34, 3->35, 4->36, 5->37, 6->38, 7->39, 8->40, 9->41, 10->42, 11->43, 12->44, 13->45, 14->46, 15->47.
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:33:26 [cuda.py:253] Using Sparse MLA backend on V1 engine.
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:33:26 [fp8.py:462] Using DeepGemm kernels for Fp8MoEMethod.
[1;36m(EngineCore_DP4 pid=178305)[0;0m WARNING 11-04 09:33:26 [fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:33:26 [fp8.py:462] Using DeepGemm kernels for Fp8MoEMethod.
[1;36m(EngineCore_DP2 pid=178303)[0;0m WARNING 11-04 09:33:26 [fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:33:26 [layer.py:1052] [EP Rank 1/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->16, 1->17, 2->18, 3->19, 4->20, 5->21, 6->22, 7->23, 8->24, 9->25, 10->26, 11->27, 12->28, 13->29, 14->30, 15->31.
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:33:26 [fp8.py:462] Using DeepGemm kernels for Fp8MoEMethod.
[1;36m(EngineCore_DP1 pid=178302)[0;0m WARNING 11-04 09:33:26 [fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:33:26 [layer.py:1052] [EP Rank 7/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->112, 1->113, 2->114, 3->115, 4->116, 5->117, 6->118, 7->119, 8->120, 9->121, 10->122, 11->123, 12->124, 13->125, 14->126, 15->127.
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:33:26 [fp8.py:462] Using DeepGemm kernels for Fp8MoEMethod.
[1;36m(EngineCore_DP7 pid=178308)[0;0m WARNING 11-04 09:33:26 [fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:33:26 [layer.py:1052] [EP Rank 3/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->48, 1->49, 2->50, 3->51, 4->52, 5->53, 6->54, 7->55, 8->56, 9->57, 10->58, 11->59, 12->60, 13->61, 14->62, 15->63.
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:33:26 [fp8.py:462] Using DeepGemm kernels for Fp8MoEMethod.
[1;36m(EngineCore_DP3 pid=178304)[0;0m WARNING 11-04 09:33:26 [fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:33:26 [cuda.py:253] Using Sparse MLA backend on V1 engine.
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:33:26 [layer.py:1052] [EP Rank 5/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->80, 1->81, 2->82, 3->83, 4->84, 5->85, 6->86, 7->87, 8->88, 9->89, 10->90, 11->91, 12->92, 13->93, 14->94, 15->95.
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:33:26 [fp8.py:462] Using DeepGemm kernels for Fp8MoEMethod.
[1;36m(EngineCore_DP5 pid=178306)[0;0m WARNING 11-04 09:33:26 [fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:33:26 [layer.py:1052] [EP Rank 0/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->0, 1->1, 2->2, 3->3, 4->4, 5->5, 6->6, 7->7, 8->8, 9->9, 10->10, 11->11, 12->12, 13->13, 14->14, 15->15.
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:33:26 [fp8.py:462] Using DeepGemm kernels for Fp8MoEMethod.
[1;36m(EngineCore_DP0 pid=178301)[0;0m WARNING 11-04 09:33:26 [fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:33:26 [layer.py:1052] [EP Rank 6/16] Expert parallelism is enabled. Expert placement strategy: linear. Local/global number of experts: 16/256. Experts local to global index map: 0->96, 1->97, 2->98, 3->99, 4->100, 5->101, 6->102, 7->103, 8->104, 9->105, 10->106, 11->107, 12->108, 13->109, 14->110, 15->111.
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:33:26 [fp8.py:462] Using DeepGemm kernels for Fp8MoEMethod.
[1;36m(EngineCore_DP6 pid=178307)[0;0m WARNING 11-04 09:33:26 [fp8.py:480] CutlassBlockScaledGroupedGemm not supported on the current platform.
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/163 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:   3% Completed | 5/163 [00:00<00:09, 16.41it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:   4% Completed | 7/163 [00:00<00:14, 10.98it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:   6% Completed | 9/163 [00:00<00:15,  9.81it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:   6% Completed | 10/163 [00:01<00:19,  7.70it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:   7% Completed | 11/163 [00:01<00:23,  6.41it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:   7% Completed | 12/163 [00:01<00:26,  5.70it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:   8% Completed | 13/163 [00:01<00:29,  5.15it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:   9% Completed | 14/163 [00:02<00:30,  4.86it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:   9% Completed | 15/163 [00:02<00:31,  4.65it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  10% Completed | 16/163 [00:02<00:32,  4.49it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  10% Completed | 17/163 [00:02<00:33,  4.33it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  11% Completed | 18/163 [00:03<00:33,  4.27it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  12% Completed | 19/163 [00:03<00:33,  4.25it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  12% Completed | 20/163 [00:03<00:33,  4.21it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  13% Completed | 21/163 [00:03<00:33,  4.21it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  13% Completed | 22/163 [00:03<00:33,  4.19it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  14% Completed | 23/163 [00:04<00:33,  4.17it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  15% Completed | 24/163 [00:04<00:33,  4.19it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  15% Completed | 25/163 [00:04<00:33,  4.18it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  16% Completed | 26/163 [00:04<00:32,  4.17it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  17% Completed | 28/163 [00:05<00:26,  5.16it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  18% Completed | 29/163 [00:05<00:27,  4.88it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  18% Completed | 30/163 [00:05<00:28,  4.69it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  19% Completed | 31/163 [00:05<00:29,  4.53it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  20% Completed | 32/163 [00:06<00:29,  4.44it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  20% Completed | 33/163 [00:06<00:29,  4.39it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  21% Completed | 34/163 [00:06<00:29,  4.31it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  21% Completed | 35/163 [00:06<00:30,  4.25it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  22% Completed | 36/163 [00:07<00:30,  4.22it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  23% Completed | 37/163 [00:07<00:30,  4.12it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  23% Completed | 38/163 [00:07<00:30,  4.07it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  24% Completed | 39/163 [00:07<00:30,  4.06it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  25% Completed | 40/163 [00:08<00:30,  4.06it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  25% Completed | 41/163 [00:08<00:29,  4.07it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  26% Completed | 43/163 [00:08<00:24,  5.00it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  28% Completed | 45/163 [00:08<00:16,  7.00it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  28% Completed | 46/163 [00:09<00:18,  6.17it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  29% Completed | 47/163 [00:09<00:21,  5.51it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  29% Completed | 48/163 [00:09<00:22,  5.09it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  30% Completed | 49/163 [00:09<00:23,  4.78it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  31% Completed | 50/163 [00:10<00:24,  4.55it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  31% Completed | 51/163 [00:10<00:25,  4.39it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  32% Completed | 52/163 [00:10<00:25,  4.28it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  33% Completed | 53/163 [00:10<00:26,  4.22it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  33% Completed | 54/163 [00:10<00:26,  4.15it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  34% Completed | 55/163 [00:11<00:26,  4.13it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  34% Completed | 56/163 [00:11<00:25,  4.13it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  35% Completed | 57/163 [00:11<00:25,  4.16it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  36% Completed | 58/163 [00:11<00:25,  4.13it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  36% Completed | 59/163 [00:12<00:25,  4.12it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  37% Completed | 61/163 [00:12<00:20,  5.01it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  38% Completed | 62/163 [00:12<00:21,  4.76it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  39% Completed | 63/163 [00:12<00:21,  4.56it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  39% Completed | 64/163 [00:13<00:22,  4.41it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  40% Completed | 65/163 [00:13<00:22,  4.30it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  40% Completed | 66/163 [00:13<00:22,  4.24it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  41% Completed | 67/163 [00:13<00:23,  4.16it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  42% Completed | 69/163 [00:14<00:14,  6.35it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  44% Completed | 72/163 [00:14<00:09,  9.73it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  46% Completed | 75/163 [00:14<00:06, 12.62it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  48% Completed | 78/163 [00:14<00:05, 14.97it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  50% Completed | 81/163 [00:14<00:04, 16.87it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  52% Completed | 84/163 [00:14<00:04, 18.38it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  53% Completed | 87/163 [00:14<00:03, 19.51it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  55% Completed | 90/163 [00:15<00:03, 20.35it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  57% Completed | 93/163 [00:15<00:03, 20.91it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  59% Completed | 96/163 [00:15<00:03, 21.23it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  61% Completed | 99/163 [00:15<00:02, 21.64it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  63% Completed | 102/163 [00:15<00:02, 21.90it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  64% Completed | 105/163 [00:15<00:02, 22.03it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  66% Completed | 108/163 [00:15<00:02, 22.08it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  68% Completed | 111/163 [00:15<00:02, 22.14it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  70% Completed | 114/163 [00:16<00:02, 22.20it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  72% Completed | 117/163 [00:16<00:02, 21.79it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  74% Completed | 120/163 [00:16<00:01, 23.72it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  75% Completed | 123/163 [00:16<00:01, 23.21it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  77% Completed | 126/163 [00:16<00:01, 22.94it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  79% Completed | 129/163 [00:16<00:01, 22.73it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  81% Completed | 132/163 [00:16<00:01, 22.55it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  83% Completed | 135/163 [00:17<00:01, 22.35it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  85% Completed | 138/163 [00:17<00:01, 22.25it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  87% Completed | 141/163 [00:17<00:00, 22.22it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  88% Completed | 144/163 [00:17<00:00, 22.12it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  90% Completed | 147/163 [00:17<00:00, 22.08it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  92% Completed | 150/163 [00:17<00:00, 22.05it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  94% Completed | 153/163 [00:17<00:00, 22.00it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  96% Completed | 156/163 [00:17<00:00, 21.94it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  98% Completed | 159/163 [00:18<00:00, 16.55it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards:  99% Completed | 161/163 [00:19<00:00,  5.93it/s]
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:33:48 [default_loader.py:267] Loading weights took 19.94 seconds
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards: 100% Completed | 163/163 [00:19<00:00,  5.29it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m Loading safetensors checkpoint shards: 100% Completed | 163/163 [00:19<00:00,  8.20it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m 
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:33:48 [default_loader.py:267] Loading weights took 19.94 seconds
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:33:48 [deep_gemm.py:56] DeepGEMM E8M0 enabled on Hopper GPU.
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:33:48 [deep_gemm.py:56] DeepGEMM E8M0 enabled on Hopper GPU.
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:33:48 [default_loader.py:267] Loading weights took 20.14 seconds
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:33:49 [default_loader.py:267] Loading weights took 20.22 seconds
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:33:49 [default_loader.py:267] Loading weights took 20.23 seconds
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:33:49 [deep_gemm.py:56] DeepGEMM E8M0 enabled on Hopper GPU.
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:33:49 [deep_gemm.py:56] DeepGEMM E8M0 enabled on Hopper GPU.
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:33:49 [deep_gemm.py:56] DeepGEMM E8M0 enabled on Hopper GPU.
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:33:49 [default_loader.py:267] Loading weights took 20.50 seconds
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:33:49 [default_loader.py:267] Loading weights took 20.39 seconds
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:33:49 [deep_gemm.py:56] DeepGEMM E8M0 enabled on Hopper GPU.
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:33:49 [deep_gemm.py:56] DeepGEMM E8M0 enabled on Hopper GPU.
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:33:49 [default_loader.py:267] Loading weights took 20.94 seconds
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:33:49 [deep_gemm.py:56] DeepGEMM E8M0 enabled on Hopper GPU.
[1;36m(EngineCore_DP0 pid=178301)[0;0m WARNING 11-04 09:34:07 [kv_cache.py:86] Checkpoint does not provide a q scaling factor. Setting it to k_scale. This only matters for the flash-attn backend.
[1;36m(EngineCore_DP0 pid=178301)[0;0m WARNING 11-04 09:34:07 [kv_cache.py:100] Using KV cache scaling factor 1.0 for fp8_e4m3. This may cause accuracy issues. Please make sure k/v_scale scaling factors are available in the fp8 checkpoint.
[1;36m(EngineCore_DP2 pid=178303)[0;0m WARNING 11-04 09:34:07 [kv_cache.py:86] Checkpoint does not provide a q scaling factor. Setting it to k_scale. This only matters for the flash-attn backend.
[1;36m(EngineCore_DP2 pid=178303)[0;0m WARNING 11-04 09:34:07 [kv_cache.py:100] Using KV cache scaling factor 1.0 for fp8_e4m3. This may cause accuracy issues. Please make sure k/v_scale scaling factors are available in the fp8 checkpoint.
[1;36m(EngineCore_DP7 pid=178308)[0;0m WARNING 11-04 09:34:07 [kv_cache.py:86] Checkpoint does not provide a q scaling factor. Setting it to k_scale. This only matters for the flash-attn backend.
[1;36m(EngineCore_DP7 pid=178308)[0;0m WARNING 11-04 09:34:07 [kv_cache.py:100] Using KV cache scaling factor 1.0 for fp8_e4m3. This may cause accuracy issues. Please make sure k/v_scale scaling factors are available in the fp8 checkpoint.
[1;36m(EngineCore_DP1 pid=178302)[0;0m WARNING 11-04 09:34:07 [kv_cache.py:86] Checkpoint does not provide a q scaling factor. Setting it to k_scale. This only matters for the flash-attn backend.
[1;36m(EngineCore_DP1 pid=178302)[0;0m WARNING 11-04 09:34:07 [kv_cache.py:100] Using KV cache scaling factor 1.0 for fp8_e4m3. This may cause accuracy issues. Please make sure k/v_scale scaling factors are available in the fp8 checkpoint.
[1;36m(EngineCore_DP3 pid=178304)[0;0m WARNING 11-04 09:34:07 [kv_cache.py:86] Checkpoint does not provide a q scaling factor. Setting it to k_scale. This only matters for the flash-attn backend.
[1;36m(EngineCore_DP3 pid=178304)[0;0m WARNING 11-04 09:34:07 [kv_cache.py:100] Using KV cache scaling factor 1.0 for fp8_e4m3. This may cause accuracy issues. Please make sure k/v_scale scaling factors are available in the fp8 checkpoint.
[1;36m(EngineCore_DP4 pid=178305)[0;0m WARNING 11-04 09:34:07 [kv_cache.py:86] Checkpoint does not provide a q scaling factor. Setting it to k_scale. This only matters for the flash-attn backend.
[1;36m(EngineCore_DP4 pid=178305)[0;0m WARNING 11-04 09:34:07 [kv_cache.py:100] Using KV cache scaling factor 1.0 for fp8_e4m3. This may cause accuracy issues. Please make sure k/v_scale scaling factors are available in the fp8 checkpoint.
[1;36m(EngineCore_DP6 pid=178307)[0;0m WARNING 11-04 09:34:07 [kv_cache.py:86] Checkpoint does not provide a q scaling factor. Setting it to k_scale. This only matters for the flash-attn backend.
[1;36m(EngineCore_DP6 pid=178307)[0;0m WARNING 11-04 09:34:07 [kv_cache.py:100] Using KV cache scaling factor 1.0 for fp8_e4m3. This may cause accuracy issues. Please make sure k/v_scale scaling factors are available in the fp8 checkpoint.
[1;36m(EngineCore_DP5 pid=178306)[0;0m WARNING 11-04 09:34:07 [kv_cache.py:86] Checkpoint does not provide a q scaling factor. Setting it to k_scale. This only matters for the flash-attn backend.
[1;36m(EngineCore_DP5 pid=178306)[0;0m WARNING 11-04 09:34:07 [kv_cache.py:100] Using KV cache scaling factor 1.0 for fp8_e4m3. This may cause accuracy issues. Please make sure k/v_scale scaling factors are available in the fp8 checkpoint.
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:34:10 [gpu_model_runner.py:2653] Model loading took 58.6827 GiB and 43.830818 seconds
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:34:10 [gpu_model_runner.py:2653] Model loading took 58.6827 GiB and 43.827256 seconds
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:34:10 [gpu_model_runner.py:2653] Model loading took 58.6827 GiB and 43.782092 seconds
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:34:10 [gpu_model_runner.py:2653] Model loading took 58.6827 GiB and 43.743084 seconds
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:34:10 [gpu_model_runner.py:2653] Model loading took 58.6827 GiB and 43.839848 seconds
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:34:10 [gpu_model_runner.py:2653] Model loading took 58.6827 GiB and 43.817924 seconds
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:34:10 [gpu_model_runner.py:2653] Model loading took 58.6827 GiB and 43.879980 seconds
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:34:10 [gpu_model_runner.py:2653] Model loading took 58.6827 GiB and 43.690401 seconds
[1;36m(EngineCore_DP1 pid=178302)[0;0m /home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3421: UserWarning: Unsupported unwinding pattern: Address not in range (Triggered internally at /pytorch/torch/csrc/profiler/unwind/unwind.cpp:219.)
[1;36m(EngineCore_DP1 pid=178302)[0;0m   return node.target(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=178301)[0;0m /home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3421: UserWarning: Unsupported unwinding pattern: Address not in range (Triggered internally at /pytorch/torch/csrc/profiler/unwind/unwind.cpp:219.)
[1;36m(EngineCore_DP0 pid=178301)[0;0m   return node.target(*args, **kwargs)
[1;36m(EngineCore_DP4 pid=178305)[0;0m /home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3421: UserWarning: Unsupported unwinding pattern: Address not in range (Triggered internally at /pytorch/torch/csrc/profiler/unwind/unwind.cpp:219.)
[1;36m(EngineCore_DP4 pid=178305)[0;0m   return node.target(*args, **kwargs)
[1;36m(EngineCore_DP6 pid=178307)[0;0m /home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3421: UserWarning: Unsupported unwinding pattern: Address not in range (Triggered internally at /pytorch/torch/csrc/profiler/unwind/unwind.cpp:219.)
[1;36m(EngineCore_DP6 pid=178307)[0;0m   return node.target(*args, **kwargs)
[1;36m(EngineCore_DP7 pid=178308)[0;0m /home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3421: UserWarning: Unsupported unwinding pattern: Address not in range (Triggered internally at /pytorch/torch/csrc/profiler/unwind/unwind.cpp:219.)
[1;36m(EngineCore_DP7 pid=178308)[0;0m   return node.target(*args, **kwargs)
[1;36m(EngineCore_DP2 pid=178303)[0;0m /home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3421: UserWarning: Unsupported unwinding pattern: Address not in range (Triggered internally at /pytorch/torch/csrc/profiler/unwind/unwind.cpp:219.)
[1;36m(EngineCore_DP2 pid=178303)[0;0m   return node.target(*args, **kwargs)
[1;36m(EngineCore_DP5 pid=178306)[0;0m /home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3421: UserWarning: Unsupported unwinding pattern: Address not in range (Triggered internally at /pytorch/torch/csrc/profiler/unwind/unwind.cpp:219.)
[1;36m(EngineCore_DP5 pid=178306)[0;0m   return node.target(*args, **kwargs)
[1;36m(EngineCore_DP3 pid=178304)[0;0m /home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/torch/_dynamo/utils.py:3421: UserWarning: Unsupported unwinding pattern: Address not in range (Triggered internally at /pytorch/torch/csrc/profiler/unwind/unwind.cpp:219.)
[1;36m(EngineCore_DP3 pid=178304)[0;0m   return node.target(*args, **kwargs)
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:34:34 [gpu_worker.py:298] Available KV cache memory: 2.22 GiB
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:34:34 [gpu_worker.py:298] Available KV cache memory: 2.22 GiB
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:34:34 [gpu_worker.py:298] Available KV cache memory: 2.23 GiB
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:34:34 [gpu_worker.py:298] Available KV cache memory: 2.23 GiB
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:34:34 [gpu_worker.py:298] Available KV cache memory: 2.22 GiB
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:34:34 [gpu_worker.py:298] Available KV cache memory: 2.23 GiB
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:34:34 [gpu_worker.py:298] Available KV cache memory: 2.23 GiB
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:34:34 [gpu_worker.py:298] Available KV cache memory: 2.22 GiB
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:34:34 [kv_cache_utils.py:1087] GPU KV cache size: 49,472 tokens
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:34:34 [kv_cache_utils.py:1091] Maximum concurrency for 5,000 tokens per request: 9.78x
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:34:34 [kv_cache_utils.py:1087] GPU KV cache size: 49,792 tokens
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:34:34 [kv_cache_utils.py:1091] Maximum concurrency for 5,000 tokens per request: 9.85x
[1;36m(EngineCore_DP3 pid=178304)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):   0%|          | 0/8192 [00:00<?, ?it/s][1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:34:34 [kv_cache_utils.py:1087] GPU KV cache size: 49,792 tokens
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:34:34 [kv_cache_utils.py:1091] Maximum concurrency for 5,000 tokens per request: 9.85x
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:34:34 [kv_cache_utils.py:1087] GPU KV cache size: 49,792 tokens
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:34:34 [kv_cache_utils.py:1091] Maximum concurrency for 5,000 tokens per request: 9.85x
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:34:34 [kv_cache_utils.py:1087] GPU KV cache size: 49,472 tokens
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:34:34 [kv_cache_utils.py:1091] Maximum concurrency for 5,000 tokens per request: 9.78x
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:34:34 [kv_cache_utils.py:1087] GPU KV cache size: 49,792 tokens
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:34:34 [kv_cache_utils.py:1091] Maximum concurrency for 5,000 tokens per request: 9.85x
[1;36m(EngineCore_DP2 pid=178303)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):   0%|          | 0/8192 [00:00<?, ?it/s][1;36m(EngineCore_DP6 pid=178307)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):   0%|          | 0/8192 [00:00<?, ?it/s][1;36m(EngineCore_DP0 pid=178301)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):   0%|          | 0/8192 [00:00<?, ?it/s][1;36m(EngineCore_DP5 pid=178306)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):   0%|          | 0/8192 [00:00<?, ?it/s][1;36m(EngineCore_DP4 pid=178305)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):   0%|          | 0/8192 [00:00<?, ?it/s][1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:34:34 [kv_cache_utils.py:1087] GPU KV cache size: 49,472 tokens
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:34:34 [kv_cache_utils.py:1091] Maximum concurrency for 5,000 tokens per request: 9.78x
DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):   3%|▎         | 257/8192 [00:00<00:04, 1681.83it/s][1;36m(EngineCore_DP7 pid=178308)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):   0%|          | 0/8192 [00:00<?, ?it/s][1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:34:34 [kv_cache_utils.py:1087] GPU KV cache size: 49,472 tokens
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:34:34 [kv_cache_utils.py:1091] Maximum concurrency for 5,000 tokens per request: 9.78x
DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):   3%|▎         | 257/8192 [00:00<00:04, 1924.25it/s][1;36m(EngineCore_DP1 pid=178302)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):   3%|▎         | 257/8192 [00:00<00:04, 1901.00it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):   3%|▎         | 257/8192 [00:00<00:04, 1897.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):   3%|▎         | 257/8192 [00:00<00:04, 1894.79it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):   3%|▎         | 257/8192 [00:00<00:04, 1907.85it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  12%|█▏        | 987/8192 [00:00<00:01, 4387.63it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  12%|█▏        | 975/8192 [00:00<00:01, 4635.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  12%|█▏        | 985/8192 [00:00<00:01, 4657.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  12%|█▏        | 986/8192 [00:00<00:01, 4660.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):   3%|▎         | 257/8192 [00:00<00:04, 1902.12it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  12%|█▏        | 987/8192 [00:00<00:01, 4660.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  12%|█▏        | 986/8192 [00:00<00:01, 4674.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):   3%|▎         | 257/8192 [00:00<00:04, 1904.62it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  12%|█▏        | 985/8192 [00:00<00:01, 4664.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  12%|█▏        | 984/8192 [00:00<00:01, 4655.84it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  18%|█▊        | 1484/8192 [00:00<00:02, 3128.60it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  18%|█▊        | 1476/8192 [00:00<00:02, 3156.90it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  18%|█▊        | 1491/8192 [00:00<00:02, 3198.02it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  18%|█▊        | 1492/8192 [00:00<00:02, 3196.98it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  18%|█▊        | 1494/8192 [00:00<00:02, 3190.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  18%|█▊        | 1493/8192 [00:00<00:02, 3206.52it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  23%|██▎       | 1859/8192 [00:00<00:02, 2861.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  18%|█▊        | 1492/8192 [00:00<00:02, 3187.38it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  18%|█▊        | 1489/8192 [00:00<00:02, 3188.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  23%|██▎       | 1852/8192 [00:00<00:02, 2870.57it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  23%|██▎       | 1871/8192 [00:00<00:02, 2901.90it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  23%|██▎       | 1872/8192 [00:00<00:02, 2903.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  23%|██▎       | 1874/8192 [00:00<00:02, 2898.66it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  23%|██▎       | 1874/8192 [00:00<00:02, 2907.43it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  27%|██▋       | 2182/8192 [00:00<00:02, 2763.00it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  23%|██▎       | 1872/8192 [00:00<00:02, 2895.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  27%|██▋       | 2175/8192 [00:00<00:02, 2761.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  27%|██▋       | 2197/8192 [00:00<00:02, 2790.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  27%|██▋       | 2198/8192 [00:00<00:02, 2793.10it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  23%|██▎       | 1868/8192 [00:00<00:02, 2896.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  27%|██▋       | 2201/8192 [00:00<00:02, 2801.50it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  27%|██▋       | 2200/8192 [00:00<00:02, 2789.38it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  30%|███       | 2480/8192 [00:00<00:02, 2731.84it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  30%|███       | 2472/8192 [00:00<00:02, 2724.76it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  27%|██▋       | 2198/8192 [00:00<00:02, 2786.90it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  30%|███       | 2497/8192 [00:00<00:02, 2755.13it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  31%|███       | 2499/8192 [00:00<00:02, 2755.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  31%|███       | 2503/8192 [00:00<00:02, 2765.96it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  31%|███       | 2500/8192 [00:00<00:02, 2752.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  27%|██▋       | 2193/8192 [00:00<00:02, 2787.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  34%|███▍      | 2767/8192 [00:00<00:02, 2700.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  34%|███▎      | 2758/8192 [00:00<00:02, 2675.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  30%|███       | 2498/8192 [00:00<00:02, 2746.31it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  34%|███▍      | 2788/8192 [00:00<00:01, 2718.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  34%|███▍      | 2786/8192 [00:00<00:02, 2693.45it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  34%|███▍      | 2789/8192 [00:00<00:01, 2722.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  34%|███▍      | 2793/8192 [00:00<00:01, 2722.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  30%|███       | 2493/8192 [00:00<00:02, 2749.89it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  37%|███▋      | 3046/8192 [00:01<00:01, 2682.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  37%|███▋      | 3034/8192 [00:01<00:01, 2684.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  37%|███▋      | 3064/8192 [00:01<00:01, 2699.89it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  37%|███▋      | 3069/8192 [00:01<00:01, 2705.45it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  37%|███▋      | 3070/8192 [00:01<00:01, 2725.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  34%|███▍      | 2786/8192 [00:00<00:02, 2679.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  34%|███▍      | 2781/8192 [00:00<00:01, 2727.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  37%|███▋      | 3062/8192 [00:01<00:01, 2691.37it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  41%|████      | 3320/8192 [00:01<00:02, 2202.45it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  37%|███▋      | 3063/8192 [00:01<00:01, 2743.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  40%|████      | 3309/8192 [00:01<00:02, 2173.23it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  38%|███▊      | 3074/8192 [00:01<00:02, 1893.37it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  41%|████      | 3340/8192 [00:01<00:02, 2251.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  41%|████      | 3349/8192 [00:01<00:02, 2287.17it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  41%|████      | 3345/8192 [00:01<00:02, 2257.45it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  48%|████▊     | 3939/8192 [00:01<00:01, 3165.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  48%|████▊     | 3936/8192 [00:01<00:01, 3155.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  48%|████▊     | 3921/8192 [00:01<00:01, 3261.73it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  48%|████▊     | 3944/8192 [00:01<00:01, 3178.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  48%|████▊     | 3941/8192 [00:01<00:01, 3182.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  48%|████▊     | 3944/8192 [00:01<00:01, 3171.36it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  41%|████      | 3337/8192 [00:01<00:02, 2242.39it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  41%|████      | 3344/8192 [00:01<00:02, 2282.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  53%|█████▎    | 4301/8192 [00:01<00:01, 3281.00it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  52%|█████▏    | 4295/8192 [00:01<00:01, 3265.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  53%|█████▎    | 4301/8192 [00:01<00:01, 3289.86it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  53%|█████▎    | 4307/8192 [00:01<00:01, 3293.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  53%|█████▎    | 4309/8192 [00:01<00:01, 3295.02it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  48%|████▊     | 3941/8192 [00:01<00:01, 3171.50it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  53%|█████▎    | 4340/8192 [00:01<00:01, 3354.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  48%|████▊     | 3942/8192 [00:01<00:01, 3192.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  57%|█████▋    | 4694/8192 [00:01<00:01, 3454.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  57%|█████▋    | 4685/8192 [00:01<00:01, 3433.89it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  57%|█████▋    | 4695/8192 [00:01<00:01, 3465.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  57%|█████▋    | 4702/8192 [00:01<00:01, 3468.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  57%|█████▋    | 4706/8192 [00:01<00:01, 3476.59it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  53%|█████▎    | 4301/8192 [00:01<00:01, 3280.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  58%|█████▊    | 4742/8192 [00:01<00:00, 3504.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  53%|█████▎    | 4303/8192 [00:01<00:01, 3298.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  63%|██████▎   | 5125/8192 [00:01<00:00, 3689.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  62%|██████▏   | 5116/8192 [00:01<00:00, 3675.68it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  63%|██████▎   | 5131/8192 [00:01<00:00, 3714.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  63%|██████▎   | 5136/8192 [00:01<00:00, 3709.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  63%|██████▎   | 5144/8192 [00:01<00:00, 3726.64it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  57%|█████▋    | 4691/8192 [00:01<00:01, 3447.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  63%|██████▎   | 5183/8192 [00:01<00:00, 3734.46it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  57%|█████▋    | 4695/8192 [00:01<00:01, 3465.96it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  69%|██████▊   | 5614/8192 [00:01<00:00, 4028.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  68%|██████▊   | 5603/8192 [00:01<00:00, 4011.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  69%|██████▊   | 5625/8192 [00:01<00:00, 4062.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  69%|██████▊   | 5628/8192 [00:01<00:00, 4052.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  69%|██████▉   | 5638/8192 [00:01<00:00, 4070.64it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  63%|██████▎   | 5126/8192 [00:01<00:00, 3697.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  69%|██████▉   | 5683/8192 [00:01<00:00, 4070.92it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  63%|██████▎   | 5126/8192 [00:01<00:00, 3699.68it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  74%|███████▎  | 6032/8192 [00:01<00:00, 3666.64it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  69%|██████▊   | 5618/8192 [00:01<00:00, 4044.62it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  69%|██████▊   | 5612/8192 [00:01<00:00, 4029.66it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  74%|███████▍  | 6044/8192 [00:01<00:00, 3718.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  74%|███████▍  | 6059/8192 [00:01<00:00, 3743.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  75%|███████▍  | 6122/8192 [00:01<00:00, 3885.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  73%|███████▎  | 6020/8192 [00:01<00:00, 3612.40it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  74%|███████▍  | 6047/8192 [00:01<00:00, 3693.12it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  84%|████████▍ | 6913/8192 [00:02<00:00, 4716.78it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  74%|███████▎  | 6036/8192 [00:01<00:00, 3657.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  84%|████████▍ | 6913/8192 [00:01<00:00, 4687.66it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  84%|████████▍ | 6913/8192 [00:02<00:00, 4755.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  84%|████████▍ | 6913/8192 [00:02<00:00, 4718.68it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  74%|███████▎  | 6028/8192 [00:01<00:00, 3675.02it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  84%|████████▍ | 6913/8192 [00:02<00:00, 4707.14it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  84%|████████▍ | 6913/8192 [00:02<00:00, 4699.35it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  99%|█████████▉| 8129/8192 [00:02<00:00, 6625.97it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])): 100%|██████████| 8192/8192 [00:02<00:00, 3839.38it/s]
[1;36m(EngineCore_DP3 pid=178304)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  99%|█████████▉| 8129/8192 [00:02<00:00, 6669.17it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  99%|█████████▉| 8141/8192 [00:02<00:00, 6767.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])): 100%|██████████| 8192/8192 [00:02<00:00, 3897.62it/s]
DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])): 100%|██████████| 8192/8192 [00:02<00:00, 3902.25it/s]
DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  99%|█████████▉| 8135/8192 [00:02<00:00, 6721.76it/s][1;36m(EngineCore_DP5 pid=178306)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])): 100%|██████████| 8192/8192 [00:02<00:00, 3889.72it/s]
[1;36m(EngineCore_DP4 pid=178305)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])): 100%|█████████▉| 8163/8192 [00:02<00:00, 6751.61it/s][1;36m(EngineCore_DP0 pid=178301)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])): 100%|██████████| 8192/8192 [00:02<00:00, 3851.87it/s]
DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  99%|█████████▉| 8129/8192 [00:02<00:00, 6664.29it/s][1;36m(EngineCore_DP2 pid=178303)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])): 100%|██████████| 8192/8192 [00:02<00:00, 3878.30it/s]
[1;36m(EngineCore_DP6 pid=178307)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  84%|████████▍ | 6913/8192 [00:02<00:00, 4695.13it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  84%|████████▍ | 6913/8192 [00:01<00:00, 4806.59it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):   9%|▉         | 750/8192 [00:00<00:00, 7485.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):   9%|▉         | 765/8192 [00:00<00:00, 7632.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):   9%|▉         | 768/8192 [00:00<00:00, 7666.50it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):   9%|▉         | 769/8192 [00:00<00:00, 7671.73it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):   9%|▉         | 770/8192 [00:00<00:00, 7697.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):   9%|▉         | 765/8192 [00:00<00:00, 7634.23it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  99%|█████████▉| 8129/8192 [00:02<00:00, 6640.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])): 100%|██████████| 8192/8192 [00:02<00:00, 3867.24it/s]
[1;36m(EngineCore_DP7 pid=178308)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])):  99%|█████████▉| 8129/8192 [00:02<00:00, 6773.07it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([24576, 1536])): 100%|██████████| 8192/8192 [00:02<00:00, 3901.84it/s]
[1;36m(EngineCore_DP1 pid=178302)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):   9%|▉         | 768/8192 [00:00<00:00, 7676.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):   9%|▉         | 767/8192 [00:00<00:00, 7653.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  18%|█▊        | 1499/8192 [00:00<00:01, 4749.91it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  19%|█▊        | 1529/8192 [00:00<00:01, 4780.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  19%|█▊        | 1535/8192 [00:00<00:01, 4787.09it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  19%|█▉        | 1537/8192 [00:00<00:01, 4791.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  19%|█▉        | 1540/8192 [00:00<00:01, 4793.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  19%|█▊        | 1529/8192 [00:00<00:01, 4771.52it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  25%|██▍       | 2030/8192 [00:00<00:01, 4531.39it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  19%|█▉        | 1536/8192 [00:00<00:01, 4787.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  19%|█▊        | 1533/8192 [00:00<00:01, 4796.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  25%|██▌       | 2067/8192 [00:00<00:01, 4559.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  25%|██▌       | 2074/8192 [00:00<00:01, 4558.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  25%|██▌       | 2077/8192 [00:00<00:01, 4559.36it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  25%|██▌       | 2081/8192 [00:00<00:01, 4554.45it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  25%|██▌       | 2066/8192 [00:00<00:01, 4541.66it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  31%|███       | 2511/8192 [00:00<00:01, 4540.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  31%|███       | 2552/8192 [00:00<00:01, 4560.35it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  31%|███▏      | 2560/8192 [00:00<00:01, 4557.40it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  31%|███▏      | 2563/8192 [00:00<00:01, 4558.89it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  31%|███       | 2550/8192 [00:00<00:01, 4539.03it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  31%|███▏      | 2567/8192 [00:00<00:01, 4539.60it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  25%|██▌       | 2075/8192 [00:00<00:01, 4563.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  25%|██▌       | 2072/8192 [00:00<00:01, 4573.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  37%|███▋      | 3006/8192 [00:00<00:01, 4665.41it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  37%|███▋      | 3045/8192 [00:00<00:01, 4670.72it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  37%|███▋      | 3052/8192 [00:00<00:01, 4665.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  37%|███▋      | 3056/8192 [00:00<00:01, 4670.12it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  37%|███▋      | 3041/8192 [00:00<00:01, 4650.63it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  37%|███▋      | 3051/8192 [00:00<00:01, 4628.68it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  31%|███▏      | 2561/8192 [00:00<00:01, 4559.35it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  31%|███       | 2559/8192 [00:00<00:01, 4572.82it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  43%|████▎     | 3550/8192 [00:00<00:00, 4898.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  44%|████▎     | 3575/8192 [00:00<00:00, 4860.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  44%|████▎     | 3581/8192 [00:00<00:00, 4853.19it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  44%|████▍     | 3590/8192 [00:00<00:00, 4870.17it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  44%|████▎     | 3575/8192 [00:00<00:00, 4857.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  44%|████▍     | 3585/8192 [00:00<00:00, 4840.63it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  37%|███▋      | 3054/8192 [00:00<00:01, 4670.67it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  37%|███▋      | 3054/8192 [00:00<00:01, 4685.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  51%|█████     | 4156/8192 [00:00<00:00, 5247.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  51%|█████     | 4179/8192 [00:00<00:00, 5213.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  51%|█████     | 4187/8192 [00:00<00:00, 5216.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  51%|█████▏    | 4200/8192 [00:00<00:00, 5239.64it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  51%|█████     | 4178/8192 [00:00<00:00, 5209.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  51%|█████     | 4187/8192 [00:00<00:00, 5194.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  44%|████▎     | 3583/8192 [00:00<00:00, 4855.73it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  44%|████▍     | 3588/8192 [00:00<00:00, 4882.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  59%|█████▊    | 4799/8192 [00:00<00:00, 5603.50it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  59%|█████▉    | 4836/8192 [00:00<00:00, 5619.68it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  59%|█████▉    | 4842/8192 [00:00<00:00, 5616.62it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  59%|█████▉    | 4858/8192 [00:00<00:00, 5641.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  59%|█████▉    | 4853/8192 [00:00<00:00, 5672.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  59%|█████▉    | 4857/8192 [00:00<00:00, 5645.73it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  51%|█████     | 4186/8192 [00:00<00:00, 5207.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  51%|█████     | 4192/8192 [00:00<00:00, 5229.41it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  67%|██████▋   | 5476/8192 [00:01<00:00, 5954.41it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  68%|██████▊   | 5577/8192 [00:01<00:00, 6156.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  68%|██████▊   | 5587/8192 [00:01<00:00, 6167.47it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  68%|██████▊   | 5601/8192 [00:01<00:00, 6177.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  68%|██████▊   | 5594/8192 [00:01<00:00, 6193.39it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  68%|██████▊   | 5588/8192 [00:01<00:00, 6144.85it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  59%|█████▉    | 4836/8192 [00:00<00:00, 5594.13it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  59%|█████▉    | 4853/8192 [00:00<00:00, 5643.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  78%|███████▊  | 6395/8192 [00:01<00:00, 6926.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  80%|███████▉  | 6542/8192 [00:01<00:00, 7203.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  80%|████████  | 6558/8192 [00:01<00:00, 7231.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  80%|████████  | 6584/8192 [00:01<00:00, 7272.65it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  80%|████████  | 6558/8192 [00:01<00:00, 7227.94it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  80%|████████  | 6565/8192 [00:01<00:00, 7231.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  68%|██████▊   | 5567/8192 [00:01<00:00, 6107.44it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  68%|██████▊   | 5597/8192 [00:01<00:00, 6182.19it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  94%|█████████▍| 7682/8192 [00:01<00:00, 8509.07it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  95%|█████████▌| 7809/8192 [00:01<00:00, 8616.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  95%|█████████▌| 7809/8192 [00:01<00:00, 8604.74it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  95%|█████████▌| 7809/8192 [00:01<00:00, 8600.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])): 100%|██████████| 8192/8192 [00:01<00:00, 6301.32it/s]
[1;36m(EngineCore_DP3 pid=178304)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  95%|█████████▌| 7809/8192 [00:01<00:00, 8591.62it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  95%|█████████▌| 7809/8192 [00:01<00:00, 8581.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  80%|███████▉  | 6521/8192 [00:01<00:00, 7137.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  80%|████████  | 6578/8192 [00:01<00:00, 7271.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])): 100%|██████████| 8192/8192 [00:01<00:00, 6390.82it/s]
DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])): 100%|██████████| 8192/8192 [00:01<00:00, 6398.34it/s]
[1;36m(EngineCore_DP5 pid=178306)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   0%|          | 0/8192 [00:00<?, ?it/s][1;36m(EngineCore_DP0 pid=178301)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])): 100%|██████████| 8192/8192 [00:01<00:00, 6388.27it/s]
[1;36m(EngineCore_DP4 pid=178305)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])): 100%|██████████| 8192/8192 [00:01<00:00, 6379.34it/s]
[1;36m(EngineCore_DP2 pid=178303)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])): 100%|██████████| 8192/8192 [00:01<00:00, 6369.86it/s]
[1;36m(EngineCore_DP6 pid=178307)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  95%|█████████▌| 7809/8192 [00:01<00:00, 8566.36it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])):  95%|█████████▌| 7809/8192 [00:01<00:00, 8606.44it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])): 100%|██████████| 8192/8192 [00:01<00:00, 6373.62it/s]
[1;36m(EngineCore_DP7 pid=178308)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([32768, 512])): 100%|██████████| 8192/8192 [00:01<00:00, 6397.40it/s]
[1;36m(EngineCore_DP1 pid=178302)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   3%|▎         | 257/8192 [00:00<00:11, 670.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   3%|▎         | 257/8192 [00:00<00:12, 639.14it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   3%|▎         | 257/8192 [00:00<00:12, 640.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   3%|▎         | 257/8192 [00:00<00:12, 635.12it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   3%|▎         | 257/8192 [00:00<00:12, 638.57it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   3%|▎         | 257/8192 [00:00<00:12, 633.23it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   3%|▎         | 257/8192 [00:00<00:11, 672.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   3%|▎         | 257/8192 [00:00<00:11, 670.80it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   6%|▋         | 513/8192 [00:00<00:11, 687.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   6%|▋         | 513/8192 [00:00<00:11, 677.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   6%|▋         | 513/8192 [00:00<00:11, 674.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   6%|▋         | 513/8192 [00:00<00:11, 670.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   6%|▋         | 513/8192 [00:00<00:11, 669.65it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   6%|▋         | 513/8192 [00:00<00:11, 668.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   6%|▋         | 513/8192 [00:00<00:11, 687.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   6%|▋         | 513/8192 [00:00<00:11, 686.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   9%|▉         | 769/8192 [00:01<00:10, 702.76it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   9%|▉         | 769/8192 [00:01<00:10, 701.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   9%|▉         | 769/8192 [00:01<00:10, 700.14it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   9%|▉         | 769/8192 [00:01<00:10, 692.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   9%|▉         | 769/8192 [00:01<00:10, 693.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   9%|▉         | 769/8192 [00:01<00:10, 695.86it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   9%|▉         | 769/8192 [00:01<00:10, 711.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):   9%|▉         | 769/8192 [00:01<00:10, 705.57it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  13%|█▎        | 1025/8192 [00:01<00:09, 719.06it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  13%|█▎        | 1025/8192 [00:01<00:09, 720.03it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  13%|█▎        | 1025/8192 [00:01<00:09, 717.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  13%|█▎        | 1025/8192 [00:01<00:10, 712.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  13%|█▎        | 1025/8192 [00:01<00:10, 710.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  13%|█▎        | 1025/8192 [00:01<00:10, 713.75it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  13%|█▎        | 1025/8192 [00:01<00:09, 726.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  13%|█▎        | 1025/8192 [00:01<00:09, 720.43it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  19%|█▉        | 1537/8192 [00:02<00:08, 755.39it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  19%|█▉        | 1537/8192 [00:02<00:08, 761.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  19%|█▉        | 1537/8192 [00:02<00:08, 759.18it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  19%|█▉        | 1537/8192 [00:02<00:08, 753.47it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  19%|█▉        | 1537/8192 [00:02<00:08, 755.94it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  19%|█▉        | 1537/8192 [00:02<00:08, 748.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  26%|██▌       | 2128/8192 [00:02<00:04, 1272.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  26%|██▌       | 2128/8192 [00:02<00:04, 1281.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  19%|█▉        | 1537/8192 [00:02<00:08, 764.78it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  26%|██▌       | 2129/8192 [00:02<00:04, 1279.43it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  19%|█▉        | 1537/8192 [00:02<00:08, 756.44it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  26%|██▌       | 2128/8192 [00:02<00:04, 1269.13it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  26%|██▌       | 2129/8192 [00:02<00:04, 1273.63it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  26%|██▌       | 2128/8192 [00:02<00:04, 1262.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  26%|██▌       | 2129/8192 [00:02<00:04, 1288.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  26%|██▌       | 2129/8192 [00:02<00:04, 1275.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  29%|██▉       | 2378/8192 [00:02<00:05, 1142.55it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  29%|██▉       | 2378/8192 [00:02<00:05, 1148.55it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  29%|██▉       | 2379/8192 [00:02<00:05, 1146.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  29%|██▉       | 2377/8192 [00:02<00:05, 1139.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  29%|██▉       | 2378/8192 [00:02<00:05, 1140.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  29%|██▉       | 2377/8192 [00:02<00:05, 1132.03it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  29%|██▉       | 2380/8192 [00:02<00:05, 1153.74it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  29%|██▉       | 2379/8192 [00:02<00:05, 1141.80it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  31%|███▏      | 2574/8192 [00:02<00:05, 1077.12it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  31%|███▏      | 2574/8192 [00:02<00:05, 1085.24it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  31%|███▏      | 2575/8192 [00:02<00:05, 1079.38it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  31%|███▏      | 2572/8192 [00:02<00:05, 1076.24it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  31%|███▏      | 2573/8192 [00:02<00:05, 1076.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  31%|███▏      | 2572/8192 [00:02<00:05, 1066.74it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  31%|███▏      | 2577/8192 [00:02<00:05, 1083.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  31%|███▏      | 2575/8192 [00:02<00:05, 1077.18it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  33%|███▎      | 2735/8192 [00:02<00:05, 1034.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  33%|███▎      | 2736/8192 [00:02<00:05, 1041.91it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  33%|███▎      | 2737/8192 [00:02<00:05, 1037.73it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  33%|███▎      | 2733/8192 [00:02<00:05, 1031.87it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  33%|███▎      | 2734/8192 [00:02<00:05, 1033.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  33%|███▎      | 2732/8192 [00:02<00:05, 1024.87it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  33%|███▎      | 2739/8192 [00:02<00:05, 1041.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  33%|███▎      | 2737/8192 [00:02<00:05, 1033.59it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  35%|███▌      | 2874/8192 [00:03<00:05, 1006.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  35%|███▌      | 2875/8192 [00:03<00:05, 1015.92it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  35%|███▌      | 2876/8192 [00:03<00:05, 1014.19it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  35%|███▌      | 2871/8192 [00:03<00:05, 1003.80it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  35%|███▌      | 2872/8192 [00:03<00:05, 1007.24it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  35%|███▌      | 2870/8192 [00:03<00:05, 997.31it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  35%|███▌      | 2878/8192 [00:03<00:05, 1017.75it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  37%|███▋      | 2998/8192 [00:03<00:05, 993.18it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  35%|███▌      | 2876/8192 [00:03<00:05, 1007.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  37%|███▋      | 3000/8192 [00:03<00:05, 1002.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  37%|███▋      | 3001/8192 [00:03<00:05, 1001.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  37%|███▋      | 2994/8192 [00:03<00:05, 990.89it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  37%|███▋      | 2996/8192 [00:03<00:05, 995.21it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  37%|███▋      | 2993/8192 [00:03<00:05, 986.36it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  38%|███▊      | 3113/8192 [00:03<00:05, 983.89it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  37%|███▋      | 3003/8192 [00:03<00:05, 1007.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  38%|███▊      | 3116/8192 [00:03<00:05, 992.33it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  37%|███▋      | 3000/8192 [00:03<00:05, 995.41it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  38%|███▊      | 3117/8192 [00:03<00:05, 992.40it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  38%|███▊      | 3109/8192 [00:03<00:05, 981.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  38%|███▊      | 3111/8192 [00:03<00:05, 987.07it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  38%|███▊      | 3107/8192 [00:03<00:05, 978.31it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  39%|███▉      | 3222/8192 [00:03<00:05, 982.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  38%|███▊      | 3120/8192 [00:03<00:05, 998.51it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  39%|███▉      | 3226/8192 [00:03<00:05, 989.39it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  39%|███▉      | 3227/8192 [00:03<00:05, 989.59it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  38%|███▊      | 3115/8192 [00:03<00:05, 988.43it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  39%|███▉      | 3218/8192 [00:03<00:05, 982.92it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  39%|███▉      | 3220/8192 [00:03<00:05, 983.62it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  39%|███▉      | 3216/8192 [00:03<00:05, 975.74it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  41%|████      | 3328/8192 [00:03<00:04, 980.17it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  39%|███▉      | 3231/8192 [00:03<00:04, 994.60it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  39%|███▉      | 3225/8192 [00:03<00:05, 983.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  41%|████      | 3324/8192 [00:03<00:04, 982.52it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  41%|████      | 3326/8192 [00:03<00:04, 981.19it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  41%|████      | 3321/8192 [00:03<00:04, 974.24it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  42%|████▏     | 3431/8192 [00:04<00:09, 520.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  41%|████      | 3332/8192 [00:03<00:09, 489.31it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  41%|████      | 3333/8192 [00:04<00:09, 488.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  42%|████▏     | 3428/8192 [00:04<00:09, 520.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  42%|████▏     | 3429/8192 [00:04<00:09, 521.02it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  42%|████▏     | 3424/8192 [00:04<00:09, 511.80it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  48%|████▊     | 3951/8192 [00:04<00:03, 1217.35it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  41%|████      | 3338/8192 [00:03<00:09, 494.47it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  48%|████▊     | 3949/8192 [00:04<00:03, 1237.43it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  48%|████▊     | 3949/8192 [00:04<00:03, 1235.23it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  41%|████      | 3331/8192 [00:04<00:10, 483.89it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  48%|████▊     | 3950/8192 [00:04<00:03, 1219.85it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  48%|████▊     | 3951/8192 [00:04<00:03, 1223.13it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  48%|████▊     | 3950/8192 [00:04<00:03, 1212.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  48%|████▊     | 3950/8192 [00:04<00:03, 1239.65it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  48%|████▊     | 3948/8192 [00:04<00:03, 1226.98it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  51%|█████     | 4161/8192 [00:04<00:03, 1190.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  51%|█████     | 4190/8192 [00:04<00:03, 1207.12it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  51%|█████     | 4190/8192 [00:04<00:03, 1207.38it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  51%|█████     | 4162/8192 [00:04<00:03, 1191.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  51%|█████     | 4163/8192 [00:04<00:03, 1197.03it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  51%|█████     | 4163/8192 [00:04<00:03, 1186.54it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  51%|█████     | 4191/8192 [00:04<00:03, 1214.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  53%|█████▎    | 4342/8192 [00:04<00:03, 1191.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  51%|█████     | 4189/8192 [00:04<00:03, 1202.35it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  53%|█████▎    | 4344/8192 [00:04<00:03, 1194.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  54%|█████▎    | 4392/8192 [00:04<00:03, 1208.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  53%|█████▎    | 4346/8192 [00:04<00:03, 1196.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  54%|█████▎    | 4393/8192 [00:04<00:03, 1205.43it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  53%|█████▎    | 4346/8192 [00:04<00:03, 1188.78it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  55%|█████▍    | 4505/8192 [00:04<00:03, 1197.90it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  54%|█████▎    | 4394/8192 [00:04<00:03, 1213.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  55%|█████▌    | 4508/8192 [00:04<00:03, 1202.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  54%|█████▎    | 4392/8192 [00:04<00:03, 1200.68it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  55%|█████▌    | 4510/8192 [00:04<00:03, 1203.43it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  56%|█████▌    | 4570/8192 [00:04<00:02, 1215.89it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  56%|█████▌    | 4571/8192 [00:04<00:02, 1211.44it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  55%|█████▌    | 4510/8192 [00:04<00:03, 1195.63it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  57%|█████▋    | 4656/8192 [00:04<00:02, 1215.82it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  56%|█████▌    | 4572/8192 [00:04<00:02, 1219.96it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  57%|█████▋    | 4660/8192 [00:04<00:02, 1219.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  57%|█████▋    | 4662/8192 [00:04<00:02, 1220.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  58%|█████▊    | 4732/8192 [00:04<00:02, 1246.10it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  58%|█████▊    | 4733/8192 [00:04<00:02, 1241.00it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  56%|█████▌    | 4570/8192 [00:04<00:03, 1205.06it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  57%|█████▋    | 4661/8192 [00:04<00:02, 1213.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  59%|█████▊    | 4800/8192 [00:04<00:02, 1251.44it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  59%|█████▊    | 4805/8192 [00:04<00:02, 1249.97it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  58%|█████▊    | 4734/8192 [00:04<00:02, 1250.91it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  59%|█████▊    | 4807/8192 [00:04<00:02, 1254.45it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  60%|█████▉    | 4886/8192 [00:04<00:02, 1275.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  60%|█████▉    | 4887/8192 [00:04<00:02, 1272.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  59%|█████▊    | 4805/8192 [00:04<00:02, 1247.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  58%|█████▊    | 4731/8192 [00:04<00:02, 1229.94it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  60%|██████    | 4942/8192 [00:04<00:02, 1282.03it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  60%|██████    | 4947/8192 [00:04<00:02, 1279.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  60%|██████    | 4949/8192 [00:04<00:02, 1283.87it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  60%|█████▉    | 4889/8192 [00:04<00:02, 1278.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  61%|██████▏   | 5035/8192 [00:04<00:02, 1306.41it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  60%|██████    | 4947/8192 [00:04<00:02, 1275.84it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  61%|██████▏   | 5036/8192 [00:04<00:02, 1303.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  62%|██████▏   | 5083/8192 [00:05<00:02, 1310.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  60%|█████▉    | 4884/8192 [00:04<00:02, 1261.37it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  62%|██████▏   | 5088/8192 [00:05<00:02, 1311.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  62%|██████▏   | 5090/8192 [00:05<00:02, 1313.84it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  62%|██████▏   | 5039/8192 [00:04<00:02, 1307.64it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  62%|██████▏   | 5088/8192 [00:05<00:02, 1305.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  61%|██████▏   | 5032/8192 [00:04<00:02, 1291.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  64%|██████▍   | 5224/8192 [00:05<00:03, 804.02it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  63%|██████▎   | 5182/8192 [00:05<00:03, 803.13it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  63%|██████▎   | 5183/8192 [00:05<00:03, 805.29it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  64%|██████▍   | 5229/8192 [00:05<00:03, 808.92it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  64%|██████▍   | 5231/8192 [00:05<00:03, 812.73it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  64%|██████▍   | 5228/8192 [00:05<00:03, 806.91it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  63%|██████▎   | 5186/8192 [00:05<00:03, 812.84it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  71%|███████   | 5801/8192 [00:05<00:01, 1718.52it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  71%|███████   | 5803/8192 [00:05<00:01, 1714.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  71%|███████   | 5800/8192 [00:05<00:01, 1712.13it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  63%|██████▎   | 5178/8192 [00:05<00:03, 793.83it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  71%|███████   | 5802/8192 [00:05<00:01, 1719.03it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  71%|███████   | 5803/8192 [00:05<00:01, 1722.38it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  71%|███████   | 5801/8192 [00:05<00:01, 1716.82it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  71%|███████   | 5803/8192 [00:05<00:01, 1723.98it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  74%|███████▍  | 6051/8192 [00:05<00:01, 1743.85it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  71%|███████   | 5801/8192 [00:05<00:01, 1705.17it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  74%|███████▍  | 6069/8192 [00:05<00:01, 1748.84it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  74%|███████▍  | 6065/8192 [00:05<00:01, 1741.07it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  74%|███████▍  | 6052/8192 [00:05<00:01, 1750.40it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  74%|███████▍  | 6052/8192 [00:05<00:01, 1748.79it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  74%|███████▍  | 6050/8192 [00:05<00:01, 1743.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  74%|███████▍  | 6068/8192 [00:05<00:01, 1753.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  77%|███████▋  | 6281/8192 [00:05<00:01, 1798.07it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  77%|███████▋  | 6311/8192 [00:05<00:01, 1804.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  77%|███████▋  | 6305/8192 [00:05<00:01, 1794.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  74%|███████▍  | 6067/8192 [00:05<00:01, 1735.74it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  77%|███████▋  | 6282/8192 [00:05<00:01, 1797.94it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  77%|███████▋  | 6281/8192 [00:05<00:01, 1800.75it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  77%|███████▋  | 6279/8192 [00:05<00:01, 1789.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  79%|███████▉  | 6501/8192 [00:05<00:00, 1875.45it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  77%|███████▋  | 6309/8192 [00:05<00:01, 1809.82it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  80%|███████▉  | 6540/8192 [00:05<00:00, 1893.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  80%|███████▉  | 6532/8192 [00:05<00:00, 1880.03it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  79%|███████▉  | 6500/8192 [00:05<00:00, 1878.50it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  79%|███████▉  | 6501/8192 [00:05<00:00, 1873.46it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  77%|███████▋  | 6308/8192 [00:05<00:01, 1786.59it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  79%|███████▉  | 6497/8192 [00:05<00:00, 1862.45it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  82%|████████▏ | 6739/8192 [00:05<00:00, 1998.38it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  80%|███████▉  | 6537/8192 [00:05<00:00, 1894.10it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  83%|████████▎ | 6784/8192 [00:05<00:00, 2020.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  83%|████████▎ | 6774/8192 [00:05<00:00, 2005.57it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  82%|████████▏ | 6739/8192 [00:05<00:00, 2002.94it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  82%|████████▏ | 6739/8192 [00:05<00:00, 1997.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  80%|███████▉  | 6535/8192 [00:05<00:00, 1871.54it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  82%|████████▏ | 6733/8192 [00:05<00:00, 1984.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  83%|████████▎ | 6779/8192 [00:05<00:00, 2017.73it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  83%|████████▎ | 6775/8192 [00:05<00:00, 1994.98it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  86%|████████▌ | 7015/8192 [00:06<00:00, 1626.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  85%|████████▍ | 6963/8192 [00:06<00:00, 1532.82it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  85%|████████▌ | 7004/8192 [00:06<00:00, 1606.97it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  85%|████████▍ | 6963/8192 [00:06<00:00, 1535.37it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  85%|████████▍ | 6963/8192 [00:06<00:00, 1532.54it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  85%|████████▍ | 6955/8192 [00:06<00:00, 1512.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  86%|████████▌ | 7009/8192 [00:06<00:00, 1623.10it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  91%|█████████ | 7425/8192 [00:06<00:00, 2107.44it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  91%|█████████ | 7425/8192 [00:06<00:00, 2128.49it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  91%|█████████ | 7425/8192 [00:06<00:00, 2109.90it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  85%|████████▌ | 7004/8192 [00:06<00:00, 1598.65it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  91%|█████████ | 7425/8192 [00:06<00:00, 2139.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  91%|█████████ | 7425/8192 [00:06<00:00, 2136.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  91%|█████████ | 7425/8192 [00:06<00:00, 2123.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  91%|█████████ | 7425/8192 [00:06<00:00, 2127.73it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  99%|█████████▉| 8129/8192 [00:06<00:00, 3194.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])): 100%|██████████| 8192/8192 [00:06<00:00, 1290.95it/s]
[1;36m(EngineCore_DP4 pid=178305)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  99%|█████████▉| 8129/8192 [00:06<00:00, 3194.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])): 100%|██████████| 8192/8192 [00:06<00:00, 1283.10it/s]
[1;36m(EngineCore_DP3 pid=178304)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  99%|█████████▉| 8129/8192 [00:06<00:00, 3192.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])): 100%|██████████| 8192/8192 [00:06<00:00, 1287.51it/s]
[1;36m(EngineCore_DP5 pid=178306)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  91%|█████████ | 7425/8192 [00:06<00:00, 2101.78it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  99%|█████████▉| 8129/8192 [00:06<00:00, 3207.47it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  99%|█████████▉| 8129/8192 [00:06<00:00, 3206.09it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])): 100%|██████████| 8192/8192 [00:06<00:00, 1280.16it/s]
DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])): 100%|██████████| 8192/8192 [00:06<00:00, 1282.04it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):   0%|          | 0/8192 [00:00<?, ?it/s][1;36m(EngineCore_DP6 pid=178307)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  99%|█████████▉| 8129/8192 [00:06<00:00, 3209.40it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])): 100%|██████████| 8192/8192 [00:06<00:00, 1297.89it/s]
DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  99%|█████████▉| 8129/8192 [00:06<00:00, 3195.56it/s][1;36m(EngineCore_DP1 pid=178302)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])): 100%|██████████| 8192/8192 [00:06<00:00, 1273.58it/s]
[1;36m(EngineCore_DP2 pid=178303)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  14%|█▎        | 1119/8192 [00:00<00:00, 11185.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  14%|█▎        | 1116/8192 [00:00<00:00, 11151.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  14%|█▎        | 1121/8192 [00:00<00:00, 11196.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])):  99%|█████████▉| 8129/8192 [00:06<00:00, 3183.63it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 16384])): 100%|██████████| 8192/8192 [00:06<00:00, 1284.84it/s]
[1;36m(EngineCore_DP7 pid=178308)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  14%|█▎        | 1122/8192 [00:00<00:00, 11212.15it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  14%|█▎        | 1118/8192 [00:00<00:00, 11169.23it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  14%|█▎        | 1123/8192 [00:00<00:00, 11216.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  14%|█▎        | 1115/8192 [00:00<00:00, 11133.10it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  14%|█▎        | 1120/8192 [00:00<00:00, 11194.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  27%|██▋       | 2238/8192 [00:00<00:00, 8116.87it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  27%|██▋       | 2232/8192 [00:00<00:00, 8098.94it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  27%|██▋       | 2241/8192 [00:00<00:00, 8120.91it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  27%|██▋       | 2244/8192 [00:00<00:00, 8142.19it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  27%|██▋       | 2235/8192 [00:00<00:00, 7962.36it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  27%|██▋       | 2245/8192 [00:00<00:00, 8138.10it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  27%|██▋       | 2229/8192 [00:00<00:00, 8094.53it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  38%|███▊      | 3100/8192 [00:00<00:00, 7955.44it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  38%|███▊      | 3091/8192 [00:00<00:00, 7932.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  38%|███▊      | 3103/8192 [00:00<00:00, 7938.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  27%|██▋       | 2240/8192 [00:00<00:00, 8104.41it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  38%|███▊      | 3108/8192 [00:00<00:00, 7982.10it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  38%|███▊      | 3085/8192 [00:00<00:00, 7850.94it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  38%|███▊      | 3109/8192 [00:00<00:00, 7976.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  38%|███▊      | 3088/8192 [00:00<00:00, 7907.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  49%|████▊     | 3988/8192 [00:00<00:00, 8270.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  48%|████▊     | 3954/8192 [00:00<00:00, 8170.67it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  49%|████▊     | 3989/8192 [00:00<00:00, 8250.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  38%|███▊      | 3101/8192 [00:00<00:00, 7928.85it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  49%|████▉     | 3995/8192 [00:00<00:00, 8284.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  48%|████▊     | 3898/8192 [00:00<00:00, 7888.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  49%|████▉     | 4001/8192 [00:00<00:00, 8296.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  48%|████▊     | 3903/8192 [00:00<00:00, 7903.67it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  61%|██████▏   | 5024/8192 [00:00<00:00, 8955.02it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  61%|██████    | 4962/8192 [00:00<00:00, 8796.12it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  62%|██████▏   | 5051/8192 [00:00<00:00, 9023.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  48%|████▊     | 3956/8192 [00:00<00:00, 8140.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  62%|██████▏   | 5056/8192 [00:00<00:00, 9045.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  59%|█████▉    | 4872/8192 [00:00<00:00, 8490.02it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  62%|██████▏   | 5042/8192 [00:00<00:00, 8988.66it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  59%|█████▉    | 4874/8192 [00:00<00:00, 8490.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  74%|███████▎  | 6030/8192 [00:00<00:00, 9307.38it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  73%|███████▎  | 5968/8192 [00:00<00:00, 9198.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  74%|███████▍  | 6071/8192 [00:00<00:00, 9398.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  60%|██████    | 4950/8192 [00:00<00:00, 8728.91it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  74%|███████▍  | 6085/8192 [00:00<00:00, 9442.38it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  72%|███████▏  | 5889/8192 [00:00<00:00, 9017.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  75%|███████▍  | 6132/8192 [00:00<00:00, 9597.47it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  72%|███████▏  | 5889/8192 [00:00<00:00, 8955.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  92%|█████████▏| 7553/8192 [00:00<00:00, 11052.49it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  92%|█████████▏| 7553/8192 [00:00<00:00, 11199.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  92%|█████████▏| 7571/8192 [00:00<00:00, 11149.43it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  73%|███████▎  | 5957/8192 [00:00<00:00, 9155.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  93%|█████████▎| 7605/8192 [00:00<00:00, 11244.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  92%|█████████▏| 7553/8192 [00:00<00:00, 11191.65it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  92%|█████████▏| 7553/8192 [00:00<00:00, 10984.73it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  92%|█████████▏| 7553/8192 [00:00<00:00, 11231.92it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])): 100%|██████████| 8192/8192 [00:00<00:00, 9186.39it/s] 
[1;36m(EngineCore_DP4 pid=178305)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])): 100%|██████████| 8192/8192 [00:00<00:00, 9195.65it/s] 
[1;36m(EngineCore_DP3 pid=178304)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])): 100%|██████████| 8192/8192 [00:00<00:00, 9226.36it/s] 
[1;36m(EngineCore_DP5 pid=178306)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])):  92%|█████████▏| 7553/8192 [00:00<00:00, 11168.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])): 100%|██████████| 8192/8192 [00:00<00:00, 9249.85it/s] 
[1;36m(EngineCore_DP0 pid=178301)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])): 100%|██████████| 8192/8192 [00:00<00:00, 9097.57it/s] 
[1;36m(EngineCore_DP6 pid=178307)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])): 100%|██████████| 8192/8192 [00:00<00:00, 9189.43it/s] 
[1;36m(EngineCore_DP1 pid=178302)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])): 100%|██████████| 8192/8192 [00:00<00:00, 9133.20it/s] 
[1;36m(EngineCore_DP2 pid=178303)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):   6%|▋         | 513/8192 [00:00<00:01, 4773.19it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):   6%|▋         | 513/8192 [00:00<00:01, 4709.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):   6%|▋         | 513/8192 [00:00<00:01, 4783.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([8192, 1536])): 100%|██████████| 8192/8192 [00:00<00:00, 9192.84it/s] 
[1;36m(EngineCore_DP7 pid=178308)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):   6%|▋         | 513/8192 [00:00<00:01, 4802.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):   6%|▋         | 513/8192 [00:00<00:01, 4766.23it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):   6%|▋         | 513/8192 [00:00<00:01, 4622.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):   6%|▋         | 513/8192 [00:00<00:01, 4799.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  13%|█▎        | 1025/8192 [00:00<00:01, 4732.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  13%|█▎        | 1025/8192 [00:00<00:01, 4667.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  13%|█▎        | 1025/8192 [00:00<00:01, 4767.75it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):   6%|▋         | 513/8192 [00:00<00:01, 4718.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  13%|█▎        | 1025/8192 [00:00<00:01, 4758.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  13%|█▎        | 1025/8192 [00:00<00:01, 4753.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  13%|█▎        | 1025/8192 [00:00<00:01, 4651.91it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  13%|█▎        | 1025/8192 [00:00<00:01, 4785.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  19%|█▉        | 1537/8192 [00:00<00:01, 4742.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  19%|█▉        | 1537/8192 [00:00<00:01, 4771.15it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  19%|█▉        | 1537/8192 [00:00<00:01, 4658.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  13%|█▎        | 1025/8192 [00:00<00:01, 4757.62it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  19%|█▉        | 1537/8192 [00:00<00:01, 4772.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  19%|█▉        | 1537/8192 [00:00<00:01, 4773.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  19%|█▉        | 1537/8192 [00:00<00:01, 4793.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  19%|█▉        | 1537/8192 [00:00<00:01, 4667.84it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  25%|██▌       | 2049/8192 [00:00<00:01, 4753.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  25%|██▌       | 2049/8192 [00:00<00:01, 4784.14it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  25%|██▌       | 2049/8192 [00:00<00:01, 4664.45it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  19%|█▉        | 1537/8192 [00:00<00:01, 4767.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  25%|██▌       | 2049/8192 [00:00<00:01, 4794.97it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  25%|██▌       | 2049/8192 [00:00<00:01, 4774.54it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  25%|██▌       | 2049/8192 [00:00<00:01, 4789.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  25%|██▌       | 2049/8192 [00:00<00:01, 4699.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  31%|███▏      | 2561/8192 [00:00<00:01, 4776.14it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  31%|███▏      | 2561/8192 [00:00<00:01, 4794.10it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  31%|███▏      | 2561/8192 [00:00<00:01, 4685.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  25%|██▌       | 2049/8192 [00:00<00:01, 4780.63it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  31%|███▏      | 2561/8192 [00:00<00:01, 4808.92it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  31%|███▏      | 2561/8192 [00:00<00:01, 4783.91it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  31%|███▏      | 2561/8192 [00:00<00:01, 4797.80it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  31%|███▏      | 2561/8192 [00:00<00:01, 4721.98it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  41%|████      | 3329/8192 [00:00<00:00, 5498.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  41%|████      | 3329/8192 [00:00<00:00, 5489.10it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  41%|████      | 3329/8192 [00:00<00:00, 5382.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  31%|███▏      | 2561/8192 [00:00<00:01, 4800.89it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  41%|████      | 3329/8192 [00:00<00:00, 5529.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  41%|████      | 3329/8192 [00:00<00:00, 5494.79it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  41%|████      | 3329/8192 [00:00<00:00, 5526.39it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  41%|████      | 3329/8192 [00:00<00:00, 5455.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  49%|████▉     | 4033/8192 [00:00<00:00, 5754.85it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  49%|████▉     | 4033/8192 [00:00<00:00, 5745.89it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  49%|████▉     | 4033/8192 [00:00<00:00, 5646.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  41%|████      | 3329/8192 [00:00<00:00, 5512.36it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  49%|████▉     | 4033/8192 [00:00<00:00, 5793.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  49%|████▉     | 4033/8192 [00:00<00:00, 5783.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  49%|████▉     | 4033/8192 [00:00<00:00, 5807.41it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  49%|████▉     | 4033/8192 [00:00<00:00, 5746.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  56%|█████▌    | 4607/8192 [00:00<00:00, 5615.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  56%|█████▌    | 4606/8192 [00:00<00:00, 5615.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  56%|█████▌    | 4596/8192 [00:00<00:00, 5482.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  49%|████▉     | 4033/8192 [00:00<00:00, 5765.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  56%|█████▋    | 4611/8192 [00:00<00:00, 5418.07it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  56%|█████▋    | 4610/8192 [00:00<00:00, 5402.35it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  56%|█████▌    | 4607/8192 [00:00<00:00, 5619.62it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  56%|█████▋    | 4612/8192 [00:00<00:00, 5439.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  63%|██████▎   | 5168/8192 [00:00<00:00, 5266.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  63%|██████▎   | 5166/8192 [00:00<00:00, 5263.44it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  56%|█████▋    | 4608/8192 [00:00<00:00, 5620.47it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  63%|██████▎   | 5143/8192 [00:01<00:00, 5090.97it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  63%|██████▎   | 5155/8192 [00:00<00:00, 5329.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  63%|██████▎   | 5152/8192 [00:00<00:00, 5308.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  63%|██████▎   | 5158/8192 [00:00<00:00, 5346.85it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  63%|██████▎   | 5168/8192 [00:00<00:00, 5267.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  70%|██████▉   | 5694/8192 [00:01<00:00, 4811.63it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  70%|██████▉   | 5697/8192 [00:01<00:00, 4610.46it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  69%|██████▉   | 5655/8192 [00:01<00:00, 4647.43it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  63%|██████▎   | 5169/8192 [00:01<00:00, 5045.13it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  69%|██████▉   | 5689/8192 [00:01<00:00, 4801.82it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  69%|██████▉   | 5684/8192 [00:01<00:00, 4804.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  70%|██████▉   | 5694/8192 [00:01<00:00, 4888.63it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  70%|██████▉   | 5697/8192 [00:01<00:00, 4597.73it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  75%|███████▌  | 6171/8192 [00:01<00:00, 4392.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  75%|███████▌  | 6181/8192 [00:01<00:00, 4387.74it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  75%|███████▍  | 6126/8192 [00:01<00:00, 4409.02it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  69%|██████▉   | 5681/8192 [00:01<00:00, 4773.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  75%|███████▌  | 6177/8192 [00:01<00:00, 4368.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  75%|███████▌  | 6172/8192 [00:01<00:00, 4378.82it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  76%|███████▌  | 6189/8192 [00:01<00:00, 4459.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  75%|███████▌  | 6170/8192 [00:01<00:00, 4384.47it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  81%|████████  | 6619/8192 [00:01<00:00, 4187.87it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  81%|████████  | 6628/8192 [00:01<00:00, 4196.60it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  80%|████████  | 6571/8192 [00:01<00:00, 4180.15it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  75%|███████▌  | 6164/8192 [00:01<00:00, 4359.64it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  81%|████████  | 6624/8192 [00:01<00:00, 4175.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  81%|████████  | 6619/8192 [00:01<00:00, 4183.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  81%|████████  | 6643/8192 [00:01<00:00, 4254.49it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  81%|████████  | 6618/8192 [00:01<00:00, 4183.13it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  86%|████████▌ | 7044/8192 [00:01<00:00, 4004.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  86%|████████▌ | 7053/8192 [00:01<00:00, 4015.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  85%|████████▌ | 6992/8192 [00:01<00:00, 3976.55it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  81%|████████  | 6608/8192 [00:01<00:00, 4164.85it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  86%|████████▌ | 7048/8192 [00:01<00:00, 3989.89it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  86%|████████▌ | 7043/8192 [00:01<00:00, 3998.97it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  86%|████████▋ | 7074/8192 [00:01<00:00, 4061.18it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  86%|████████▌ | 7042/8192 [00:01<00:00, 4001.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  91%|█████████ | 7448/8192 [00:01<00:00, 3976.82it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  91%|█████████ | 7458/8192 [00:01<00:00, 3996.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  90%|█████████ | 7392/8192 [00:01<00:00, 3948.17it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  86%|████████▌ | 7030/8192 [00:01<00:00, 4143.12it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  91%|█████████ | 7451/8192 [00:01<00:00, 3970.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  91%|█████████ | 7447/8192 [00:01<00:00, 3981.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  91%|█████████▏| 7484/8192 [00:01<00:00, 4041.66it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  91%|█████████ | 7446/8192 [00:01<00:00, 3979.18it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  96%|█████████▌| 7848/8192 [00:01<00:00, 3781.54it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  96%|█████████▌| 7860/8192 [00:01<00:00, 3819.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  95%|█████████▌| 7788/8192 [00:01<00:00, 3759.40it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  91%|█████████ | 7448/8192 [00:01<00:00, 3944.00it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  96%|█████████▌| 7851/8192 [00:01<00:00, 3796.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  96%|█████████▌| 7848/8192 [00:01<00:00, 3792.18it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])): 100%|██████████| 8192/8192 [00:01<00:00, 4513.94it/s]
[1;36m(EngineCore_DP4 pid=178305)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])): 100%|██████████| 8192/8192 [00:01<00:00, 4535.90it/s]
[1;36m(EngineCore_DP5 pid=178306)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  96%|█████████▌| 7847/8192 [00:01<00:00, 3800.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  96%|█████████▋| 7891/8192 [00:01<00:00, 3705.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])): 100%|█████████▉| 8165/8192 [00:01<00:00, 3729.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])): 100%|██████████| 8192/8192 [00:01<00:00, 4457.69it/s]
[1;36m(EngineCore_DP3 pid=178304)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])): 100%|██████████| 8192/8192 [00:01<00:00, 4524.11it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])): 100%|██████████| 8192/8192 [00:01<00:00, 4519.35it/s]
[1;36m(EngineCore_DP6 pid=178307)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])):  96%|█████████▌| 7845/8192 [00:01<00:00, 3756.50it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])): 100%|██████████| 8192/8192 [00:01<00:00, 4546.33it/s]
[1;36m(EngineCore_DP2 pid=178303)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])): 100%|██████████| 8192/8192 [00:01<00:00, 4498.73it/s]
[1;36m(EngineCore_DP1 pid=178302)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):   7%|▋         | 543/8192 [00:00<00:01, 5309.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):   7%|▋         | 544/8192 [00:00<00:01, 5284.90it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):   7%|▋         | 543/8192 [00:00<00:01, 5263.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):   7%|▋         | 543/8192 [00:00<00:01, 5398.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([128, 7168])): 100%|██████████| 8192/8192 [00:01<00:00, 4510.26it/s]
[1;36m(EngineCore_DP7 pid=178308)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):   7%|▋         | 543/8192 [00:00<00:01, 5315.19it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):   7%|▋         | 544/8192 [00:00<00:01, 5278.91it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):   7%|▋         | 543/8192 [00:00<00:01, 5297.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):   7%|▋         | 543/8192 [00:00<00:01, 5284.67it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  13%|█▎        | 1073/8192 [00:01<00:13, 517.38it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  13%|█▎        | 1074/8192 [00:01<00:13, 517.24it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  13%|█▎        | 1070/8192 [00:01<00:13, 514.62it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  13%|█▎        | 1075/8192 [00:01<00:13, 514.06it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  13%|█▎        | 1083/8192 [00:01<00:13, 510.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  13%|█▎        | 1073/8192 [00:01<00:13, 518.52it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  13%|█▎        | 1072/8192 [00:01<00:13, 512.79it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  13%|█▎        | 1072/8192 [00:01<00:13, 515.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  16%|█▌        | 1312/8192 [00:02<00:15, 445.67it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  16%|█▌        | 1310/8192 [00:02<00:15, 444.60it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  16%|█▌        | 1306/8192 [00:02<00:15, 442.12it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  16%|█▌        | 1310/8192 [00:02<00:15, 447.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  16%|█▌        | 1313/8192 [00:02<00:15, 441.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  16%|█▌        | 1324/8192 [00:02<00:15, 440.59it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  16%|█▌        | 1308/8192 [00:02<00:15, 440.64it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  16%|█▌        | 1309/8192 [00:02<00:15, 444.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  18%|█▊        | 1456/8192 [00:02<00:16, 419.97it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  18%|█▊        | 1454/8192 [00:02<00:16, 417.45it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  18%|█▊        | 1449/8192 [00:02<00:16, 415.76it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  18%|█▊        | 1454/8192 [00:02<00:16, 421.03it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  18%|█▊        | 1457/8192 [00:02<00:16, 415.39it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  18%|█▊        | 1451/8192 [00:02<00:16, 413.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  18%|█▊        | 1470/8192 [00:03<00:16, 413.39it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  18%|█▊        | 1453/8192 [00:02<00:16, 418.74it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  19%|█▉        | 1557/8192 [00:03<00:16, 403.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  19%|█▉        | 1554/8192 [00:03<00:16, 401.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  19%|█▉        | 1549/8192 [00:03<00:16, 399.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  19%|█▉        | 1555/8192 [00:03<00:16, 404.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  19%|█▉        | 1557/8192 [00:03<00:16, 399.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  19%|█▉        | 1551/8192 [00:03<00:16, 398.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  19%|█▉        | 1571/8192 [00:03<00:16, 399.12it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  19%|█▉        | 1553/8192 [00:03<00:16, 402.46it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  20%|█▉        | 1634/8192 [00:03<00:16, 394.73it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  20%|█▉        | 1630/8192 [00:03<00:16, 392.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  20%|█▉        | 1625/8192 [00:03<00:16, 391.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  20%|█▉        | 1632/8192 [00:03<00:16, 395.35it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  20%|█▉        | 1633/8192 [00:03<00:16, 391.63it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  20%|█▉        | 1627/8192 [00:03<00:16, 390.18it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  20%|██        | 1648/8192 [00:03<00:16, 389.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  20%|█▉        | 1629/8192 [00:03<00:16, 393.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  21%|██        | 1697/8192 [00:03<00:16, 387.78it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  21%|██        | 1692/8192 [00:03<00:16, 385.76it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  21%|██        | 1687/8192 [00:03<00:16, 384.17it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  21%|██        | 1695/8192 [00:03<00:16, 388.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  21%|██        | 1696/8192 [00:03<00:16, 385.09it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  21%|██        | 1689/8192 [00:03<00:16, 383.50it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  21%|██        | 1711/8192 [00:03<00:16, 381.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  21%|██        | 1691/8192 [00:03<00:16, 386.15it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  21%|██▏       | 1751/8192 [00:03<00:16, 381.98it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  21%|██▏       | 1746/8192 [00:03<00:17, 378.54it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  21%|██        | 1740/8192 [00:03<00:17, 377.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  21%|██▏       | 1749/8192 [00:03<00:16, 381.74it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  21%|██▏       | 1750/8192 [00:03<00:17, 377.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  21%|██▏       | 1742/8192 [00:03<00:17, 376.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  22%|██▏       | 1765/8192 [00:03<00:17, 374.96it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  22%|██▏       | 1799/8192 [00:03<00:17, 375.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  21%|██▏       | 1745/8192 [00:03<00:16, 379.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  22%|██▏       | 1794/8192 [00:03<00:17, 371.24it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  22%|██▏       | 1787/8192 [00:03<00:17, 370.10it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  22%|██▏       | 1797/8192 [00:03<00:17, 376.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  22%|██▏       | 1798/8192 [00:03<00:17, 370.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  22%|██▏       | 1789/8192 [00:03<00:17, 368.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  22%|██▏       | 1843/8192 [00:04<00:17, 371.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  22%|██▏       | 1813/8192 [00:04<00:17, 370.90it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  22%|██▏       | 1837/8192 [00:04<00:17, 368.79it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  22%|██▏       | 1793/8192 [00:03<00:17, 373.23it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  22%|██▏       | 1830/8192 [00:04<00:17, 366.89it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  22%|██▏       | 1841/8192 [00:04<00:17, 373.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  22%|██▏       | 1842/8192 [00:04<00:17, 367.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  22%|██▏       | 1832/8192 [00:04<00:17, 365.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  23%|██▎       | 1884/8192 [00:04<00:17, 368.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  23%|██▎       | 1878/8192 [00:04<00:17, 366.97it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  23%|██▎       | 1857/8192 [00:04<00:17, 368.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  22%|██▏       | 1837/8192 [00:04<00:17, 370.12it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  23%|██▎       | 1871/8192 [00:04<00:17, 364.75it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  23%|██▎       | 1883/8192 [00:04<00:17, 370.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  23%|██▎       | 1883/8192 [00:04<00:17, 364.79it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  23%|██▎       | 1873/8192 [00:04<00:17, 363.72it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  23%|██▎       | 1924/8192 [00:04<00:17, 367.07it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  23%|██▎       | 1918/8192 [00:04<00:17, 366.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  23%|██▎       | 1899/8192 [00:04<00:17, 367.54it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  23%|██▎       | 1910/8192 [00:04<00:17, 364.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  23%|██▎       | 1878/8192 [00:04<00:17, 367.98it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  23%|██▎       | 1923/8192 [00:04<00:17, 368.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  23%|██▎       | 1923/8192 [00:04<00:17, 364.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  23%|██▎       | 1912/8192 [00:04<00:17, 363.91it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  24%|██▍       | 1963/8192 [00:04<00:16, 366.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  24%|██▍       | 1957/8192 [00:04<00:17, 365.91it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  24%|██▎       | 1939/8192 [00:04<00:17, 365.72it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  24%|██▍       | 1949/8192 [00:04<00:17, 363.67it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  23%|██▎       | 1918/8192 [00:04<00:17, 366.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  24%|██▍       | 1962/8192 [00:04<00:16, 367.19it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  24%|██▍       | 1962/8192 [00:04<00:17, 365.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  24%|██▍       | 2001/8192 [00:04<00:16, 366.41it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  24%|██▍       | 1951/8192 [00:04<00:17, 364.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  24%|██▍       | 1995/8192 [00:04<00:16, 365.45it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  24%|██▍       | 1978/8192 [00:04<00:17, 364.03it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  24%|██▍       | 1987/8192 [00:04<00:17, 363.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  24%|██▍       | 1957/8192 [00:04<00:17, 366.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  24%|██▍       | 2000/8192 [00:04<00:16, 367.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  24%|██▍       | 2000/8192 [00:04<00:16, 365.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  25%|██▍       | 2039/8192 [00:04<00:16, 366.75it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  24%|██▍       | 1989/8192 [00:04<00:17, 364.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  25%|██▍       | 2033/8192 [00:04<00:16, 364.85it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  25%|██▍       | 2016/8192 [00:04<00:17, 361.98it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  25%|██▍       | 2025/8192 [00:04<00:16, 363.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  24%|██▍       | 1995/8192 [00:04<00:16, 365.46it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  25%|██▍       | 2038/8192 [00:04<00:16, 366.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  25%|██▍       | 2038/8192 [00:04<00:16, 365.18it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  25%|██▌       | 2077/8192 [00:04<00:16, 369.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  25%|██▍       | 2027/8192 [00:04<00:16, 364.06it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  25%|██▌       | 2071/8192 [00:04<00:16, 365.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  25%|██▌       | 2054/8192 [00:04<00:16, 361.92it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  25%|██▌       | 2062/8192 [00:04<00:16, 363.46it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  25%|██▍       | 2033/8192 [00:04<00:16, 364.65it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  25%|██▌       | 2076/8192 [00:04<00:16, 369.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  25%|██▌       | 2076/8192 [00:04<00:16, 366.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  26%|██▌       | 2115/8192 [00:04<00:16, 371.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  26%|██▌       | 2108/8192 [00:04<00:16, 365.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  25%|██▌       | 2065/8192 [00:04<00:16, 363.90it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  26%|██▌       | 2092/8192 [00:04<00:16, 365.02it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  26%|██▌       | 2099/8192 [00:04<00:16, 364.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  25%|██▌       | 2071/8192 [00:04<00:16, 366.31it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  26%|██▌       | 2114/8192 [00:04<00:16, 370.87it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  26%|██▌       | 2114/8192 [00:04<00:16, 366.94it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  26%|██▋       | 2153/8192 [00:04<00:16, 371.18it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  26%|██▌       | 2145/8192 [00:04<00:16, 365.15it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  26%|██▌       | 2102/8192 [00:04<00:16, 364.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  26%|██▌       | 2130/8192 [00:04<00:16, 366.80it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  26%|██▌       | 2136/8192 [00:04<00:16, 365.46it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  26%|██▌       | 2109/8192 [00:04<00:16, 368.52it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  26%|██▋       | 2152/8192 [00:04<00:16, 372.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  26%|██▋       | 2152/8192 [00:04<00:16, 366.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2191/8192 [00:05<00:16, 370.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2183/8192 [00:05<00:16, 366.78it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  26%|██▌       | 2139/8192 [00:04<00:16, 363.87it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2173/8192 [00:05<00:16, 365.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  26%|██▋       | 2168/8192 [00:05<00:16, 368.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  26%|██▌       | 2147/8192 [00:04<00:16, 368.94it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2190/8192 [00:05<00:16, 373.64it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2189/8192 [00:05<00:16, 366.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2229/8192 [00:05<00:16, 369.87it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2176/8192 [00:05<00:16, 364.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2221/8192 [00:05<00:16, 368.35it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2210/8192 [00:05<00:16, 366.13it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2206/8192 [00:05<00:16, 369.86it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2185/8192 [00:05<00:16, 368.90it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2228/8192 [00:05<00:15, 373.72it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2226/8192 [00:05<00:16, 367.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  28%|██▊       | 2267/8192 [00:05<00:16, 370.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2213/8192 [00:05<00:16, 364.40it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  28%|██▊       | 2259/8192 [00:05<00:16, 370.68it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2247/8192 [00:05<00:16, 366.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2244/8192 [00:05<00:16, 371.50it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2223/8192 [00:05<00:16, 370.13it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  28%|██▊       | 2266/8192 [00:05<00:15, 373.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  28%|██▊       | 2264/8192 [00:05<00:16, 368.37it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  28%|██▊       | 2297/8192 [00:05<00:15, 372.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  27%|██▋       | 2251/8192 [00:05<00:16, 366.17it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  28%|██▊       | 2285/8192 [00:05<00:16, 368.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  28%|██▊       | 2282/8192 [00:05<00:15, 371.66it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  28%|██▊       | 2261/8192 [00:05<00:15, 371.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  28%|██▊       | 2304/8192 [00:05<00:15, 373.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  28%|██▊       | 2303/8192 [00:05<00:15, 372.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  28%|██▊       | 2289/8192 [00:05<00:15, 369.24it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  28%|██▊       | 2299/8192 [00:05<00:15, 372.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  28%|██▊       | 2305/8192 [00:06<01:14, 79.10it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  29%|██▊       | 2335/8192 [00:06<01:11, 82.12it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  29%|██▊       | 2342/8192 [00:06<01:09, 84.02it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  28%|██▊       | 2322/8192 [00:06<01:14, 79.01it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  35%|███▍      | 2858/8192 [00:06<00:10, 519.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  29%|██▊       | 2341/8192 [00:06<01:10, 83.42it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  28%|██▊       | 2320/8192 [00:06<01:13, 80.15it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  35%|███▍      | 2857/8192 [00:06<00:10, 514.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  28%|██▊       | 2326/8192 [00:06<01:13, 79.72it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  29%|██▊       | 2337/8192 [00:06<01:10, 82.72it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  35%|███▍      | 2859/8192 [00:06<00:10, 519.40it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  35%|███▍      | 2858/8192 [00:06<00:10, 514.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  35%|███▍      | 2857/8192 [00:06<00:10, 515.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  35%|███▍      | 2858/8192 [00:06<00:10, 512.86it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  35%|███▍      | 2857/8192 [00:06<00:10, 512.45it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  35%|███▍      | 2858/8192 [00:06<00:10, 515.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  37%|███▋      | 3043/8192 [00:07<00:10, 485.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  37%|███▋      | 3032/8192 [00:07<00:10, 481.67it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  37%|███▋      | 3031/8192 [00:07<00:10, 487.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  37%|███▋      | 3035/8192 [00:07<00:10, 480.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  37%|███▋      | 3031/8192 [00:07<00:10, 481.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  37%|███▋      | 3036/8192 [00:07<00:10, 482.38it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  37%|███▋      | 3033/8192 [00:07<00:10, 483.02it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  37%|███▋      | 3033/8192 [00:07<00:10, 477.89it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  39%|███▉      | 3185/8192 [00:07<00:10, 474.75it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  39%|███▊      | 3167/8192 [00:07<00:10, 470.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  39%|███▊      | 3164/8192 [00:07<00:10, 474.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  39%|███▊      | 3166/8192 [00:07<00:10, 470.09it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  39%|███▊      | 3171/8192 [00:07<00:10, 469.09it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  39%|███▊      | 3173/8192 [00:07<00:10, 470.37it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  39%|███▊      | 3168/8192 [00:07<00:10, 471.66it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  39%|███▊      | 3169/8192 [00:07<00:10, 467.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  40%|███▉      | 3275/8192 [00:07<00:10, 464.35it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  40%|████      | 3298/8192 [00:07<00:10, 468.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  40%|███▉      | 3271/8192 [00:07<00:10, 468.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  40%|███▉      | 3273/8192 [00:07<00:10, 464.68it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  40%|████      | 3280/8192 [00:07<00:10, 462.78it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  40%|████      | 3282/8192 [00:07<00:10, 464.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  40%|███▉      | 3276/8192 [00:07<00:10, 465.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  40%|████      | 3277/8192 [00:07<00:10, 461.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  41%|████      | 3364/8192 [00:07<00:10, 461.31it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  41%|████▏     | 3391/8192 [00:07<00:10, 466.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  41%|████      | 3359/8192 [00:07<00:10, 465.36it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  41%|████      | 3362/8192 [00:07<00:10, 461.40it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  41%|████      | 3369/8192 [00:07<00:10, 459.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  41%|████      | 3372/8192 [00:07<00:10, 461.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  41%|████      | 3365/8192 [00:07<00:10, 463.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  41%|████      | 3366/8192 [00:07<00:10, 457.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  42%|████▏     | 3440/8192 [00:08<00:10, 461.46it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  42%|████▏     | 3470/8192 [00:08<00:10, 465.49it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  42%|████▏     | 3435/8192 [00:07<00:10, 465.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  42%|████▏     | 3438/8192 [00:08<00:10, 461.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  42%|████▏     | 3445/8192 [00:08<00:10, 459.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  42%|████▏     | 3449/8192 [00:08<00:10, 462.06it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  42%|████▏     | 3441/8192 [00:08<00:10, 462.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  43%|████▎     | 3507/8192 [00:08<00:10, 462.03it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  42%|████▏     | 3442/8192 [00:08<00:10, 456.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  43%|████▎     | 3502/8192 [00:08<00:10, 464.94it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  43%|████▎     | 3539/8192 [00:08<00:10, 464.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  43%|████▎     | 3505/8192 [00:08<00:10, 461.18it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  43%|████▎     | 3512/8192 [00:08<00:10, 459.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  43%|████▎     | 3517/8192 [00:08<00:10, 462.72it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  44%|████▎     | 3568/8192 [00:08<00:09, 462.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  43%|████▎     | 3508/8192 [00:08<00:10, 462.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  43%|████▎     | 3563/8192 [00:08<00:09, 464.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  44%|████▍     | 3601/8192 [00:08<00:09, 466.50it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  43%|████▎     | 3509/8192 [00:08<00:10, 457.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  44%|████▎     | 3566/8192 [00:08<00:10, 461.40it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  44%|████▎     | 3573/8192 [00:08<00:10, 459.44it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  44%|████▎     | 3579/8192 [00:08<00:09, 462.52it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  44%|████▍     | 3625/8192 [00:08<00:09, 466.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  44%|████▎     | 3569/8192 [00:08<00:09, 463.12it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  44%|████▍     | 3620/8192 [00:08<00:09, 467.52it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  45%|████▍     | 3659/8192 [00:08<00:09, 471.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  44%|████▎     | 3570/8192 [00:08<00:10, 459.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  44%|████▍     | 3623/8192 [00:08<00:09, 465.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  44%|████▍     | 3630/8192 [00:08<00:09, 463.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  44%|████▍     | 3636/8192 [00:08<00:09, 466.66it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  45%|████▍     | 3679/8192 [00:08<00:09, 470.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  45%|████▍     | 3674/8192 [00:08<00:09, 471.09it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  45%|████▌     | 3715/8192 [00:08<00:09, 475.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  44%|████▍     | 3626/8192 [00:08<00:09, 466.78it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  44%|████▍     | 3627/8192 [00:08<00:09, 463.47it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  45%|████▍     | 3677/8192 [00:08<00:09, 470.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  45%|████▍     | 3684/8192 [00:08<00:09, 467.82it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  45%|████▌     | 3691/8192 [00:08<00:09, 470.90it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  46%|████▌     | 3732/8192 [00:08<00:09, 474.40it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  45%|████▌     | 3727/8192 [00:08<00:09, 475.36it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  46%|████▌     | 3769/8192 [00:08<00:09, 479.55it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  45%|████▍     | 3680/8192 [00:08<00:09, 471.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  45%|████▍     | 3681/8192 [00:08<00:09, 467.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  46%|████▌     | 3730/8192 [00:08<00:09, 474.92it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  46%|████▌     | 3737/8192 [00:08<00:09, 470.73it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  46%|████▌     | 3744/8192 [00:08<00:09, 473.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  46%|████▌     | 3784/8192 [00:08<00:09, 470.45it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  46%|████▌     | 3779/8192 [00:08<00:09, 479.12it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  47%|████▋     | 3822/8192 [00:08<00:09, 482.09it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  46%|████▌     | 3733/8192 [00:08<00:09, 474.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  46%|████▌     | 3734/8192 [00:08<00:09, 469.14it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  46%|████▌     | 3782/8192 [00:08<00:09, 477.31it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  46%|████▌     | 3788/8192 [00:08<00:09, 473.43it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  46%|████▋     | 3796/8192 [00:08<00:09, 476.55it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  47%|████▋     | 3834/8192 [00:08<00:09, 471.03it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  47%|████▋     | 3830/8192 [00:08<00:09, 481.43it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  47%|████▋     | 3874/8192 [00:08<00:08, 486.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  46%|████▌     | 3785/8192 [00:08<00:09, 477.14it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  46%|████▌     | 3785/8192 [00:08<00:09, 470.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  47%|████▋     | 3833/8192 [00:08<00:09, 478.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  47%|████▋     | 3839/8192 [00:08<00:09, 475.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  47%|████▋     | 3847/8192 [00:08<00:09, 479.49it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  47%|████▋     | 3884/8192 [00:09<00:09, 477.07it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  47%|████▋     | 3882/8192 [00:08<00:08, 489.12it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  48%|████▊     | 3925/8192 [00:09<00:08, 491.76it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  47%|████▋     | 3836/8192 [00:08<00:09, 477.87it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  47%|████▋     | 3835/8192 [00:08<00:09, 470.76it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  47%|████▋     | 3884/8192 [00:09<00:08, 485.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  47%|████▋     | 3890/8192 [00:09<00:08, 482.15it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  48%|████▊     | 3898/8192 [00:09<00:08, 486.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  48%|████▊     | 3934/8192 [00:09<00:08, 482.15it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  48%|████▊     | 3933/8192 [00:09<00:08, 494.59it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  49%|████▊     | 3976/8192 [00:09<00:08, 495.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  47%|████▋     | 3887/8192 [00:08<00:08, 485.40it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  47%|████▋     | 3885/8192 [00:09<00:09, 477.62it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  48%|████▊     | 3935/8192 [00:09<00:08, 491.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  48%|████▊     | 3941/8192 [00:09<00:08, 488.02it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  48%|████▊     | 3950/8192 [00:09<00:08, 493.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  49%|████▊     | 3984/8192 [00:09<00:08, 486.13it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  49%|████▊     | 3985/8192 [00:09<00:08, 499.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  49%|████▉     | 4028/8192 [00:09<00:08, 499.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  48%|████▊     | 3938/8192 [00:09<00:08, 491.80it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  48%|████▊     | 3936/8192 [00:09<00:08, 484.76it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  49%|████▊     | 3986/8192 [00:09<00:08, 495.89it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  49%|████▊     | 3992/8192 [00:09<00:08, 493.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  49%|████▉     | 4002/8192 [00:09<00:08, 498.84it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  49%|████▉     | 4034/8192 [00:09<00:08, 488.75it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  49%|████▉     | 4037/8192 [00:09<00:08, 502.41it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  50%|████▉     | 4080/8192 [00:09<00:08, 503.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  49%|████▊     | 3990/8192 [00:09<00:08, 497.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  49%|████▊     | 3987/8192 [00:09<00:08, 490.89it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  49%|████▉     | 4037/8192 [00:09<00:08, 499.02it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  49%|████▉     | 4043/8192 [00:09<00:08, 497.35it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  49%|████▉     | 4053/8192 [00:09<00:08, 500.80it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  50%|████▉     | 4084/8192 [00:09<00:08, 490.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  50%|████▉     | 4089/8192 [00:09<00:08, 505.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  50%|█████     | 4134/8192 [00:09<00:07, 512.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  49%|████▉     | 4042/8192 [00:09<00:08, 501.78it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  49%|████▉     | 4039/8192 [00:09<00:08, 496.92it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  50%|████▉     | 4088/8192 [00:09<00:08, 502.13it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  50%|████▉     | 4094/8192 [00:09<00:08, 500.43it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  50%|█████     | 4105/8192 [00:09<00:08, 504.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  50%|█████     | 4136/8192 [00:09<00:08, 498.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  51%|█████     | 4143/8192 [00:09<00:07, 514.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  51%|█████     | 4189/8192 [00:09<00:07, 521.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  50%|████▉     | 4094/8192 [00:09<00:08, 504.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  50%|████▉     | 4091/8192 [00:09<00:08, 501.07it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  51%|█████     | 4142/8192 [00:09<00:07, 511.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  51%|█████     | 4148/8192 [00:09<00:07, 509.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  51%|█████     | 4159/8192 [00:09<00:07, 513.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  51%|█████     | 4189/8192 [00:09<00:07, 505.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  51%|█████     | 4197/8192 [00:09<00:07, 520.84it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  52%|█████▏    | 4244/8192 [00:09<00:07, 527.67it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  51%|█████     | 4148/8192 [00:09<00:07, 514.18it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  51%|█████     | 4145/8192 [00:09<00:07, 509.68it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  51%|█████     | 4196/8192 [00:09<00:07, 518.35it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  51%|█████▏    | 4201/8192 [00:09<00:07, 515.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  51%|█████▏    | 4213/8192 [00:09<00:07, 519.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  52%|█████▏    | 4244/8192 [00:09<00:07, 516.19it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  52%|█████▏    | 4252/8192 [00:09<00:07, 526.64it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  52%|█████▏    | 4299/8192 [00:09<00:07, 531.92it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  51%|█████▏    | 4202/8192 [00:09<00:07, 520.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  51%|█████     | 4198/8192 [00:09<00:07, 512.89it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  52%|█████▏    | 4250/8192 [00:09<00:07, 523.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  52%|█████▏    | 4255/8192 [00:09<00:07, 519.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  52%|█████▏    | 4267/8192 [00:09<00:07, 523.68it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  52%|█████▏    | 4298/8192 [00:09<00:07, 521.44it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  53%|█████▎    | 4306/8192 [00:09<00:07, 530.46it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  53%|█████▎    | 4353/8192 [00:09<00:07, 533.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  52%|█████▏    | 4256/8192 [00:09<00:07, 525.57it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  52%|█████▏    | 4251/8192 [00:09<00:07, 517.18it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  53%|█████▎    | 4304/8192 [00:09<00:07, 526.75it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  53%|█████▎    | 4308/8192 [00:09<00:07, 522.60it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  53%|█████▎    | 4321/8192 [00:09<00:07, 526.07it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  53%|█████▎    | 4351/8192 [00:09<00:07, 517.15it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  53%|█████▎    | 4361/8192 [00:09<00:07, 534.63it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  54%|█████▍    | 4410/8192 [00:09<00:06, 543.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  53%|█████▎    | 4310/8192 [00:09<00:07, 528.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  53%|█████▎    | 4303/8192 [00:09<00:07, 517.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  53%|█████▎    | 4358/8192 [00:09<00:07, 530.24it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  53%|█████▎    | 4362/8192 [00:09<00:07, 526.07it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  53%|█████▎    | 4376/8192 [00:09<00:07, 532.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  54%|█████▍    | 4406/8192 [00:10<00:07, 526.37it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  54%|█████▍    | 4418/8192 [00:09<00:06, 544.75it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  55%|█████▍    | 4467/8192 [00:10<00:06, 549.90it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  53%|█████▎    | 4364/8192 [00:09<00:07, 531.17it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  53%|█████▎    | 4355/8192 [00:09<00:07, 513.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  54%|█████▍    | 4415/8192 [00:10<00:06, 540.19it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  54%|█████▍    | 4418/8192 [00:10<00:07, 535.64it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  54%|█████▍    | 4433/8192 [00:10<00:06, 541.75it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  54%|█████▍    | 4461/8192 [00:10<00:07, 532.65it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  55%|█████▍    | 4475/8192 [00:10<00:06, 551.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  55%|█████▌    | 4524/8192 [00:10<00:06, 554.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  54%|█████▍    | 4421/8192 [00:09<00:06, 540.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  54%|█████▍    | 4410/8192 [00:10<00:07, 522.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  55%|█████▍    | 4472/8192 [00:10<00:06, 547.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  55%|█████▍    | 4475/8192 [00:10<00:06, 543.52it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  55%|█████▍    | 4490/8192 [00:10<00:06, 549.38it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  55%|█████▌    | 4516/8192 [00:10<00:06, 537.57it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  55%|█████▌    | 4532/8192 [00:10<00:06, 556.57it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  56%|█████▌    | 4581/8192 [00:10<00:06, 557.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  55%|█████▍    | 4478/8192 [00:10<00:06, 546.36it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  55%|█████▍    | 4465/8192 [00:10<00:07, 528.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  55%|█████▌    | 4529/8192 [00:10<00:06, 551.44it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  55%|█████▌    | 4532/8192 [00:10<00:06, 548.91it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  56%|█████▌    | 4547/8192 [00:10<00:06, 553.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  56%|█████▌    | 4571/8192 [00:10<00:06, 540.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  56%|█████▌    | 4589/8192 [00:10<00:06, 559.67it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  57%|█████▋    | 4641/8192 [00:10<00:06, 568.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  55%|█████▌    | 4535/8192 [00:10<00:06, 552.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  55%|█████▌    | 4520/8192 [00:10<00:06, 532.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  56%|█████▌    | 4586/8192 [00:10<00:06, 554.84it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  56%|█████▌    | 4589/8192 [00:10<00:06, 552.92it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  56%|█████▌    | 4604/8192 [00:10<00:06, 556.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  56%|█████▋    | 4628/8192 [00:10<00:06, 547.85it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  57%|█████▋    | 4650/8192 [00:10<00:06, 572.39it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  57%|█████▋    | 4703/8192 [00:10<00:05, 582.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  56%|█████▌    | 4592/8192 [00:10<00:06, 556.59it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  56%|█████▌    | 4575/8192 [00:10<00:06, 536.92it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  57%|█████▋    | 4646/8192 [00:10<00:06, 566.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  57%|█████▋    | 4649/8192 [00:10<00:06, 564.90it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  57%|█████▋    | 4665/8192 [00:10<00:06, 570.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  57%|█████▋    | 4688/8192 [00:10<00:06, 561.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  58%|█████▊    | 4711/8192 [00:10<00:05, 582.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  58%|█████▊    | 4765/8192 [00:10<00:05, 592.59it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  57%|█████▋    | 4652/8192 [00:10<00:06, 568.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  57%|█████▋    | 4632/8192 [00:10<00:06, 545.49it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  57%|█████▋    | 4707/8192 [00:10<00:06, 578.62it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  57%|█████▋    | 4710/8192 [00:10<00:06, 575.80it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  58%|█████▊    | 4726/8192 [00:10<00:05, 580.79it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  58%|█████▊    | 4748/8192 [00:10<00:06, 570.24it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  58%|█████▊    | 4772/8192 [00:10<00:05, 589.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  59%|█████▉    | 4827/8192 [00:10<00:05, 600.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  58%|█████▊    | 4713/8192 [00:10<00:06, 579.75it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  57%|█████▋    | 4692/8192 [00:10<00:06, 559.23it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  58%|█████▊    | 4768/8192 [00:10<00:05, 586.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  58%|█████▊    | 4771/8192 [00:10<00:05, 583.39it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  58%|█████▊    | 4787/8192 [00:10<00:05, 588.38it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  59%|█████▊    | 4808/8192 [00:10<00:05, 576.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  59%|█████▉    | 4833/8192 [00:10<00:05, 595.15it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  60%|█████▉    | 4890/8192 [00:10<00:05, 608.91it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  58%|█████▊    | 4774/8192 [00:10<00:05, 588.66it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  58%|█████▊    | 4751/8192 [00:10<00:06, 567.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  59%|█████▉    | 4829/8192 [00:10<00:05, 592.36it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  59%|█████▉    | 4832/8192 [00:10<00:05, 588.44it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  59%|█████▉    | 4848/8192 [00:10<00:05, 593.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  59%|█████▉    | 4868/8192 [00:10<00:05, 581.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  60%|█████▉    | 4897/8192 [00:10<00:05, 606.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  60%|██████    | 4955/8192 [00:10<00:05, 620.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  59%|█████▉    | 4835/8192 [00:10<00:05, 593.68it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  59%|█████▊    | 4810/8192 [00:10<00:05, 573.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  60%|█████▉    | 4892/8192 [00:10<00:05, 601.72it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  60%|█████▉    | 4894/8192 [00:10<00:05, 596.97it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  60%|█████▉    | 4912/8192 [00:10<00:05, 605.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  60%|██████    | 4931/8192 [00:10<00:05, 596.06it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  61%|██████    | 4962/8192 [00:10<00:05, 618.60it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  61%|██████▏   | 5020/8192 [00:10<00:05, 628.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  60%|█████▉    | 4899/8192 [00:10<00:05, 605.47it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  59%|█████▉    | 4870/8192 [00:10<00:05, 579.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  61%|██████    | 4957/8192 [00:10<00:05, 614.14it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  61%|██████    | 4958/8192 [00:10<00:05, 609.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  61%|██████    | 4977/8192 [00:10<00:05, 616.86it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  61%|██████    | 4994/8192 [00:11<00:05, 605.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  61%|██████▏   | 5027/8192 [00:10<00:05, 627.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  62%|██████▏   | 5085/8192 [00:11<00:04, 632.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  61%|██████    | 4964/8192 [00:10<00:05, 616.94it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  60%|██████    | 4933/8192 [00:10<00:05, 592.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  61%|██████▏   | 5022/8192 [00:11<00:05, 623.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  61%|██████▏   | 5022/8192 [00:11<00:05, 618.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  62%|██████▏   | 5042/8192 [00:11<00:05, 625.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  62%|██████▏   | 5057/8192 [00:11<00:05, 612.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  62%|██████▏   | 5092/8192 [00:11<00:04, 633.09it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  61%|██████▏   | 5028/8192 [00:11<00:05, 623.78it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  61%|██████    | 4996/8192 [00:11<00:05, 601.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  62%|██████▏   | 5087/8192 [00:11<00:04, 629.13it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  62%|██████▏   | 5087/8192 [00:11<00:04, 624.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  62%|██████▏   | 5107/8192 [00:11<00:04, 631.17it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  62%|██████▏   | 5093/8192 [00:11<00:04, 630.66it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  62%|██████▏   | 5059/8192 [00:11<00:05, 608.46it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  63%|██████▎   | 5149/8192 [00:11<00:14, 212.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  63%|██████▎   | 5156/8192 [00:11<00:14, 214.06it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  70%|██████▉   | 5712/8192 [00:11<00:02, 886.94it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  63%|██████▎   | 5171/8192 [00:11<00:13, 217.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  63%|██████▎   | 5150/8192 [00:11<00:14, 209.52it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  63%|██████▎   | 5121/8192 [00:11<00:15, 193.84it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  63%|██████▎   | 5150/8192 [00:11<00:14, 207.57it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  70%|██████▉   | 5713/8192 [00:11<00:02, 887.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  63%|██████▎   | 5157/8192 [00:11<00:14, 213.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  70%|██████▉   | 5713/8192 [00:12<00:02, 880.82it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  70%|██████▉   | 5712/8192 [00:12<00:02, 880.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  70%|██████▉   | 5709/8192 [00:12<00:02, 862.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  70%|██████▉   | 5711/8192 [00:12<00:02, 875.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  70%|██████▉   | 5711/8192 [00:11<00:02, 882.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  63%|██████▎   | 5121/8192 [00:12<00:16, 191.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  72%|███████▏  | 5913/8192 [00:12<00:02, 862.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  70%|██████▉   | 5708/8192 [00:12<00:02, 859.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  72%|███████▏  | 5913/8192 [00:12<00:02, 863.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  72%|███████▏  | 5907/8192 [00:12<00:02, 855.78it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  72%|███████▏  | 5913/8192 [00:12<00:02, 857.74it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  72%|███████▏  | 5917/8192 [00:12<00:02, 839.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  72%|███████▏  | 5912/8192 [00:12<00:02, 852.66it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  74%|███████▍  | 6078/8192 [00:12<00:02, 867.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  72%|███████▏  | 5910/8192 [00:12<00:02, 859.09it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  74%|███████▍  | 6077/8192 [00:12<00:02, 868.74it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  74%|███████▍  | 6067/8192 [00:12<00:02, 861.44it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  72%|███████▏  | 5916/8192 [00:12<00:02, 834.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  76%|███████▌  | 6220/8192 [00:12<00:02, 882.41it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  74%|███████▍  | 6078/8192 [00:12<00:02, 862.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  74%|███████▍  | 6077/8192 [00:12<00:02, 858.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  74%|███████▍  | 6086/8192 [00:12<00:02, 844.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  74%|███████▍  | 6074/8192 [00:12<00:02, 865.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  76%|███████▌  | 6219/8192 [00:12<00:02, 882.66it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  77%|███████▋  | 6348/8192 [00:12<00:02, 901.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  76%|███████▌  | 6206/8192 [00:12<00:02, 873.13it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  76%|███████▌  | 6220/8192 [00:12<00:02, 876.76it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  76%|███████▌  | 6219/8192 [00:12<00:02, 872.64it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  74%|███████▍  | 6085/8192 [00:12<00:02, 840.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  76%|███████▌  | 6230/8192 [00:12<00:02, 857.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  76%|███████▌  | 6215/8192 [00:12<00:02, 877.78it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  77%|███████▋  | 6346/8192 [00:12<00:02, 899.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  77%|███████▋  | 6331/8192 [00:12<00:02, 891.86it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  77%|███████▋  | 6347/8192 [00:12<00:02, 894.52it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  77%|███████▋  | 6346/8192 [00:12<00:02, 889.19it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  78%|███████▊  | 6358/8192 [00:12<00:02, 875.17it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  77%|███████▋  | 6342/8192 [00:12<00:02, 895.92it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  76%|███████▌  | 6229/8192 [00:12<00:02, 854.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  78%|███████▊  | 6357/8192 [00:12<00:02, 872.41it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  79%|███████▉  | 6467/8192 [00:13<00:03, 538.13it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  79%|███████▉  | 6464/8192 [00:13<00:03, 533.67it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  79%|███████▊  | 6447/8192 [00:13<00:03, 516.64it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  79%|███████▉  | 6465/8192 [00:13<00:03, 532.36it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  79%|███████▉  | 6463/8192 [00:13<00:03, 527.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  81%|████████▏ | 6657/8192 [00:13<00:02, 642.64it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  79%|███████▉  | 6476/8192 [00:13<00:03, 529.18it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  79%|███████▉  | 6460/8192 [00:13<00:03, 528.49it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  81%|████████▏ | 6657/8192 [00:13<00:02, 642.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  89%|████████▉ | 7321/8192 [00:13<00:00, 1510.96it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  81%|████████▏ | 6657/8192 [00:13<00:02, 646.57it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  81%|████████▏ | 6657/8192 [00:13<00:02, 638.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  79%|███████▉  | 6475/8192 [00:13<00:03, 526.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  89%|████████▉ | 7323/8192 [00:13<00:00, 1512.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  81%|████████▏ | 6657/8192 [00:13<00:02, 636.86it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  81%|████████▏ | 6657/8192 [00:13<00:02, 620.00it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  81%|████████▏ | 6657/8192 [00:13<00:02, 642.10it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  93%|█████████▎| 7585/8192 [00:13<00:00, 1571.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  89%|████████▉ | 7320/8192 [00:13<00:00, 1503.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  89%|████████▉ | 7321/8192 [00:13<00:00, 1501.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  89%|████████▉ | 7320/8192 [00:13<00:00, 1494.79it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  89%|████████▉ | 7319/8192 [00:13<00:00, 1467.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  89%|████████▉ | 7320/8192 [00:13<00:00, 1503.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  93%|█████████▎| 7588/8192 [00:13<00:00, 1571.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  81%|████████▏ | 6657/8192 [00:13<00:02, 617.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  93%|█████████▎| 7585/8192 [00:13<00:00, 1559.91it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  93%|█████████▎| 7585/8192 [00:13<00:00, 1559.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  93%|█████████▎| 7583/8192 [00:13<00:00, 1549.45it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  93%|█████████▎| 7581/8192 [00:13<00:00, 1527.15it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  93%|█████████▎| 7585/8192 [00:13<00:00, 1561.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  89%|████████▉ | 7317/8192 [00:13<00:00, 1460.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  95%|█████████▌| 7823/8192 [00:13<00:00, 1322.55it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  96%|█████████▌| 7827/8192 [00:13<00:00, 1326.03it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  99%|█████████▉| 8129/8192 [00:13<00:00, 1600.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  93%|█████████▎| 7579/8192 [00:13<00:00, 1518.43it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])): 100%|██████████| 8192/8192 [00:13<00:00, 587.31it/s] 
[1;36m(EngineCore_DP4 pid=178305)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  95%|█████████▌| 7823/8192 [00:13<00:00, 1316.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  95%|█████████▌| 7822/8192 [00:13<00:00, 1310.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  99%|█████████▉| 8129/8192 [00:13<00:00, 1601.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])): 100%|██████████| 8192/8192 [00:13<00:00, 587.80it/s] 
[1;36m(EngineCore_DP1 pid=178302)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  95%|█████████▌| 7819/8192 [00:14<00:00, 1298.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  95%|█████████▌| 7816/8192 [00:14<00:00, 1290.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  95%|█████████▌| 7823/8192 [00:13<00:00, 1312.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  99%|█████████▉| 8129/8192 [00:14<00:00, 1592.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  99%|█████████▉| 8129/8192 [00:14<00:00, 1596.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])): 100%|██████████| 8192/8192 [00:14<00:00, 582.23it/s] 
DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])): 100%|██████████| 8192/8192 [00:14<00:00, 582.94it/s] 
[1;36m(EngineCore_DP0 pid=178301)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   0%|          | 0/8192 [00:00<?, ?it/s][1;36m(EngineCore_DP6 pid=178307)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  99%|█████████▉| 8129/8192 [00:14<00:00, 1576.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])): 100%|██████████| 8192/8192 [00:14<00:00, 580.16it/s] 
[1;36m(EngineCore_DP3 pid=178304)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  99%|█████████▉| 8129/8192 [00:14<00:00, 1588.47it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])): 100%|██████████| 8192/8192 [00:14<00:00, 578.81it/s] 
[1;36m(EngineCore_DP5 pid=178306)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  99%|█████████▉| 8129/8192 [00:14<00:00, 1597.47it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])): 100%|██████████| 8192/8192 [00:14<00:00, 584.63it/s] 
[1;36m(EngineCore_DP7 pid=178308)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  95%|█████████▌| 7814/8192 [00:14<00:00, 1278.90it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])):  99%|█████████▉| 8129/8192 [00:14<00:00, 1573.07it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([36864, 7168])): 100%|██████████| 8192/8192 [00:14<00:00, 575.39it/s] 
[1;36m(EngineCore_DP2 pid=178303)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   3%|▎         | 257/8192 [00:00<00:13, 587.12it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   3%|▎         | 257/8192 [00:00<00:13, 593.00it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   3%|▎         | 257/8192 [00:00<00:13, 591.63it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   3%|▎         | 257/8192 [00:00<00:13, 589.06it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   3%|▎         | 257/8192 [00:00<00:13, 590.15it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   3%|▎         | 257/8192 [00:00<00:13, 600.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   3%|▎         | 257/8192 [00:00<00:13, 578.52it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   3%|▎         | 257/8192 [00:00<00:13, 583.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   6%|▋         | 513/8192 [00:00<00:12, 606.19it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   6%|▋         | 513/8192 [00:00<00:12, 608.40it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   6%|▋         | 513/8192 [00:00<00:12, 608.65it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   6%|▋         | 513/8192 [00:00<00:12, 606.79it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   6%|▋         | 513/8192 [00:00<00:12, 603.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   6%|▋         | 513/8192 [00:00<00:12, 608.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   6%|▋         | 513/8192 [00:00<00:12, 604.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   6%|▋         | 513/8192 [00:00<00:12, 603.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   9%|▉         | 769/8192 [00:01<00:11, 626.85it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   9%|▉         | 769/8192 [00:01<00:11, 628.72it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   9%|▉         | 769/8192 [00:01<00:11, 623.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   9%|▉         | 769/8192 [00:01<00:11, 623.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   9%|▉         | 769/8192 [00:01<00:11, 621.02it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   9%|▉         | 769/8192 [00:01<00:11, 623.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   9%|▉         | 769/8192 [00:01<00:11, 621.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  13%|█▎        | 1025/8192 [00:01<00:11, 637.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):   9%|▉         | 769/8192 [00:01<00:12, 614.78it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  13%|█▎        | 1025/8192 [00:01<00:11, 642.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  13%|█▎        | 1025/8192 [00:01<00:11, 638.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  13%|█▎        | 1025/8192 [00:01<00:11, 638.06it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  13%|█▎        | 1025/8192 [00:01<00:11, 635.84it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  13%|█▎        | 1025/8192 [00:01<00:11, 637.91it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  13%|█▎        | 1025/8192 [00:01<00:11, 636.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  13%|█▎        | 1025/8192 [00:01<00:11, 631.39it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  19%|█▉        | 1537/8192 [00:02<00:09, 672.74it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  19%|█▉        | 1537/8192 [00:02<00:09, 676.91it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  26%|██▌       | 2119/8192 [00:02<00:05, 1137.43it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  19%|█▉        | 1537/8192 [00:02<00:09, 671.02it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  19%|█▉        | 1537/8192 [00:02<00:09, 670.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  26%|██▌       | 2120/8192 [00:02<00:05, 1145.09it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  19%|█▉        | 1537/8192 [00:02<00:09, 668.44it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  19%|█▉        | 1537/8192 [00:02<00:09, 669.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  19%|█▉        | 1537/8192 [00:02<00:09, 670.09it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  26%|██▌       | 2120/8192 [00:02<00:05, 1135.39it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  26%|██▌       | 2119/8192 [00:02<00:05, 1134.49it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  26%|██▌       | 2119/8192 [00:02<00:05, 1130.64it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  26%|██▌       | 2120/8192 [00:02<00:05, 1133.55it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  26%|██▌       | 2119/8192 [00:02<00:05, 1134.31it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  19%|█▉        | 1537/8192 [00:02<00:10, 661.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  29%|██▉       | 2359/8192 [00:02<00:05, 1018.98it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  29%|██▉       | 2362/8192 [00:02<00:05, 1024.72it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  26%|██▌       | 2119/8192 [00:02<00:05, 1120.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  29%|██▉       | 2360/8192 [00:02<00:05, 1018.35it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  29%|██▉       | 2361/8192 [00:02<00:05, 1017.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  29%|██▉       | 2359/8192 [00:02<00:05, 1012.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  29%|██▉       | 2361/8192 [00:02<00:05, 1018.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  29%|██▉       | 2360/8192 [00:02<00:05, 1014.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  31%|███       | 2545/8192 [00:03<00:05, 962.23it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  31%|███       | 2549/8192 [00:03<00:05, 967.31it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  29%|██▉       | 2359/8192 [00:02<00:05, 1007.57it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  31%|███       | 2546/8192 [00:03<00:05, 956.37it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  31%|███       | 2548/8192 [00:03<00:05, 958.06it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  33%|███▎      | 2697/8192 [00:03<00:05, 922.87it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  31%|███       | 2544/8192 [00:03<00:05, 954.75it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  31%|███       | 2548/8192 [00:03<00:05, 959.93it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  31%|███       | 2546/8192 [00:03<00:05, 953.13it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  33%|███▎      | 2702/8192 [00:03<00:05, 928.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  34%|███▍      | 2826/8192 [00:03<00:06, 893.64it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  33%|███▎      | 2697/8192 [00:03<00:05, 917.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  33%|███▎      | 2700/8192 [00:03<00:05, 919.10it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  33%|███▎      | 2695/8192 [00:03<00:05, 916.17it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  31%|███       | 2545/8192 [00:03<00:05, 946.19it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  33%|███▎      | 2697/8192 [00:03<00:05, 917.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  33%|███▎      | 2700/8192 [00:03<00:05, 917.50it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  35%|███▍      | 2832/8192 [00:03<00:05, 901.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  36%|███▌      | 2939/8192 [00:03<00:05, 884.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  34%|███▍      | 2825/8192 [00:03<00:06, 891.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  35%|███▍      | 2829/8192 [00:03<00:06, 892.82it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  36%|███▌      | 2946/8192 [00:03<00:05, 891.55it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  34%|███▍      | 2823/8192 [00:03<00:06, 888.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  34%|███▍      | 2825/8192 [00:03<00:06, 892.13it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  35%|███▍      | 2829/8192 [00:03<00:06, 890.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  33%|███▎      | 2696/8192 [00:03<00:06, 906.79it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  37%|███▋      | 3044/8192 [00:03<00:05, 877.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  36%|███▌      | 2938/8192 [00:03<00:05, 882.57it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  36%|███▌      | 2943/8192 [00:03<00:05, 885.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  37%|███▋      | 3052/8192 [00:03<00:05, 882.68it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  36%|███▌      | 2936/8192 [00:03<00:05, 881.76it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  36%|███▌      | 2938/8192 [00:03<00:05, 884.50it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  36%|███▌      | 2943/8192 [00:03<00:05, 882.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  38%|███▊      | 3143/8192 [00:03<00:05, 873.54it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  34%|███▍      | 2824/8192 [00:03<00:06, 881.03it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  37%|███▋      | 3043/8192 [00:03<00:05, 876.44it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  37%|███▋      | 3048/8192 [00:03<00:05, 878.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  38%|███▊      | 3151/8192 [00:03<00:05, 877.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  37%|███▋      | 3041/8192 [00:03<00:05, 875.09it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  37%|███▋      | 3043/8192 [00:03<00:05, 876.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  40%|███▉      | 3238/8192 [00:03<00:05, 872.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  37%|███▋      | 3048/8192 [00:03<00:05, 874.86it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  38%|███▊      | 3142/8192 [00:03<00:05, 872.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  38%|███▊      | 3147/8192 [00:03<00:05, 873.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  40%|███▉      | 3246/8192 [00:03<00:05, 875.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  36%|███▌      | 2937/8192 [00:03<00:06, 873.72it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  38%|███▊      | 3140/8192 [00:03<00:05, 869.45it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  38%|███▊      | 3142/8192 [00:03<00:05, 869.66it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  38%|███▊      | 3147/8192 [00:03<00:05, 870.24it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  40%|███▉      | 3237/8192 [00:03<00:05, 866.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  40%|███▉      | 3242/8192 [00:03<00:05, 870.38it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  37%|███▋      | 3041/8192 [00:03<00:05, 869.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  39%|███▉      | 3235/8192 [00:03<00:05, 865.66it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  40%|███▉      | 3237/8192 [00:03<00:05, 864.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  40%|███▉      | 3242/8192 [00:03<00:05, 869.75it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  38%|███▊      | 3139/8192 [00:03<00:05, 864.78it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  41%|████      | 3327/8192 [00:03<00:05, 862.37it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  39%|███▉      | 3233/8192 [00:03<00:05, 860.55it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  41%|████      | 3325/8192 [00:04<00:05, 854.62it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  41%|████      | 3331/8192 [00:04<00:12, 394.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  41%|████      | 3339/8192 [00:04<00:12, 401.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  48%|████▊     | 3936/8192 [00:04<00:03, 1107.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  48%|████▊     | 3937/8192 [00:04<00:03, 1113.73it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  41%|████      | 3335/8192 [00:04<00:12, 396.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  41%|████      | 3329/8192 [00:04<00:12, 391.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  41%|████      | 3335/8192 [00:04<00:12, 395.90it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  41%|████      | 3329/8192 [00:04<00:12, 392.36it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  42%|████▏     | 3417/8192 [00:04<00:11, 419.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  48%|████▊     | 3937/8192 [00:04<00:03, 1107.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  48%|████▊     | 3936/8192 [00:04<00:03, 1104.57it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  48%|████▊     | 3936/8192 [00:04<00:03, 1105.17it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  48%|████▊     | 3936/8192 [00:04<00:03, 1106.18it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  48%|████▊     | 3938/8192 [00:04<00:03, 1098.17it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  51%|█████     | 4166/8192 [00:04<00:03, 1079.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  51%|█████     | 4165/8192 [00:04<00:03, 1083.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  42%|████▏     | 3414/8192 [00:04<00:11, 413.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  51%|█████     | 4167/8192 [00:04<00:03, 1077.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  51%|█████     | 4167/8192 [00:04<00:03, 1073.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  53%|█████▎    | 4357/8192 [00:05<00:03, 1075.96it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  51%|█████     | 4141/8192 [00:04<00:03, 1065.23it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  48%|████▊     | 3938/8192 [00:04<00:03, 1090.96it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  51%|█████     | 4165/8192 [00:04<00:03, 1076.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  51%|█████     | 4166/8192 [00:04<00:03, 1072.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  53%|█████▎    | 4355/8192 [00:04<00:03, 1081.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  55%|█████▌    | 4523/8192 [00:05<00:03, 1076.45it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  53%|█████▎    | 4358/8192 [00:05<00:03, 1071.97it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  53%|█████▎    | 4359/8192 [00:05<00:03, 1068.03it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  53%|█████▎    | 4313/8192 [00:05<00:03, 1062.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  55%|█████▌    | 4520/8192 [00:05<00:03, 1082.79it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  53%|█████▎    | 4356/8192 [00:05<00:03, 1073.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  53%|█████▎    | 4357/8192 [00:05<00:03, 1066.37it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  51%|█████     | 4142/8192 [00:04<00:03, 1059.94it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  57%|█████▋    | 4672/8192 [00:05<00:03, 1089.35it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  55%|█████▌    | 4523/8192 [00:05<00:03, 1072.47it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  57%|█████▋    | 4668/8192 [00:05<00:03, 1096.67it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  55%|█████▍    | 4465/8192 [00:05<00:03, 1063.63it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  55%|█████▌    | 4525/8192 [00:05<00:03, 1070.00it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  55%|█████▌    | 4522/8192 [00:05<00:03, 1072.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  55%|█████▌    | 4522/8192 [00:05<00:03, 1070.55it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  59%|█████▊    | 4810/8192 [00:05<00:03, 1115.82it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  53%|█████▎    | 4314/8192 [00:05<00:03, 1053.78it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  59%|█████▊    | 4806/8192 [00:05<00:03, 1124.18it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  57%|█████▋    | 4671/8192 [00:05<00:03, 1088.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  56%|█████▌    | 4604/8192 [00:05<00:03, 1065.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  57%|█████▋    | 4673/8192 [00:05<00:03, 1086.02it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  60%|██████    | 4943/8192 [00:05<00:02, 1138.19it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  57%|█████▋    | 4670/8192 [00:05<00:03, 1085.44it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  57%|█████▋    | 4670/8192 [00:05<00:03, 1086.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  55%|█████▍    | 4466/8192 [00:05<00:03, 1052.96it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  60%|██████    | 4940/8192 [00:05<00:02, 1149.47it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  58%|█████▊    | 4733/8192 [00:05<00:03, 1097.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  59%|█████▊    | 4809/8192 [00:05<00:03, 1116.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  59%|█████▊    | 4811/8192 [00:05<00:03, 1114.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  62%|██████▏   | 5073/8192 [00:05<00:02, 1164.50it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  59%|█████▊    | 4808/8192 [00:05<00:03, 1113.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  59%|█████▊    | 4808/8192 [00:05<00:03, 1114.14it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  62%|██████▏   | 5071/8192 [00:05<00:02, 1175.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  59%|█████▉    | 4860/8192 [00:05<00:02, 1125.63it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  60%|██████    | 4942/8192 [00:05<00:02, 1141.02it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  56%|█████▌    | 4604/8192 [00:05<00:03, 1057.18it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  60%|██████    | 4945/8192 [00:05<00:02, 1140.07it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  60%|██████    | 4941/8192 [00:05<00:02, 1137.92it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  60%|██████    | 4941/8192 [00:05<00:02, 1138.41it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  61%|██████    | 4986/8192 [00:05<00:02, 1150.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  62%|██████▏   | 5072/8192 [00:05<00:02, 1168.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  58%|█████▊    | 4733/8192 [00:05<00:03, 1089.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  62%|██████▏   | 5075/8192 [00:05<00:02, 1167.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  62%|██████▏   | 5071/8192 [00:05<00:02, 1164.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  62%|██████▏   | 5071/8192 [00:05<00:02, 1164.62it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  62%|██████▏   | 5111/8192 [00:05<00:02, 1175.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  59%|█████▉    | 4860/8192 [00:05<00:02, 1118.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  61%|██████    | 4985/8192 [00:05<00:02, 1144.81it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  64%|██████▎   | 5202/8192 [00:06<00:04, 689.43it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  63%|██████▎   | 5200/8192 [00:05<00:04, 692.33it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  62%|██████▏   | 5110/8192 [00:05<00:02, 1169.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  71%|███████   | 5783/8192 [00:06<00:01, 1547.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  71%|███████   | 5783/8192 [00:06<00:01, 1556.94it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  63%|██████▎   | 5201/8192 [00:06<00:04, 686.12it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  64%|██████▎   | 5204/8192 [00:06<00:04, 687.43it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  63%|██████▎   | 5200/8192 [00:06<00:04, 687.42it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  63%|██████▎   | 5200/8192 [00:06<00:04, 682.24it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  64%|██████▍   | 5236/8192 [00:06<00:04, 688.93it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  74%|███████▎  | 6026/8192 [00:06<00:01, 1557.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  71%|███████   | 5782/8192 [00:06<00:01, 1541.92it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  71%|███████   | 5782/8192 [00:06<00:01, 1538.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  74%|███████▎  | 6028/8192 [00:06<00:01, 1571.37it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  71%|███████   | 5781/8192 [00:06<00:01, 1545.36it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  71%|███████   | 5783/8192 [00:06<00:01, 1538.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  71%|███████   | 5783/8192 [00:06<00:01, 1550.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  76%|███████▌  | 6244/8192 [00:06<00:01, 1595.14it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  76%|███████▋  | 6248/8192 [00:06<00:01, 1610.86it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  74%|███████▎  | 6025/8192 [00:06<00:01, 1555.43it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  74%|███████▎  | 6025/8192 [00:06<00:01, 1551.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  64%|██████▍   | 5235/8192 [00:06<00:04, 681.31it/s] DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  74%|███████▎  | 6025/8192 [00:06<00:01, 1555.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  73%|███████▎  | 6015/8192 [00:06<00:01, 1558.87it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  74%|███████▎  | 6028/8192 [00:06<00:01, 1556.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  79%|███████▊  | 6448/8192 [00:06<00:01, 1646.13it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  79%|███████▉  | 6454/8192 [00:06<00:01, 1663.67it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  76%|███████▌  | 6243/8192 [00:06<00:01, 1594.90it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  71%|███████   | 5780/8192 [00:06<00:01, 1534.06it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  76%|███████▌  | 6243/8192 [00:06<00:01, 1592.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  81%|████████▏ | 6660/8192 [00:06<00:00, 1753.96it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  76%|███████▌  | 6243/8192 [00:06<00:01, 1593.67it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  76%|███████▌  | 6225/8192 [00:06<00:01, 1596.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  76%|███████▋  | 6247/8192 [00:06<00:01, 1598.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  81%|████████▏ | 6667/8192 [00:06<00:00, 1769.52it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  79%|███████▊  | 6448/8192 [00:06<00:01, 1648.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  79%|███████▊  | 6447/8192 [00:06<00:01, 1644.65it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  84%|████████▍ | 6882/8192 [00:06<00:00, 1867.86it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  73%|███████▎  | 6011/8192 [00:06<00:01, 1542.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  78%|███████▊  | 6424/8192 [00:06<00:01, 1642.00it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  79%|███████▊  | 6447/8192 [00:06<00:01, 1644.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  79%|███████▉  | 6453/8192 [00:06<00:01, 1651.79it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  84%|████████▍ | 6890/8192 [00:06<00:00, 1882.74it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  81%|████████▏ | 6658/8192 [00:06<00:00, 1752.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  81%|████████▏ | 6659/8192 [00:06<00:00, 1752.96it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  81%|████████  | 6634/8192 [00:06<00:00, 1750.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  81%|████████▏ | 6657/8192 [00:06<00:00, 1748.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  81%|████████▏ | 6663/8192 [00:06<00:00, 1753.49it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  76%|███████▌  | 6220/8192 [00:06<00:01, 1582.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  84%|████████▍ | 6881/8192 [00:06<00:00, 1868.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  84%|████████▍ | 6879/8192 [00:06<00:00, 1862.96it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  84%|████████▎ | 6853/8192 [00:06<00:00, 1860.90it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  84%|████████▍ | 6879/8192 [00:06<00:00, 1863.92it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  87%|████████▋ | 7090/8192 [00:06<00:00, 1443.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  84%|████████▍ | 6884/8192 [00:06<00:00, 1865.24it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  78%|███████▊  | 6418/8192 [00:06<00:01, 1626.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  87%|████████▋ | 7099/8192 [00:06<00:00, 1467.19it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  92%|█████████▏| 7553/8192 [00:07<00:00, 2064.38it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  81%|████████  | 6628/8192 [00:06<00:00, 1737.35it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  92%|█████████▏| 7553/8192 [00:07<00:00, 2073.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  87%|████████▋ | 7089/8192 [00:06<00:00, 1436.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  87%|████████▋ | 7087/8192 [00:06<00:00, 1427.57it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])): 100%|██████████| 8192/8192 [00:07<00:00, 1142.60it/s]
[1;36m(EngineCore_DP4 pid=178305)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  84%|████████▎ | 6846/8192 [00:06<00:00, 1848.54it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  87%|████████▋ | 7087/8192 [00:06<00:00, 1435.55it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  87%|████████▋ | 7092/8192 [00:06<00:00, 1433.75it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  86%|████████▌ | 7057/8192 [00:06<00:00, 1382.09it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])): 100%|██████████| 8192/8192 [00:07<00:00, 1150.35it/s]
[1;36m(EngineCore_DP1 pid=178302)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  92%|█████████▏| 7553/8192 [00:07<00:00, 2056.84it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  92%|█████████▏| 7553/8192 [00:07<00:00, 2050.57it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):   5%|▌         | 414/8192 [00:00<00:01, 4139.74it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  92%|█████████▏| 7553/8192 [00:07<00:00, 2035.80it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):   6%|▌         | 474/8192 [00:00<00:01, 4739.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  92%|█████████▏| 7553/8192 [00:07<00:00, 2028.73it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  92%|█████████▏| 7553/8192 [00:07<00:00, 2070.07it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])): 100%|█████████▉| 8165/8192 [00:07<00:00, 2993.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])): 100%|██████████| 8192/8192 [00:07<00:00, 1140.67it/s]
[1;36m(EngineCore_DP6 pid=178307)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])): 100%|██████████| 8192/8192 [00:07<00:00, 1139.55it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  99%|█████████▉| 8129/8192 [00:07<00:00, 2864.59it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])): 100%|██████████| 8192/8192 [00:07<00:00, 1137.68it/s]
[1;36m(EngineCore_DP5 pid=178306)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])): 100%|██████████| 8192/8192 [00:07<00:00, 1138.27it/s]
[1;36m(EngineCore_DP7 pid=178308)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  99%|█████████▉| 8141/8192 [00:07<00:00, 2940.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])): 100%|██████████| 8192/8192 [00:07<00:00, 1135.61it/s]
[1;36m(EngineCore_DP3 pid=178304)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  86%|████████▌ | 7049/8192 [00:07<00:00, 1362.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):   6%|▌         | 454/8192 [00:00<00:01, 4539.12it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):   6%|▌         | 484/8192 [00:00<00:01, 4839.52it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  10%|█         | 828/8192 [00:00<00:02, 2777.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  12%|█▏        | 948/8192 [00:00<00:02, 3166.96it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):   6%|▌         | 475/8192 [00:00<00:01, 4749.00it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):   6%|▌         | 481/8192 [00:00<00:01, 4809.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  92%|█████████▏| 7499/8192 [00:07<00:00, 2032.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  19%|█▉        | 1565/8192 [00:00<00:01, 4431.85it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  19%|█▉        | 1576/8192 [00:00<00:01, 4282.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):   6%|▋         | 513/8192 [00:00<00:02, 2731.34it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])):  99%|█████████▉| 8111/8192 [00:07<00:00, 2987.97it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  11%|█         | 908/8192 [00:00<00:02, 3016.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  12%|█▏        | 968/8192 [00:00<00:02, 3213.50it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 18432])): 100%|██████████| 8192/8192 [00:07<00:00, 1127.17it/s]
[1;36m(EngineCore_DP2 pid=178303)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  12%|█▏        | 950/8192 [00:00<00:02, 3142.50it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  12%|█▏        | 962/8192 [00:00<00:02, 3169.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  13%|█▎        | 1061/8192 [00:00<00:01, 3918.39it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  25%|██▌       | 2067/8192 [00:00<00:01, 3832.47it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  19%|█▉        | 1571/8192 [00:00<00:01, 4308.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  19%|█▉        | 1576/8192 [00:00<00:01, 4237.62it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  25%|██▌       | 2051/8192 [00:00<00:01, 3764.61it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):   5%|▌         | 438/8192 [00:00<00:01, 4379.26it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  19%|█▉        | 1574/8192 [00:00<00:01, 4244.97it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  19%|█▉        | 1574/8192 [00:00<00:01, 4217.62it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  19%|█▉        | 1584/8192 [00:00<00:01, 4415.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  30%|███       | 2494/8192 [00:00<00:01, 3592.87it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  30%|███       | 2461/8192 [00:00<00:01, 3554.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  25%|██▌       | 2053/8192 [00:00<00:01, 3786.00it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  25%|██▍       | 2045/8192 [00:00<00:01, 3758.75it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  11%|█         | 876/8192 [00:00<00:02, 2889.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  25%|██▍       | 2046/8192 [00:00<00:01, 3746.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  25%|██▍       | 2043/8192 [00:00<00:01, 3734.80it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  25%|██▌       | 2059/8192 [00:00<00:01, 3812.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  30%|██▉       | 2453/8192 [00:00<00:01, 3554.78it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  30%|███       | 2468/8192 [00:00<00:01, 3565.89it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  19%|█▉        | 1567/8192 [00:00<00:01, 4320.14it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  30%|██▉       | 2454/8192 [00:00<00:01, 3538.50it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  30%|██▉       | 2449/8192 [00:00<00:01, 3528.87it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  35%|███▌      | 2881/8192 [00:00<00:01, 2691.76it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  30%|███       | 2469/8192 [00:00<00:01, 3577.52it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  35%|███▍      | 2837/8192 [00:00<00:02, 2590.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  25%|██▌       | 2055/8192 [00:00<00:01, 3759.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  41%|████      | 3329/8192 [00:01<00:01, 2900.57it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  41%|████      | 3329/8192 [00:01<00:01, 2934.79it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  35%|███▍      | 2848/8192 [00:00<00:02, 2616.50it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  35%|███▍      | 2828/8192 [00:00<00:02, 2555.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  35%|███▍      | 2829/8192 [00:00<00:02, 2568.30it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  30%|███       | 2472/8192 [00:00<00:01, 3538.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  34%|███▍      | 2822/8192 [00:00<00:02, 2545.64it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  35%|███▍      | 2845/8192 [00:00<00:02, 2587.57it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  47%|████▋     | 3841/8192 [00:01<00:01, 3269.74it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  47%|████▋     | 3841/8192 [00:01<00:01, 3303.80it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  41%|████      | 3329/8192 [00:01<00:01, 2907.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  41%|████      | 3329/8192 [00:01<00:01, 2888.54it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  59%|█████▉    | 4838/8192 [00:01<00:00, 4867.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  41%|████      | 3329/8192 [00:01<00:01, 2910.47it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  41%|████      | 3329/8192 [00:01<00:01, 2904.58it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  59%|█████▉    | 4841/8192 [00:01<00:00, 4909.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  41%|████      | 3329/8192 [00:01<00:01, 2888.28it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  47%|████▋     | 3841/8192 [00:01<00:01, 3263.68it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  47%|████▋     | 3841/8192 [00:01<00:01, 3250.76it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  66%|██████▌   | 5395/8192 [00:01<00:00, 4901.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  35%|███▍      | 2851/8192 [00:00<00:02, 2592.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  66%|██████▌   | 5404/8192 [00:01<00:00, 4951.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  47%|████▋     | 3841/8192 [00:01<00:01, 3268.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  47%|████▋     | 3841/8192 [00:01<00:01, 3264.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  47%|████▋     | 3841/8192 [00:01<00:01, 3254.62it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  59%|█████▉    | 4838/8192 [00:01<00:00, 4856.55it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  59%|█████▉    | 4835/8192 [00:01<00:00, 4832.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  59%|█████▉    | 4837/8192 [00:01<00:00, 4857.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  59%|█████▉    | 4836/8192 [00:01<00:00, 4848.87it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  59%|█████▉    | 4836/8192 [00:01<00:00, 4850.93it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  72%|███████▏  | 5935/8192 [00:01<00:00, 4530.35it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  41%|████      | 3329/8192 [00:01<00:01, 2873.72it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  73%|███████▎  | 5950/8192 [00:01<00:00, 4587.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  66%|██████▌   | 5396/8192 [00:01<00:00, 4896.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  66%|██████▌   | 5392/8192 [00:01<00:00, 4875.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  66%|██████▌   | 5396/8192 [00:01<00:00, 4903.06it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  84%|████████▍ | 6913/8192 [00:01<00:00, 5825.80it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  66%|██████▌   | 5395/8192 [00:01<00:00, 4889.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  66%|██████▌   | 5392/8192 [00:01<00:00, 4882.74it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  84%|████████▍ | 6913/8192 [00:01<00:00, 5844.40it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  47%|████▋     | 3841/8192 [00:01<00:01, 3228.41it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  72%|███████▏  | 5936/8192 [00:01<00:00, 4533.66it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  72%|███████▏  | 5931/8192 [00:01<00:00, 4515.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  96%|█████████▌| 7873/8192 [00:01<00:00, 6729.62it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  96%|█████████▌| 7873/8192 [00:01<00:00, 6729.14it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  59%|█████▉    | 4833/8192 [00:01<00:00, 4802.97it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  72%|███████▏  | 5937/8192 [00:01<00:00, 4531.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  72%|███████▏  | 5936/8192 [00:01<00:00, 4521.89it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  72%|███████▏  | 5930/8192 [00:01<00:00, 4505.48it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  84%|████████▍ | 6913/8192 [00:01<00:00, 5820.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])): 100%|██████████| 8192/8192 [00:01<00:00, 4566.19it/s]
[1;36m(EngineCore_DP4 pid=178305)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  84%|████████▍ | 6913/8192 [00:01<00:00, 5821.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])): 100%|██████████| 8192/8192 [00:01<00:00, 4586.33it/s]
[1;36m(EngineCore_DP1 pid=178302)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  84%|████████▍ | 6913/8192 [00:01<00:00, 5831.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  84%|████████▍ | 6913/8192 [00:01<00:00, 5818.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  66%|██████▌   | 5387/8192 [00:01<00:00, 4831.67it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  84%|████████▍ | 6913/8192 [00:01<00:00, 5797.06it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  96%|█████████▌| 7873/8192 [00:01<00:00, 6713.27it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  96%|█████████▌| 7873/8192 [00:01<00:00, 6745.10it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):   6%|▋         | 513/8192 [00:00<00:01, 4400.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):   6%|▋         | 513/8192 [00:00<00:01, 4380.49it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  96%|█████████▌| 7873/8192 [00:01<00:00, 6758.37it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  96%|█████████▌| 7873/8192 [00:01<00:00, 6724.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])): 100%|██████████| 8192/8192 [00:01<00:00, 4560.37it/s]
[1;36m(EngineCore_DP6 pid=178307)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  96%|█████████▌| 7873/8192 [00:01<00:00, 6700.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])): 100%|██████████| 8192/8192 [00:01<00:00, 4564.51it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  72%|███████▏  | 5922/8192 [00:01<00:00, 4457.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  16%|█▌        | 1285/8192 [00:00<00:01, 6228.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])): 100%|██████████| 8192/8192 [00:01<00:00, 4567.70it/s]
[1;36m(EngineCore_DP5 pid=178306)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])): 100%|██████████| 8192/8192 [00:01<00:00, 4557.01it/s]
[1;36m(EngineCore_DP7 pid=178308)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  16%|█▌        | 1278/8192 [00:00<00:01, 6177.10it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])): 100%|██████████| 8192/8192 [00:01<00:00, 4545.62it/s]
[1;36m(EngineCore_DP3 pid=178304)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):   6%|▋         | 513/8192 [00:00<00:01, 4377.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):   6%|▋         | 513/8192 [00:00<00:01, 4417.87it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  84%|████████▍ | 6913/8192 [00:01<00:00, 5768.60it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  26%|██▋       | 2162/8192 [00:00<00:00, 7346.24it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  26%|██▋       | 2160/8192 [00:00<00:00, 7337.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):   6%|▋         | 513/8192 [00:00<00:01, 4435.07it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):   6%|▋         | 513/8192 [00:00<00:01, 4432.35it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):   6%|▋         | 513/8192 [00:00<00:01, 4427.53it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  16%|█▌        | 1289/8192 [00:00<00:01, 6235.41it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  16%|█▌        | 1304/8192 [00:00<00:01, 6343.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])):  96%|█████████▌| 7873/8192 [00:01<00:00, 6690.70it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  35%|███▌      | 2908/8192 [00:00<00:00, 6943.59it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  16%|█▌        | 1301/8192 [00:00<00:01, 6338.46it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  16%|█▌        | 1277/8192 [00:00<00:01, 6203.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  35%|███▌      | 2906/8192 [00:00<00:00, 6946.60it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  16%|█▌        | 1286/8192 [00:00<00:01, 6250.22it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([4096, 7168])): 100%|██████████| 8192/8192 [00:01<00:00, 4520.41it/s]
[1;36m(EngineCore_DP2 pid=178303)[0;0m DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):   0%|          | 0/8192 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  26%|██▋       | 2162/8192 [00:00<00:00, 7329.79it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  26%|██▋       | 2166/8192 [00:00<00:00, 7342.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  26%|██▋       | 2166/8192 [00:00<00:00, 7353.01it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  26%|██▋       | 2160/8192 [00:00<00:00, 7359.38it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  44%|████▍     | 3612/8192 [00:00<00:00, 6262.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  26%|██▋       | 2163/8192 [00:00<00:00, 7356.18it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  44%|████▍     | 3611/8192 [00:00<00:00, 6266.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):   6%|▋         | 513/8192 [00:00<00:01, 4421.04it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  35%|███▌      | 2907/8192 [00:00<00:00, 6934.56it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  36%|███▌      | 2911/8192 [00:00<00:00, 6951.03it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  58%|█████▊    | 4748/8192 [00:00<00:00, 7813.62it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  36%|███▌      | 2912/8192 [00:00<00:00, 6956.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  35%|███▌      | 2907/8192 [00:00<00:00, 6951.69it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  36%|███▌      | 2909/8192 [00:00<00:00, 6953.11it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  58%|█████▊    | 4753/8192 [00:00<00:00, 7835.94it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  16%|█▌        | 1286/8192 [00:00<00:01, 6246.83it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  44%|████▍     | 3610/8192 [00:00<00:00, 6248.51it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  44%|████▍     | 3615/8192 [00:00<00:00, 6286.16it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  71%|███████   | 5781/8192 [00:00<00:00, 8576.08it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  71%|███████   | 5800/8192 [00:00<00:00, 8634.33it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  44%|████▍     | 3617/8192 [00:00<00:00, 6290.52it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  26%|██▋       | 2157/8192 [00:00<00:00, 7332.42it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  44%|████▍     | 3612/8192 [00:00<00:00, 6271.49it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  44%|████▍     | 3614/8192 [00:00<00:00, 6276.07it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  58%|█████▊    | 4750/8192 [00:00<00:00, 7813.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  58%|█████▊    | 4752/8192 [00:00<00:00, 7836.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  84%|████████▍ | 6913/8192 [00:00<00:00, 9301.29it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  84%|████████▍ | 6913/8192 [00:00<00:00, 9338.05it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  58%|█████▊    | 4750/8192 [00:00<00:00, 7827.99it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  58%|█████▊    | 4748/8192 [00:00<00:00, 7819.43it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  58%|█████▊    | 4749/8192 [00:00<00:00, 7822.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  35%|███▌      | 2901/8192 [00:00<00:00, 6926.25it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  71%|███████   | 5786/8192 [00:00<00:00, 8584.54it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  71%|███████   | 5824/8192 [00:00<00:00, 8710.32it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  97%|█████████▋| 7937/8192 [00:00<00:00, 9436.91it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  71%|███████   | 5797/8192 [00:00<00:00, 8629.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  97%|█████████▋| 7937/8192 [00:00<00:00, 9374.21it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  71%|███████   | 5790/8192 [00:00<00:00, 8607.35it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])): 100%|██████████| 8192/8192 [00:01<00:00, 8077.31it/s]
DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  71%|███████   | 5804/8192 [00:00<00:00, 8649.05it/s][1;36m(EngineCore_DP4 pid=178305)[0;0m DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):   0%|          | 0/2064 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])): 100%|██████████| 8192/8192 [00:01<00:00, 8060.79it/s]
DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  84%|████████▍ | 6913/8192 [00:00<00:00, 9279.79it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  84%|████████▍ | 6913/8192 [00:00<00:00, 9318.57it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  44%|████▍     | 3603/8192 [00:00<00:00, 6228.60it/s][1;36m(EngineCore_DP1 pid=178302)[0;0m DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):   0%|          | 0/2064 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  84%|████████▍ | 6913/8192 [00:00<00:00, 9315.59it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  84%|████████▍ | 6913/8192 [00:00<00:00, 9302.20it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  84%|████████▍ | 6913/8192 [00:00<00:00, 9309.78it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  25%|██▍       | 515/2064 [00:00<00:00, 4613.39it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  97%|█████████▋| 7937/8192 [00:00<00:00, 9471.00it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  97%|█████████▋| 7937/8192 [00:00<00:00, 9434.84it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  58%|█████▊    | 4740/8192 [00:00<00:00, 7790.40it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  25%|██▍       | 515/2064 [00:00<00:00, 4648.95it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])): 100%|██████████| 8192/8192 [00:01<00:00, 8117.42it/s]
DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])): 100%|██████████| 8192/8192 [00:01<00:00, 8075.47it/s]
DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  97%|█████████▋| 7937/8192 [00:00<00:00, 9448.71it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  97%|█████████▋| 7937/8192 [00:00<00:00, 9463.88it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  97%|█████████▋| 7937/8192 [00:00<00:00, 9385.41it/s][1;36m(EngineCore_DP0 pid=178301)[0;0m DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):   0%|          | 0/2064 [00:00<?, ?it/s][1;36m(EngineCore_DP6 pid=178307)[0;0m DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):   0%|          | 0/2064 [00:00<?, ?it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])): 100%|██████████| 8192/8192 [00:01<00:00, 8101.18it/s]
DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])): 100%|██████████| 8192/8192 [00:01<00:00, 8096.78it/s]
DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  70%|███████   | 5761/8192 [00:00<00:00, 8522.59it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])): 100%|██████████| 8192/8192 [00:01<00:00, 8075.32it/s]
[1;36m(EngineCore_DP5 pid=178306)[0;0m DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):   0%|          | 0/2064 [00:00<?, ?it/s][1;36m(EngineCore_DP7 pid=178308)[0;0m DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):   0%|          | 0/2064 [00:00<?, ?it/s][1;36m(EngineCore_DP3 pid=178304)[0;0m DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):   0%|          | 0/2064 [00:00<?, ?it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  25%|██▍       | 515/2064 [00:00<00:00, 4627.13it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  25%|██▍       | 515/2064 [00:00<00:00, 4685.06it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  84%|████████▍ | 6913/8192 [00:00<00:00, 9287.93it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  25%|██▍       | 515/2064 [00:00<00:00, 4586.23it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  25%|██▍       | 515/2064 [00:00<00:00, 4604.65it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  25%|██▍       | 515/2064 [00:00<00:00, 4459.75it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])):  97%|█████████▋| 7937/8192 [00:00<00:00, 9458.77it/s]DeepGemm(fp8_gemm_nt) warmup (W=torch.Size([7168, 2048])): 100%|██████████| 8192/8192 [00:01<00:00, 8081.57it/s]
[1;36m(EngineCore_DP2 pid=178303)[0;0m DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):   0%|          | 0/2064 [00:00<?, ?it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  25%|██▍       | 515/2064 [00:00<00:00, 4455.38it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  46%|████▌     | 949/2064 [00:10<00:00, 4627.13it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  46%|████▌     | 950/2064 [00:10<00:15, 73.55it/s]  DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  46%|████▌     | 948/2064 [00:10<00:00, 4604.65it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  46%|████▌     | 949/2064 [00:10<00:15, 73.70it/s]  DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  46%|████▋     | 955/2064 [00:10<00:15, 73.18it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  46%|████▌     | 954/2064 [00:10<00:15, 73.32it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  47%|████▋     | 966/2064 [00:11<00:00, 4613.39it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  47%|████▋     | 967/2064 [00:11<00:15, 72.38it/s]  DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  47%|████▋     | 970/2064 [00:11<00:00, 4648.95it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  47%|████▋     | 971/2064 [00:11<00:15, 72.46it/s]  DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  47%|████▋     | 972/2064 [00:11<00:15, 72.03it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  47%|████▋     | 976/2064 [00:11<00:15, 72.13it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  47%|████▋     | 970/2064 [00:11<00:00, 4685.06it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  47%|████▋     | 971/2064 [00:11<00:15, 72.72it/s]  DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  46%|████▋     | 955/2064 [00:11<00:00, 4459.75it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  46%|████▋     | 956/2064 [00:11<00:15, 71.85it/s]  DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  47%|████▋     | 967/2064 [00:11<00:00, 4586.23it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  47%|████▋     | 968/2064 [00:11<00:15, 72.67it/s]  DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  47%|████▋     | 976/2064 [00:11<00:15, 72.39it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  47%|████▋     | 961/2064 [00:11<00:15, 71.50it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  47%|████▋     | 973/2064 [00:11<00:15, 72.34it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  46%|████▌     | 953/2064 [00:11<00:00, 4455.38it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  46%|████▌     | 954/2064 [00:11<00:15, 71.83it/s]  DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  46%|████▋     | 959/2064 [00:11<00:15, 71.47it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  56%|█████▌    | 1149/2064 [00:14<00:14, 63.31it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  56%|█████▌    | 1147/2064 [00:14<00:14, 63.36it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  56%|█████▋    | 1165/2064 [00:15<00:14, 63.06it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  57%|█████▋    | 1171/2064 [00:15<00:14, 63.28it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  56%|█████▌    | 1148/2064 [00:15<00:14, 62.27it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  56%|█████▋    | 1165/2064 [00:15<00:14, 63.28it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  57%|█████▋    | 1172/2064 [00:15<00:14, 63.40it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  56%|█████▌    | 1146/2064 [00:15<00:14, 62.20it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  61%|██████    | 1257/2064 [00:16<00:13, 61.53it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  61%|██████    | 1254/2064 [00:16<00:13, 61.54it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  62%|██████▏   | 1273/2064 [00:17<00:12, 61.47it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  62%|██████▏   | 1279/2064 [00:17<00:12, 61.75it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  61%|██████    | 1252/2064 [00:17<00:13, 60.51it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  62%|██████▏   | 1272/2064 [00:17<00:12, 61.64it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  62%|██████▏   | 1281/2064 [00:17<00:12, 61.92it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  61%|██████    | 1250/2064 [00:17<00:13, 60.45it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  64%|██████▍   | 1325/2064 [00:17<00:12, 61.26it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  64%|██████▍   | 1321/2064 [00:17<00:12, 61.25it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  65%|██████▍   | 1340/2064 [00:18<00:11, 61.28it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  65%|██████▌   | 1347/2064 [00:18<00:11, 61.63it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  64%|██████▍   | 1317/2064 [00:18<00:12, 60.16it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  65%|██████▍   | 1339/2064 [00:18<00:11, 61.47it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  65%|██████▌   | 1350/2064 [00:18<00:11, 61.80it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  64%|██████▎   | 1315/2064 [00:18<00:12, 60.11it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  66%|██████▋   | 1371/2064 [00:18<00:11, 61.49it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  66%|██████▌   | 1366/2064 [00:18<00:11, 61.44it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  67%|██████▋   | 1385/2064 [00:18<00:11, 61.54it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  67%|██████▋   | 1393/2064 [00:19<00:10, 61.93it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  67%|██████▋   | 1384/2064 [00:18<00:11, 61.72it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  66%|██████▌   | 1361/2064 [00:18<00:11, 60.30it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  68%|██████▊   | 1396/2064 [00:19<00:10, 62.11it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  66%|██████▌   | 1359/2064 [00:18<00:11, 60.27it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  68%|██████▊   | 1403/2064 [00:19<00:10, 61.92it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  68%|██████▊   | 1398/2064 [00:19<00:10, 61.85it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  69%|██████▊   | 1417/2064 [00:19<00:10, 61.97it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  69%|██████▉   | 1426/2064 [00:19<00:10, 62.46it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  69%|██████▊   | 1416/2064 [00:19<00:10, 62.18it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  67%|██████▋   | 1392/2064 [00:19<00:11, 60.67it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  69%|██████▉   | 1429/2064 [00:19<00:10, 62.62it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  69%|██████▉   | 1427/2064 [00:19<00:10, 62.44it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  69%|██████▉   | 1422/2064 [00:19<00:10, 62.33it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  70%|██████▉   | 1441/2064 [00:19<00:09, 62.50it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  67%|██████▋   | 1390/2064 [00:19<00:11, 60.62it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  70%|███████   | 1450/2064 [00:19<00:09, 63.03it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  70%|███████   | 1446/2064 [00:19<00:09, 63.02it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  69%|██████▊   | 1415/2064 [00:19<00:10, 61.13it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  70%|██████▉   | 1440/2064 [00:19<00:09, 62.72it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  70%|██████▉   | 1441/2064 [00:19<00:09, 62.88it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  70%|███████   | 1453/2064 [00:19<00:09, 63.24it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  71%|███████   | 1460/2064 [00:20<00:09, 63.13it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  71%|███████   | 1469/2064 [00:20<00:09, 63.66it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  68%|██████▊   | 1413/2064 [00:19<00:10, 61.14it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  71%|███████   | 1461/2064 [00:20<00:09, 63.68it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  71%|███████   | 1456/2064 [00:19<00:09, 63.45it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  69%|██████▉   | 1433/2064 [00:19<00:10, 61.70it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  71%|███████   | 1459/2064 [00:20<00:09, 63.36it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  71%|███████▏  | 1475/2064 [00:20<00:09, 63.81it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  71%|███████▏  | 1472/2064 [00:20<00:09, 63.92it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  72%|███████▏  | 1484/2064 [00:20<00:09, 64.38it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  71%|███████▏  | 1474/2064 [00:20<00:09, 64.49it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  71%|███████   | 1469/2064 [00:20<00:09, 64.16it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  69%|██████▉   | 1431/2064 [00:19<00:10, 61.66it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  71%|███████▏  | 1474/2064 [00:20<00:09, 64.02it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  70%|███████   | 1448/2064 [00:20<00:09, 62.30it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  72%|███████▏  | 1488/2064 [00:20<00:08, 64.58it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  72%|███████▏  | 1487/2064 [00:20<00:08, 64.64it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  72%|███████▏  | 1485/2064 [00:20<00:08, 65.23it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  72%|███████▏  | 1480/2064 [00:20<00:08, 64.90it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1497/2064 [00:20<00:08, 65.20it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1499/2064 [00:20<00:08, 65.45it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  71%|███████   | 1460/2064 [00:20<00:09, 62.90it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  72%|███████▏  | 1487/2064 [00:20<00:08, 64.79it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  70%|███████   | 1446/2064 [00:20<00:09, 62.28it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  72%|███████▏  | 1495/2064 [00:20<00:08, 66.11it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  72%|███████▏  | 1490/2064 [00:20<00:08, 65.77it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1500/2064 [00:20<00:08, 65.48it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1508/2064 [00:20<00:08, 66.08it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1509/2064 [00:20<00:08, 66.38it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1504/2064 [00:20<00:08, 67.01it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1499/2064 [00:20<00:08, 66.73it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1498/2064 [00:20<00:08, 65.63it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  71%|███████▏  | 1471/2064 [00:20<00:09, 63.69it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▎  | 1518/2064 [00:20<00:08, 67.06it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  71%|███████   | 1458/2064 [00:20<00:09, 62.94it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1511/2064 [00:20<00:08, 66.30it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▎  | 1518/2064 [00:20<00:08, 67.24it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1513/2064 [00:20<00:08, 68.16it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1508/2064 [00:20<00:08, 67.74it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1508/2064 [00:20<00:08, 66.64it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  72%|███████▏  | 1481/2064 [00:20<00:09, 64.51it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▍  | 1528/2064 [00:20<00:07, 68.13it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▎  | 1521/2064 [00:20<00:08, 67.28it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  71%|███████   | 1469/2064 [00:20<00:09, 63.64it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▍  | 1527/2064 [00:21<00:07, 68.31it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▎  | 1522/2064 [00:20<00:07, 69.13it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1517/2064 [00:20<00:07, 68.85it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1517/2064 [00:20<00:08, 67.66it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  72%|███████▏  | 1490/2064 [00:20<00:08, 65.45it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▍  | 1537/2064 [00:21<00:07, 69.27it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▍  | 1531/2064 [00:20<00:07, 68.50it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▍  | 1536/2064 [00:21<00:07, 69.49it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▍  | 1530/2064 [00:20<00:07, 70.13it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  72%|███████▏  | 1479/2064 [00:20<00:09, 64.47it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▍  | 1525/2064 [00:20<00:07, 69.84it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▍  | 1526/2064 [00:20<00:07, 68.69it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1499/2064 [00:20<00:08, 66.45it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▍  | 1546/2064 [00:21<00:07, 70.32it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▍  | 1540/2064 [00:21<00:07, 69.73it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▍  | 1544/2064 [00:21<00:07, 70.86it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▍  | 1538/2064 [00:21<00:07, 71.26it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▍  | 1533/2064 [00:20<00:07, 71.02it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  72%|███████▏  | 1488/2064 [00:20<00:08, 65.16it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▍  | 1535/2064 [00:21<00:07, 69.94it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▌  | 1554/2064 [00:21<00:07, 71.68it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1507/2064 [00:21<00:08, 67.37it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▌  | 1552/2064 [00:21<00:07, 71.99it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▌  | 1549/2064 [00:21<00:07, 70.99it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▍  | 1546/2064 [00:21<00:07, 72.18it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▍  | 1541/2064 [00:21<00:07, 72.04it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1497/2064 [00:20<00:08, 66.14it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▍  | 1543/2064 [00:21<00:07, 70.92it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▌  | 1562/2064 [00:21<00:06, 72.74it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1515/2064 [00:21<00:08, 68.27it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▌  | 1560/2064 [00:21<00:06, 72.90it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▌  | 1554/2064 [00:21<00:06, 73.42it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▌  | 1558/2064 [00:21<00:06, 72.41it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▌  | 1549/2064 [00:21<00:07, 73.10it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1505/2064 [00:21<00:08, 67.19it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▌  | 1551/2064 [00:21<00:07, 72.03it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▌  | 1570/2064 [00:21<00:06, 74.14it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▍  | 1523/2064 [00:21<00:07, 69.10it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▌  | 1568/2064 [00:21<00:06, 73.94it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▌  | 1562/2064 [00:21<00:06, 74.53it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▌  | 1557/2064 [00:21<00:06, 74.08it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▌  | 1567/2064 [00:21<00:06, 73.45it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  73%|███████▎  | 1513/2064 [00:21<00:08, 68.21it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▌  | 1559/2064 [00:21<00:06, 73.12it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▋  | 1578/2064 [00:21<00:06, 75.00it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▍  | 1531/2064 [00:21<00:07, 70.28it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▋  | 1576/2064 [00:21<00:06, 74.96it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▌  | 1570/2064 [00:21<00:06, 75.52it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▋  | 1575/2064 [00:21<00:06, 74.47it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▌  | 1565/2064 [00:21<00:06, 74.78it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1586/2064 [00:21<00:06, 76.06it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▌  | 1567/2064 [00:21<00:06, 73.92it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▎  | 1521/2064 [00:21<00:07, 69.07it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▍  | 1539/2064 [00:21<00:07, 71.20it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1584/2064 [00:21<00:06, 76.01it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▋  | 1578/2064 [00:21<00:06, 76.58it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1583/2064 [00:21<00:06, 75.33it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▌  | 1573/2064 [00:21<00:06, 75.71it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1594/2064 [00:21<00:06, 76.97it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▋  | 1575/2064 [00:21<00:06, 74.73it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▍  | 1529/2064 [00:21<00:07, 70.18it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▍  | 1547/2064 [00:21<00:07, 72.17it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1592/2064 [00:21<00:06, 76.75it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1586/2064 [00:21<00:06, 76.88it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1591/2064 [00:21<00:06, 76.40it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1581/2064 [00:21<00:06, 76.56it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1583/2064 [00:21<00:06, 75.71it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1603/2064 [00:21<00:05, 78.04it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  74%|███████▍  | 1537/2064 [00:21<00:07, 71.23it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1600/2064 [00:21<00:05, 77.63it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▌  | 1555/2064 [00:21<00:06, 72.92it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1595/2064 [00:21<00:06, 77.81it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1599/2064 [00:21<00:06, 77.32it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1589/2064 [00:21<00:06, 77.28it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1591/2064 [00:21<00:06, 76.67it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1612/2064 [00:22<00:05, 78.94it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▍  | 1545/2064 [00:21<00:07, 72.06it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▌  | 1563/2064 [00:21<00:06, 73.87it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1609/2064 [00:22<00:05, 78.54it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1604/2064 [00:21<00:05, 79.00it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1597/2064 [00:21<00:05, 77.93it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1608/2064 [00:21<00:05, 78.49it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1599/2064 [00:21<00:06, 77.46it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▊  | 1621/2064 [00:22<00:05, 79.90it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  75%|███████▌  | 1553/2064 [00:21<00:06, 73.10it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▌  | 1571/2064 [00:21<00:06, 74.85it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1618/2064 [00:22<00:05, 79.40it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1613/2064 [00:22<00:05, 79.81it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1606/2064 [00:21<00:05, 78.81it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1617/2064 [00:22<00:05, 79.18it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1608/2064 [00:21<00:05, 78.47it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▉  | 1630/2064 [00:22<00:05, 80.80it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▌  | 1561/2064 [00:21<00:06, 73.73it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1579/2064 [00:22<00:06, 75.56it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▉  | 1627/2064 [00:22<00:05, 80.39it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▊  | 1622/2064 [00:22<00:05, 80.48it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1615/2064 [00:22<00:05, 79.52it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▉  | 1626/2064 [00:22<00:05, 80.19it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1617/2064 [00:22<00:05, 79.47it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▌  | 1569/2064 [00:21<00:06, 74.58it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▉  | 1639/2064 [00:22<00:05, 81.36it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1587/2064 [00:22<00:06, 76.07it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▉  | 1636/2064 [00:22<00:05, 81.24it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▉  | 1631/2064 [00:22<00:05, 81.06it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▊  | 1624/2064 [00:22<00:05, 80.34it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▉  | 1635/2064 [00:22<00:05, 81.14it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▉  | 1626/2064 [00:22<00:05, 80.43it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  76%|███████▋  | 1577/2064 [00:21<00:06, 75.16it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  80%|███████▉  | 1648/2064 [00:22<00:05, 81.90it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1595/2064 [00:22<00:06, 76.65it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  80%|███████▉  | 1645/2064 [00:22<00:05, 82.18it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▉  | 1640/2064 [00:22<00:05, 81.92it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▉  | 1633/2064 [00:22<00:05, 81.48it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  80%|███████▉  | 1644/2064 [00:22<00:05, 81.96it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▉  | 1635/2064 [00:22<00:05, 81.52it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1585/2064 [00:22<00:06, 76.08it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1603/2064 [00:22<00:05, 77.53it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  80%|████████  | 1657/2064 [00:22<00:04, 83.03it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  80%|████████  | 1654/2064 [00:22<00:04, 83.01it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  80%|███████▉  | 1649/2064 [00:22<00:05, 82.72it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  80%|███████▉  | 1642/2064 [00:22<00:05, 82.31it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  80%|████████  | 1653/2064 [00:22<00:04, 82.80it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  80%|███████▉  | 1644/2064 [00:22<00:05, 82.53it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  77%|███████▋  | 1593/2064 [00:22<00:06, 76.64it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████  | 1666/2064 [00:22<00:04, 84.05it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1612/2064 [00:22<00:05, 78.57it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████  | 1663/2064 [00:22<00:04, 83.47it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  80%|████████  | 1658/2064 [00:22<00:04, 83.40it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  80%|███████▉  | 1651/2064 [00:22<00:04, 83.19it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████  | 1662/2064 [00:22<00:04, 83.85it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1601/2064 [00:22<00:05, 77.28it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  80%|████████  | 1653/2064 [00:22<00:04, 83.09it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████  | 1675/2064 [00:22<00:04, 84.88it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▊  | 1621/2064 [00:22<00:05, 79.24it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████  | 1672/2064 [00:22<00:04, 84.25it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████  | 1667/2064 [00:22<00:04, 84.58it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  80%|████████  | 1660/2064 [00:22<00:04, 83.92it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████  | 1671/2064 [00:22<00:04, 84.70it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1609/2064 [00:22<00:05, 78.04it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████  | 1662/2064 [00:22<00:04, 84.01it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1684/2064 [00:22<00:04, 86.08it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▉  | 1630/2064 [00:22<00:05, 79.64it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████▏ | 1681/2064 [00:22<00:04, 85.18it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████  | 1676/2064 [00:22<00:04, 85.34it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████▏ | 1680/2064 [00:22<00:04, 85.80it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████  | 1669/2064 [00:22<00:04, 84.77it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  78%|███████▊  | 1618/2064 [00:22<00:05, 79.06it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████  | 1671/2064 [00:22<00:04, 84.89it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1693/2064 [00:22<00:04, 87.01it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1690/2064 [00:23<00:04, 86.27it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▉  | 1639/2064 [00:22<00:05, 80.29it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1685/2064 [00:22<00:04, 85.84it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1689/2064 [00:22<00:04, 86.99it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████▏ | 1678/2064 [00:22<00:04, 85.65it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████▏ | 1680/2064 [00:22<00:04, 85.63it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1702/2064 [00:23<00:04, 87.81it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▉  | 1627/2064 [00:22<00:05, 80.04it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1699/2064 [00:23<00:04, 87.04it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  80%|███████▉  | 1648/2064 [00:22<00:05, 81.48it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1694/2064 [00:22<00:04, 86.88it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1698/2064 [00:22<00:04, 87.78it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1687/2064 [00:22<00:04, 86.53it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1689/2064 [00:22<00:04, 86.71it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  83%|████████▎ | 1712/2064 [00:23<00:03, 88.87it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  79%|███████▉  | 1636/2064 [00:22<00:05, 80.98it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  83%|████████▎ | 1709/2064 [00:23<00:04, 88.46it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  80%|████████  | 1657/2064 [00:22<00:04, 82.35it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  83%|████████▎ | 1704/2064 [00:23<00:04, 88.04it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  83%|████████▎ | 1708/2064 [00:23<00:03, 89.09it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1697/2064 [00:22<00:04, 87.67it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1698/2064 [00:23<00:04, 87.34it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  83%|████████▎ | 1722/2064 [00:23<00:03, 89.98it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  80%|███████▉  | 1645/2064 [00:22<00:05, 81.51it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████  | 1666/2064 [00:23<00:04, 83.29it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  83%|████████▎ | 1719/2064 [00:23<00:03, 89.20it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  83%|████████▎ | 1714/2064 [00:23<00:03, 89.38it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  83%|████████▎ | 1706/2064 [00:23<00:04, 88.33it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  83%|████████▎ | 1718/2064 [00:23<00:03, 89.80it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  83%|████████▎ | 1708/2064 [00:23<00:04, 88.68it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  84%|████████▍ | 1732/2064 [00:23<00:03, 91.14it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  80%|████████  | 1654/2064 [00:22<00:04, 82.11it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████  | 1675/2064 [00:23<00:04, 84.14it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  84%|████████▍ | 1729/2064 [00:23<00:03, 90.32it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  84%|████████▎ | 1724/2064 [00:23<00:03, 90.15it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  84%|████████▎ | 1728/2064 [00:23<00:03, 90.93it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  83%|████████▎ | 1716/2064 [00:23<00:03, 89.14it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  83%|████████▎ | 1718/2064 [00:23<00:03, 89.87it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████  | 1663/2064 [00:23<00:04, 83.36it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1684/2064 [00:23<00:04, 84.79it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  84%|████████▍ | 1739/2064 [00:23<00:03, 91.62it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  84%|████████▍ | 1734/2064 [00:23<00:03, 91.40it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  84%|████████▍ | 1738/2064 [00:23<00:03, 91.55it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  84%|████████▎ | 1726/2064 [00:23<00:03, 90.30it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  84%|████████▎ | 1728/2064 [00:23<00:03, 91.10it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████  | 1672/2064 [00:23<00:04, 84.09it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1693/2064 [00:23<00:04, 85.85it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  84%|████████▍ | 1736/2064 [00:23<00:03, 91.35it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  84%|████████▍ | 1738/2064 [00:23<00:03, 92.34it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  81%|████████▏ | 1681/2064 [00:23<00:04, 85.19it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1702/2064 [00:23<00:04, 86.84it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1690/2064 [00:23<00:04, 86.22it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  83%|████████▎ | 1711/2064 [00:23<00:04, 87.66it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  82%|████████▏ | 1699/2064 [00:23<00:04, 87.12it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  83%|████████▎ | 1721/2064 [00:23<00:03, 88.74it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  83%|████████▎ | 1708/2064 [00:23<00:04, 87.89it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  84%|████████▍ | 1731/2064 [00:23<00:03, 89.68it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  83%|████████▎ | 1718/2064 [00:23<00:03, 88.97it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  84%|████████▎ | 1728/2064 [00:23<00:03, 89.76it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  84%|████████▍ | 1738/2064 [00:23<00:03, 90.95it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  84%|████████▍ | 1742/2064 [00:27<00:39,  8.24it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  85%|████████▍ | 1749/2064 [00:27<00:37,  8.43it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  85%|████████▍ | 1748/2064 [00:27<00:37,  8.44it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  84%|████████▍ | 1744/2064 [00:27<00:38,  8.37it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  85%|████████▍ | 1746/2064 [00:27<00:37,  8.39it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  85%|████████▍ | 1748/2064 [00:27<00:37,  8.45it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  92%|█████████▏| 1908/2064 [00:27<00:02, 58.63it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  92%|█████████▏| 1908/2064 [00:27<00:02, 57.30it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  92%|█████████▏| 1908/2064 [00:27<00:02, 57.71it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  97%|█████████▋| 1992/2064 [00:27<00:00, 91.79it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  92%|█████████▏| 1908/2064 [00:27<00:02, 58.63it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  97%|█████████▋| 1992/2064 [00:27<00:00, 90.98it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  97%|█████████▋| 1992/2064 [00:27<00:00, 91.41it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  92%|█████████▏| 1908/2064 [00:27<00:02, 58.22it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  97%|█████████▋| 1992/2064 [00:27<00:00, 92.11it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  99%|█████████▉| 2046/2064 [00:27<00:00, 116.42it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  92%|█████████▏| 1908/2064 [00:27<00:02, 57.82it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  84%|████████▍ | 1740/2064 [00:27<00:41,  7.82it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  99%|█████████▉| 2046/2064 [00:27<00:00, 116.07it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  99%|█████████▉| 2046/2064 [00:27<00:00, 116.38it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  97%|█████████▋| 1992/2064 [00:27<00:00, 91.85it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  97%|█████████▋| 1992/2064 [00:27<00:00, 91.59it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  99%|█████████▉| 2046/2064 [00:27<00:00, 116.98it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])): 100%|██████████| 2064/2064 [00:27<00:00, 73.95it/s] 
[1;36m(EngineCore_DP1 pid=178302)[0;0m DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):   0%|          | 0/2064 [00:00<?, ?it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  85%|████████▍ | 1748/2064 [00:27<00:37,  8.41it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])): 100%|██████████| 2064/2064 [00:28<00:00, 73.69it/s] 
DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  99%|█████████▉| 2046/2064 [00:27<00:00, 117.00it/s][1;36m(EngineCore_DP4 pid=178305)[0;0m DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):   0%|          | 0/2064 [00:00<?, ?it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])): 100%|██████████| 2064/2064 [00:27<00:00, 74.14it/s] 
DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  99%|█████████▉| 2046/2064 [00:27<00:00, 116.80it/s][1;36m(EngineCore_DP6 pid=178307)[0;0m DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):   0%|          | 0/2064 [00:00<?, ?it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])): 100%|██████████| 2064/2064 [00:27<00:00, 74.09it/s] 
DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  25%|██▌       | 520/2064 [00:00<00:00, 4715.10it/s][1;36m(EngineCore_DP0 pid=178301)[0;0m DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):   0%|          | 0/2064 [00:00<?, ?it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  25%|██▌       | 520/2064 [00:00<00:00, 4743.37it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])): 100%|██████████| 2064/2064 [00:27<00:00, 74.09it/s] 
DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  25%|██▌       | 520/2064 [00:00<00:00, 4707.22it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])): 100%|██████████| 2064/2064 [00:27<00:00, 73.98it/s] 
[1;36m(EngineCore_DP7 pid=178308)[0;0m DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):   0%|          | 0/2064 [00:00<?, ?it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  25%|██▌       | 520/2064 [00:00<00:00, 4748.61it/s][1;36m(EngineCore_DP5 pid=178306)[0;0m DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):   0%|          | 0/2064 [00:00<?, ?it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  25%|██▌       | 520/2064 [00:00<00:00, 4754.14it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  25%|██▌       | 520/2064 [00:00<00:00, 4718.88it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  92%|█████████▏| 1908/2064 [00:28<00:02, 58.46it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  97%|█████████▋| 1993/2064 [00:28<00:00, 91.81it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  92%|█████████▏| 1908/2064 [00:27<00:02, 58.02it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  99%|█████████▉| 2040/2064 [00:28<00:00, 113.19it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  97%|█████████▋| 1995/2064 [00:28<00:00, 93.24it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])): 100%|██████████| 2064/2064 [00:28<00:00, 72.81it/s] 
[1;36m(EngineCore_DP3 pid=178304)[0;0m DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):   0%|          | 0/2064 [00:00<?, ?it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])):  99%|█████████▉| 2046/2064 [00:28<00:00, 116.66it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  25%|██▌       | 519/2064 [00:00<00:00, 5182.44it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 4096, 7168])): 100%|██████████| 2064/2064 [00:28<00:00, 72.97it/s] 
[1;36m(EngineCore_DP2 pid=178303)[0;0m DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):   0%|          | 0/2064 [00:00<?, ?it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  25%|██▌       | 519/2064 [00:00<00:00, 5151.16it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  48%|████▊     | 992/2064 [00:05<00:06, 164.05it/s] DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  48%|████▊     | 991/2064 [00:05<00:06, 163.89it/s] DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  48%|████▊     | 995/2064 [00:05<00:06, 163.24it/s] DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  48%|████▊     | 995/2064 [00:05<00:06, 163.52it/s] DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  48%|████▊     | 992/2064 [00:05<00:06, 163.90it/s] DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  48%|████▊     | 996/2064 [00:05<00:06, 163.64it/s] DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  50%|█████     | 1038/2064 [00:05<00:06, 156.86it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  50%|█████     | 1035/2064 [00:05<00:06, 155.99it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  58%|█████▊    | 1192/2064 [00:06<00:05, 149.08it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  58%|█████▊    | 1191/2064 [00:06<00:05, 149.00it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  58%|█████▊    | 1196/2064 [00:06<00:05, 148.50it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  58%|█████▊    | 1197/2064 [00:06<00:05, 148.79it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  58%|█████▊    | 1192/2064 [00:06<00:05, 148.98it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  58%|█████▊    | 1198/2064 [00:06<00:05, 148.93it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  63%|██████▎   | 1306/2064 [00:07<00:05, 146.07it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  63%|██████▎   | 1305/2064 [00:07<00:05, 145.97it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  64%|██████▎   | 1311/2064 [00:07<00:05, 145.55it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  64%|██████▎   | 1312/2064 [00:07<00:05, 145.98it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  63%|██████▎   | 1306/2064 [00:07<00:05, 145.90it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  64%|██████▎   | 1313/2064 [00:07<00:05, 146.09it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  61%|██████    | 1257/2064 [00:07<00:05, 145.44it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  67%|██████▋   | 1381/2064 [00:08<00:04, 145.86it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  67%|██████▋   | 1380/2064 [00:08<00:04, 145.85it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  67%|██████▋   | 1386/2064 [00:08<00:04, 145.43it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  67%|██████▋   | 1387/2064 [00:08<00:04, 145.92it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  61%|██████    | 1253/2064 [00:07<00:05, 144.43it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  67%|██████▋   | 1381/2064 [00:08<00:04, 145.69it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  67%|██████▋   | 1388/2064 [00:08<00:04, 146.17it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  69%|██████▉   | 1434/2064 [00:08<00:04, 146.67it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  69%|██████▉   | 1433/2064 [00:08<00:04, 146.61it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  70%|██████▉   | 1439/2064 [00:08<00:04, 146.33it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  70%|██████▉   | 1440/2064 [00:08<00:04, 146.90it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  69%|██████▉   | 1434/2064 [00:08<00:04, 146.62it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  71%|███████▏  | 1474/2064 [00:08<00:03, 148.07it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  70%|██████▉   | 1442/2064 [00:08<00:04, 147.14it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  71%|███████▏  | 1473/2064 [00:08<00:03, 148.05it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  72%|███████▏  | 1480/2064 [00:08<00:03, 147.80it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  72%|███████▏  | 1481/2064 [00:08<00:03, 148.53it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  73%|███████▎  | 1507/2064 [00:08<00:03, 150.09it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  71%|███████▏  | 1474/2064 [00:08<00:03, 148.02it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  67%|██████▋   | 1382/2064 [00:08<00:04, 144.23it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  72%|███████▏  | 1483/2064 [00:08<00:03, 148.69it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  73%|███████▎  | 1506/2064 [00:08<00:03, 149.97it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  73%|███████▎  | 1513/2064 [00:09<00:03, 149.84it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  73%|███████▎  | 1514/2064 [00:09<00:03, 150.65it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  74%|███████▍  | 1535/2064 [00:09<00:03, 152.61it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  73%|███████▎  | 1507/2064 [00:09<00:03, 150.07it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  74%|███████▍  | 1534/2064 [00:09<00:03, 152.54it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  73%|███████▎  | 1516/2064 [00:09<00:03, 150.78it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  67%|██████▋   | 1377/2064 [00:08<00:04, 143.23it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  75%|███████▍  | 1541/2064 [00:09<00:03, 152.31it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  76%|███████▌  | 1560/2064 [00:09<00:03, 155.52it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  75%|███████▍  | 1542/2064 [00:09<00:03, 153.18it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  76%|███████▌  | 1559/2064 [00:09<00:03, 155.48it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  74%|███████▍  | 1535/2064 [00:09<00:03, 152.50it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  77%|███████▋  | 1583/2064 [00:09<00:03, 159.20it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  75%|███████▍  | 1544/2064 [00:09<00:03, 153.24it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  76%|███████▌  | 1566/2064 [00:09<00:03, 155.27it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  76%|███████▌  | 1567/2064 [00:09<00:03, 156.21it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  77%|███████▋  | 1582/2064 [00:09<00:03, 159.00it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  76%|███████▌  | 1560/2064 [00:09<00:03, 155.35it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  78%|███████▊  | 1604/2064 [00:09<00:02, 163.04it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  76%|███████▌  | 1569/2064 [00:09<00:03, 156.45it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  77%|███████▋  | 1589/2064 [00:09<00:02, 158.76it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  77%|███████▋  | 1590/2064 [00:09<00:02, 159.85it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  71%|███████   | 1463/2064 [00:08<00:04, 145.35it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  78%|███████▊  | 1603/2064 [00:09<00:02, 162.98it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  79%|███████▊  | 1625/2064 [00:09<00:02, 167.76it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  77%|███████▋  | 1583/2064 [00:09<00:03, 159.00it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  78%|███████▊  | 1610/2064 [00:09<00:02, 162.62it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  77%|███████▋  | 1592/2064 [00:09<00:02, 159.89it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  78%|███████▊  | 1612/2064 [00:09<00:02, 163.99it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  79%|███████▊  | 1624/2064 [00:09<00:02, 167.42it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  80%|███████▉  | 1645/2064 [00:09<00:02, 172.64it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  78%|███████▊  | 1604/2064 [00:09<00:02, 162.88it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  79%|███████▉  | 1631/2064 [00:09<00:02, 167.34it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  79%|███████▉  | 1633/2064 [00:09<00:02, 168.53it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  78%|███████▊  | 1614/2064 [00:09<00:02, 163.97it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  71%|███████   | 1458/2064 [00:08<00:04, 144.26it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  80%|███████▉  | 1644/2064 [00:09<00:02, 172.34it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  81%|████████  | 1665/2064 [00:09<00:02, 178.06it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  79%|███████▊  | 1625/2064 [00:09<00:02, 167.49it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  80%|███████▉  | 1651/2064 [00:09<00:02, 172.39it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  80%|████████  | 1653/2064 [00:09<00:02, 173.51it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  79%|███████▉  | 1635/2064 [00:09<00:02, 168.70it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  81%|████████  | 1664/2064 [00:09<00:02, 177.70it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  74%|███████▎  | 1521/2064 [00:09<00:03, 147.49it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  82%|████████▏ | 1686/2064 [00:09<00:02, 184.18it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  80%|███████▉  | 1645/2064 [00:09<00:02, 172.44it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  81%|████████  | 1672/2064 [00:09<00:02, 178.29it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  81%|████████  | 1674/2064 [00:09<00:02, 179.55it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  80%|████████  | 1655/2064 [00:09<00:02, 173.97it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  82%|████████▏ | 1685/2064 [00:09<00:02, 183.94it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  83%|████████▎ | 1707/2064 [00:10<00:01, 190.27it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  81%|████████  | 1666/2064 [00:09<00:02, 178.48it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  82%|████████▏ | 1693/2064 [00:10<00:02, 184.37it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  82%|████████▏ | 1695/2064 [00:10<00:01, 185.77it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  81%|████████  | 1676/2064 [00:09<00:02, 180.05it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  83%|████████▎ | 1706/2064 [00:10<00:01, 190.22it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  84%|████████▍ | 1729/2064 [00:10<00:01, 197.16it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  73%|███████▎  | 1515/2064 [00:09<00:03, 146.29it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  82%|████████▏ | 1687/2064 [00:09<00:02, 184.47it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  76%|███████▌  | 1565/2064 [00:09<00:03, 150.01it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  83%|████████▎ | 1715/2064 [00:10<00:01, 191.24it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  83%|████████▎ | 1717/2064 [00:10<00:01, 192.69it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  82%|████████▏ | 1697/2064 [00:10<00:01, 186.41it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  84%|████████▎ | 1728/2064 [00:10<00:01, 197.31it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  85%|████████▍ | 1752/2064 [00:10<00:01, 203.88it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  83%|████████▎ | 1708/2064 [00:10<00:01, 190.28it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  84%|████████▍ | 1737/2064 [00:10<00:01, 197.54it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  84%|████████▍ | 1739/2064 [00:10<00:01, 199.37it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  83%|████████▎ | 1719/2064 [00:10<00:01, 193.44it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  85%|████████▍ | 1751/2064 [00:10<00:01, 204.24it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  86%|████████▌ | 1775/2064 [00:10<00:01, 210.50it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  78%|███████▊  | 1600/2064 [00:09<00:03, 153.02it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  84%|████████▍ | 1730/2064 [00:10<00:01, 196.84it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  85%|████████▌ | 1760/2064 [00:10<00:01, 204.19it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  75%|███████▌  | 1558/2064 [00:09<00:03, 148.69it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  85%|████████▌ | 1762/2064 [00:10<00:01, 205.92it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  84%|████████▍ | 1741/2064 [00:10<00:01, 199.80it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  86%|████████▌ | 1774/2064 [00:10<00:01, 210.84it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  87%|████████▋ | 1799/2064 [00:10<00:01, 217.85it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  85%|████████▍ | 1753/2064 [00:10<00:01, 203.85it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  86%|████████▋ | 1784/2064 [00:10<00:01, 211.61it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  87%|████████▋ | 1786/2064 [00:10<00:01, 212.85it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  85%|████████▌ | 1764/2064 [00:10<00:01, 206.94it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  87%|████████▋ | 1798/2064 [00:10<00:01, 217.78it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  79%|███████▉  | 1630/2064 [00:09<00:02, 156.64it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  88%|████████▊ | 1824/2064 [00:10<00:01, 225.79it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  86%|████████▌ | 1776/2064 [00:10<00:01, 210.83it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  88%|████████▊ | 1808/2064 [00:10<00:01, 218.75it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  77%|███████▋  | 1593/2064 [00:09<00:03, 151.59it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  88%|████████▊ | 1811/2064 [00:10<00:01, 220.78it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  87%|████████▋ | 1788/2064 [00:10<00:01, 214.49it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  88%|████████▊ | 1823/2064 [00:10<00:01, 225.60it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  90%|████████▉ | 1850/2064 [00:10<00:00, 234.34it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  80%|████████  | 1657/2064 [00:10<00:02, 161.01it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  87%|████████▋ | 1800/2064 [00:10<00:01, 218.36it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  89%|████████▉ | 1833/2064 [00:10<00:01, 226.67it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  89%|████████▉ | 1836/2064 [00:10<00:00, 228.91it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  88%|████████▊ | 1813/2064 [00:10<00:01, 222.06it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  90%|████████▉ | 1849/2064 [00:10<00:00, 233.78it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  79%|███████▊  | 1623/2064 [00:09<00:02, 155.13it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  88%|████████▊ | 1825/2064 [00:10<00:01, 226.52it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  81%|████████▏ | 1682/2064 [00:10<00:02, 166.18it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  89%|████████▉ | 1839/2064 [00:10<00:00, 230.66it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  90%|████████▉ | 1851/2064 [00:10<00:00, 234.98it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  80%|███████▉  | 1649/2064 [00:10<00:02, 159.18it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  83%|████████▎ | 1705/2064 [00:10<00:02, 171.92it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  81%|████████  | 1673/2064 [00:10<00:02, 163.97it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  84%|████████▎ | 1728/2064 [00:10<00:01, 178.55it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  85%|████████▍ | 1750/2064 [00:10<00:01, 185.69it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  82%|████████▏ | 1696/2064 [00:10<00:02, 169.43it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  86%|████████▌ | 1773/2064 [00:10<00:01, 193.61it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  83%|████████▎ | 1718/2064 [00:10<00:01, 175.49it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  87%|████████▋ | 1797/2064 [00:10<00:01, 202.40it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  84%|████████▍ | 1740/2064 [00:10<00:01, 182.26it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  88%|████████▊ | 1821/2064 [00:10<00:01, 211.43it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  85%|████████▌ | 1762/2064 [00:10<00:01, 189.70it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  89%|████████▉ | 1846/2064 [00:10<00:00, 221.29it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  86%|████████▋ | 1785/2064 [00:10<00:01, 197.75it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  88%|████████▊ | 1809/2064 [00:10<00:01, 206.83it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  89%|████████▉ | 1834/2064 [00:10<00:01, 216.37it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  91%|█████████ | 1874/2064 [00:11<00:03, 55.12it/s] DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  91%|█████████ | 1873/2064 [00:11<00:03, 54.87it/s] DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  90%|█████████ | 1860/2064 [00:11<00:03, 52.71it/s] DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  98%|█████████▊| 2023/2064 [00:12<00:00, 179.42it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  90%|████████▉ | 1857/2064 [00:11<00:04, 51.57it/s] DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  97%|█████████▋| 2002/2064 [00:12<00:00, 163.71it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  90%|█████████ | 1863/2064 [00:11<00:03, 53.70it/s] DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  98%|█████████▊| 2019/2064 [00:12<00:00, 184.05it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  91%|█████████ | 1875/2064 [00:11<00:03, 55.27it/s] DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  98%|█████████▊| 2023/2064 [00:12<00:00, 184.44it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])): 100%|█████████▉| 2054/2064 [00:12<00:00, 203.40it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])): 100%|██████████| 2064/2064 [00:12<00:00, 168.98it/s]
[1;36m(EngineCore_DP1 pid=178302)[0;0m WARNING 11-04 09:35:51 [cudagraph_dispatcher.py:106] cudagraph dispatching keys are not initialized. No cudagraph will be used.
DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  98%|█████████▊| 2023/2064 [00:12<00:00, 184.55it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  98%|█████████▊| 2023/2064 [00:12<00:00, 179.18it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])): 100%|██████████| 2064/2064 [00:12<00:00, 168.87it/s]
[1;36m(EngineCore_DP6 pid=178307)[0;0m WARNING 11-04 09:35:51 [cudagraph_dispatcher.py:106] cudagraph dispatching keys are not initialized. No cudagraph will be used.
DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])): 100%|██████████| 2064/2064 [00:12<00:00, 168.98it/s]
[1;36m(EngineCore_DP0 pid=178301)[0;0m WARNING 11-04 09:35:51 [cudagraph_dispatcher.py:106] cudagraph dispatching keys are not initialized. No cudagraph will be used.
DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])): 100%|██████████| 2064/2064 [00:12<00:00, 168.26it/s]
[1;36m(EngineCore_DP4 pid=178305)[0;0m WARNING 11-04 09:35:51 [cudagraph_dispatcher.py:106] cudagraph dispatching keys are not initialized. No cudagraph will be used.
DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])): 100%|██████████| 2064/2064 [00:12<00:00, 169.21it/s]
[1;36m(EngineCore_DP7 pid=178308)[0;0m WARNING 11-04 09:35:51 [cudagraph_dispatcher.py:106] cudagraph dispatching keys are not initialized. No cudagraph will be used.
DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])): 100%|██████████| 2064/2064 [00:12<00:00, 168.94it/s]
[1;36m(EngineCore_DP5 pid=178306)[0;0m WARNING 11-04 09:35:51 [cudagraph_dispatcher.py:106] cudagraph dispatching keys are not initialized. No cudagraph will be used.
DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  91%|█████████ | 1870/2064 [00:12<00:03, 54.82it/s] DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  97%|█████████▋| 2002/2064 [00:12<00:00, 161.86it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])): 100%|█████████▉| 2054/2064 [00:12<00:00, 199.98it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  90%|████████▉ | 1857/2064 [00:12<00:04, 51.45it/s] DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])): 100%|██████████| 2064/2064 [00:12<00:00, 165.85it/s]
[1;36m(EngineCore_DP3 pid=178304)[0;0m WARNING 11-04 09:35:52 [cudagraph_dispatcher.py:106] cudagraph dispatching keys are not initialized. No cudagraph will be used.
DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])):  97%|█████████▋| 2002/2064 [00:12<00:00, 165.46it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])): 100%|█████████▉| 2057/2064 [00:12<00:00, 201.65it/s]DeepGemm(m_grouped_fp8_gemm_nt_contiguous) warmup (W=torch.Size([16, 7168, 2048])): 100%|██████████| 2064/2064 [00:12<00:00, 164.59it/s]
[1;36m(EngineCore_DP2 pid=178303)[0;0m WARNING 11-04 09:35:52 [cudagraph_dispatcher.py:106] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:35:54 [core.py:210] init engine (profile, create kv cache, warmup model) took 103.56 seconds
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:35:54 [core.py:210] init engine (profile, create kv cache, warmup model) took 103.56 seconds
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:35:54 [core.py:210] init engine (profile, create kv cache, warmup model) took 103.53 seconds
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:35:54 [core.py:210] init engine (profile, create kv cache, warmup model) took 103.57 seconds
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:35:54 [core.py:210] init engine (profile, create kv cache, warmup model) took 103.57 seconds
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:35:54 [core.py:210] init engine (profile, create kv cache, warmup model) took 103.36 seconds
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:35:54 [core.py:210] init engine (profile, create kv cache, warmup model) took 103.55 seconds
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:35:54 [core.py:210] init engine (profile, create kv cache, warmup model) took 103.54 seconds
INFO 11-04 09:35:55 [coordinator.py:187] All engine subscriptions received by DP coordinator
[1;36m(EngineCore_DP7 pid=178308)[0;0m INFO 11-04 09:35:55 [__init__.py:381] Cudagraph is disabled under eager mode
[1;36m(EngineCore_DP2 pid=178303)[0;0m INFO 11-04 09:35:55 [__init__.py:381] Cudagraph is disabled under eager mode
[1;36m(EngineCore_DP0 pid=178301)[0;0m INFO 11-04 09:35:55 [__init__.py:381] Cudagraph is disabled under eager mode
[1;36m(EngineCore_DP1 pid=178302)[0;0m INFO 11-04 09:35:55 [__init__.py:381] Cudagraph is disabled under eager mode
[1;36m(EngineCore_DP3 pid=178304)[0;0m INFO 11-04 09:35:55 [__init__.py:381] Cudagraph is disabled under eager mode
[1;36m(EngineCore_DP6 pid=178307)[0;0m INFO 11-04 09:35:55 [__init__.py:381] Cudagraph is disabled under eager mode
[1;36m(EngineCore_DP4 pid=178305)[0;0m INFO 11-04 09:35:55 [__init__.py:381] Cudagraph is disabled under eager mode
[1;36m(EngineCore_DP5 pid=178306)[0;0m INFO 11-04 09:35:55 [__init__.py:381] Cudagraph is disabled under eager mode
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [loggers.py:147] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 12408
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [loggers.py:147] Engine 001: vllm cache_config_info with initialization after num_gpu_blocks is: 12408
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [loggers.py:147] Engine 002: vllm cache_config_info with initialization after num_gpu_blocks is: 12408
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [loggers.py:147] Engine 003: vllm cache_config_info with initialization after num_gpu_blocks is: 12408
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [loggers.py:147] Engine 004: vllm cache_config_info with initialization after num_gpu_blocks is: 12408
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [loggers.py:147] Engine 005: vllm cache_config_info with initialization after num_gpu_blocks is: 12408
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [loggers.py:147] Engine 006: vllm cache_config_info with initialization after num_gpu_blocks is: 12408
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [loggers.py:147] Engine 007: vllm cache_config_info with initialization after num_gpu_blocks is: 12408
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [loggers.py:147] Engine 008: vllm cache_config_info with initialization after num_gpu_blocks is: 12408
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [loggers.py:147] Engine 009: vllm cache_config_info with initialization after num_gpu_blocks is: 12408
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [loggers.py:147] Engine 010: vllm cache_config_info with initialization after num_gpu_blocks is: 12408
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [loggers.py:147] Engine 011: vllm cache_config_info with initialization after num_gpu_blocks is: 12408
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [loggers.py:147] Engine 012: vllm cache_config_info with initialization after num_gpu_blocks is: 12408
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [loggers.py:147] Engine 013: vllm cache_config_info with initialization after num_gpu_blocks is: 12408
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [loggers.py:147] Engine 014: vllm cache_config_info with initialization after num_gpu_blocks is: 12408
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [loggers.py:147] Engine 015: vllm cache_config_info with initialization after num_gpu_blocks is: 12408
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [api_server.py:1634] Supported_tasks: ['generate']
[1;36m(APIServer pid=178162)[0;0m WARNING 11-04 09:35:55 [model.py:1389] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [serving_responses.py:137] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.95}
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [serving_chat.py:139] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.95}
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [serving_completion.py:76] Using default completion sampling params from model: {'temperature': 0.6, 'top_p': 0.95}
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [api_server.py:1912] Starting vLLM API server 0 on http://0.0.0.0:8000
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:34] Available routes are:
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /openapi.json, Methods: GET, HEAD
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /docs, Methods: GET, HEAD
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /docs/oauth2-redirect, Methods: GET, HEAD
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /redoc, Methods: GET, HEAD
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /health, Methods: GET
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /load, Methods: GET
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /ping, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /ping, Methods: GET
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /tokenize, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /detokenize, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /v1/models, Methods: GET
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /version, Methods: GET
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /v1/responses, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /v1/responses/{response_id}, Methods: GET
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /v1/responses/{response_id}/cancel, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /v1/chat/completions, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /v1/completions, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /v1/embeddings, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /pooling, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /classify, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /score, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /v1/score, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /v1/audio/transcriptions, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /v1/audio/translations, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /rerank, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /v1/rerank, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /v2/rerank, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /scale_elastic_ep, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /is_scaling_elastic_ep, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /invocations, Methods: POST
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 09:35:55 [launcher.py:42] Route: /metrics, Methods: GET
[1;36m(APIServer pid=178162)[0;0m INFO:     Started server process [178162]
[1;36m(APIServer pid=178162)[0;0m INFO:     Waiting for application startup.
[1;36m(APIServer pid=178162)[0;0m INFO:     Application startup complete.
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60658 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60658 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:56694 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:56694 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:56694 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:45056 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:41 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:41 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:41 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:41 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:41 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:41 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:56694 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:41 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:41 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:41 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:41 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:43 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:43 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:43 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:43 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:43 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:56694 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:43 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:43 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:43 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:43 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:43 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:56694 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:45 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:45 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:45 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:45 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:45 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:45 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:45 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:45 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:56694 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:45 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:45 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:45060 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:45064 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:47 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:47 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:47 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:47 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:47 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:47 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:47 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:47 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:47 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:47 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:56694 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:45060 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:49 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:49 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:49 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:49 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:49 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:49 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:49 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:49 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:49 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:49 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:56694 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:51 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:51 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:51 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:51 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:51 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:51 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:51 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:51 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:51 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:51 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:53 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:53 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:53 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:53 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:53 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:53 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:53 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:53 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:53 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:60646 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:53 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:55 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:55 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:55 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:55 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:55 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:55 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:55 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:55 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:55 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:55 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:57 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:57 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:57 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:57 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:57 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:57 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:57 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:57 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:57 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:57 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:59 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:59 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:59 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:59 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:59 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:59 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:59 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:59 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:59 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:08:59 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:01 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:01 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:01 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:01 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:01 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:01 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:01 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:01 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:01 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:01 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:03 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:03 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:03 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:03 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:03 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:03 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:03 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:03 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:03 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:03 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:05 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:05 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:05 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:05 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:05 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:05 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:05 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:05 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:05 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:05 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:07 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:07 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:07 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:07 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:07 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:07 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:07 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:07 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:07 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:07 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:09 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:09 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:09 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:09 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:09 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:09 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:09 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:09 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:09 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:09 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:11 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:11 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:11 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:11 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:11 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:11 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:11 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:11 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:11 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:11 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:13 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:13 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:13 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:13 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:13 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:13 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:48060 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:13 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:48066 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:13 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:13 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:13 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:48060 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:48066 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:48060 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:48066 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:48060 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:48066 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:48060 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:48066 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:48060 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:48060 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:34 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:34 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:34 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:36 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:36 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:36 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:38 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:38 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:38 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:40 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:40 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:40 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:40 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:41 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:41 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:41 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:41 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:42 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:42 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:42 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:42 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:42 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:42 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:43 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:43 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:43 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:43 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:44 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:44 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:44 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:44 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:44 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:44 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:45 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:45 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:46 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:46 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:46 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:46 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:46 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:46 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:46 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:46 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:47 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:47 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:48 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:48 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:48 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:48 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:48 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:48 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:48 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:48 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:49 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:49 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:50 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:50 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:50 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:50 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:50 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:50 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:50 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:50 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:51 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:51 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:52 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:52 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:52 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:52 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:52 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:52 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:52 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:52 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:53 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:53 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:54 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:54 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:54 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:54 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:54 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:54 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:54 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:54 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:55 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:55 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:56 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:56 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:56 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:56 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:56 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:56 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:56 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:56 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:57 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:57 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:58 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:58 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:58 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:58 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:58 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:58 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:58 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:58 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:09:59 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:00 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:00 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:00 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:00 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:00 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:00 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:00 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:00 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:00 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:02 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:02 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:02 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:02 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:02 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:02 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:02 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:02 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:02 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:02 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:04 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:04 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:04 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:04 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:04 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:04 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:04 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:04 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:34072 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:04 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:04 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:06 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:06 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:06 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:06 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:06 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:06 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:06 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:06 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:34072 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:06 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:06 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:08 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:08 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:08 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:08 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:08 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:08 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:08 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:08 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:34072 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:08 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:34072 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:08 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:54668 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:10 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:10 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:10 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:10 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:10 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:10 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:10 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:10 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:34072 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:12 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:12 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:12 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:12 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:12 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:12 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:12 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:12 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:14 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:14 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:14 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:14 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:14 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:14 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:14 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:10:14 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42004 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42014 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42024 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:11:27 [chat_utils.py:560] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:11:37 [loggers.py:127] Engine 000: Avg prompt throughput: 1.7 tokens/s, Avg generation throughput: 1.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.1%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42398 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:11:47 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.5 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:11:57 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:12:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:12:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:12:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:12:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:12:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:12:41 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:12:43 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:12:45 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:12:47 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:12:49 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:12:51 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:12:53 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:12:55 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:12:57 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:12:59 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:01 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:03 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:05 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:07 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:09 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:11 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:13 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:21 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:23 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:25 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:27 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:29 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:31 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:33 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:35 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:37 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:39 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:41 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:43 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:45 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:47 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:49 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:51 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:53 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:55 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:57 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:13:59 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:14:01 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:14:03 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:14:05 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:14:07 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:14:09 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:14:11 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:14:13 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:14:15 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:14:17 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:14:19 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:42112 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:07 [serving_chat.py:178] Error with model error=ErrorInfo(message='The model `DeepSeek-V3.2-Exp` does not exist.', type='NotFoundError', param=None, code=404)
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:49624 - "POST /v1/chat/completions HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263] Error in preprocessing prompt inputs
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263] Traceback (most recent call last):
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263]   File "/home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/vllm/entrypoints/openai/serving_chat.py", line 239, in create_chat_completion
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263]     ) = await self._preprocess_chat(
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263]   File "/home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/vllm/entrypoints/openai/serving_engine.py", line 822, in _preprocess_chat
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263]     prompt_inputs = await self._tokenize_prompt_input_async(
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263]   File "/home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/vllm/entrypoints/openai/serving_engine.py", line 702, in _tokenize_prompt_input_async
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263]     async for result in self._tokenize_prompt_inputs_async(
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263]   File "/home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/vllm/entrypoints/openai/serving_engine.py", line 723, in _tokenize_prompt_inputs_async
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263]     yield await self._normalize_prompt_text_to_input(
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263]   File "/home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/vllm/entrypoints/openai/serving_engine.py", line 592, in _normalize_prompt_text_to_input
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263]     return self._validate_input(request, input_ids, input_text)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263]   File "/home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/vllm/entrypoints/openai/serving_engine.py", line 683, in _validate_input
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263]     raise ValueError(
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:30 [serving_chat.py:263] ValueError: 'max_tokens' or 'max_completion_tokens' is too large: 32000. This model's maximum context length is 5000 tokens and your request has 147 input tokens (32000 > 5000 - 147).
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 400 Bad Request
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263] Error in preprocessing prompt inputs
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263] Traceback (most recent call last):
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263]   File "/home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/vllm/entrypoints/openai/serving_chat.py", line 239, in create_chat_completion
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263]     ) = await self._preprocess_chat(
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263]         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263]   File "/home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/vllm/entrypoints/openai/serving_engine.py", line 822, in _preprocess_chat
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263]     prompt_inputs = await self._tokenize_prompt_input_async(
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263]                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263]   File "/home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/vllm/entrypoints/openai/serving_engine.py", line 702, in _tokenize_prompt_input_async
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263]     async for result in self._tokenize_prompt_inputs_async(
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263]   File "/home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/vllm/entrypoints/openai/serving_engine.py", line 723, in _tokenize_prompt_inputs_async
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263]     yield await self._normalize_prompt_text_to_input(
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263]           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263]   File "/home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/vllm/entrypoints/openai/serving_engine.py", line 592, in _normalize_prompt_text_to_input
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263]     return self._validate_input(request, input_ids, input_text)
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263]   File "/home/wanglinian/dsv32_debug/.venv/lib/python3.12/site-packages/vllm/entrypoints/openai/serving_engine.py", line 683, in _validate_input
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263]     raise ValueError(
[1;36m(APIServer pid=178162)[0;0m ERROR 11-04 10:16:56 [serving_chat.py:263] ValueError: 'max_tokens' or 'max_completion_tokens' is too large: 5000. This model's maximum context length is 5000 tokens and your request has 147 input tokens (5000 > 5000 - 147).
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:49132 - "POST /v1/chat/completions HTTP/1.1" 400 Bad Request
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:17:27 [loggers.py:127] Engine 000: Avg prompt throughput: 14.7 tokens/s, Avg generation throughput: 4.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.4%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:17:37 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:17:47 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:17:57 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:18:07 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:18:17 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:18:27 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:18:37 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:18:47 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.3%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:18:57 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.3%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:34492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:19:07 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2.6 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:19:17 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:29:57 [loggers.py:127] Engine 000: Avg prompt throughput: 14.7 tokens/s, Avg generation throughput: 2.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.4%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:30:07 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:30:17 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:30:27 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:30:37 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:30:47 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:30:57 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:31:07 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:31:17 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:31:27 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.3%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:31:37 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.4%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:31:47 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.5%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:31:57 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.5%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:32:07 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.7%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:32:17 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.8%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:32:27 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.9%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:59562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:32:37 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:32:47 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 41.2%
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:53738 - "GET /v1/models HTTP/1.1" 200 OK
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:40:37 [loggers.py:127] Engine 000: Avg prompt throughput: 14.7 tokens/s, Avg generation throughput: 3.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.4%, Prefix cache hit rate: 41.9%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:40:47 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 41.9%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:40:57 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 41.9%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:41:07 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 41.9%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:41:17 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 41.9%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:41:27 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 41.9%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:41:37 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 41.9%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:41:47 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 41.9%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:41:57 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.3%, Prefix cache hit rate: 41.9%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:42:07 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.3%, Prefix cache hit rate: 41.9%
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:53738 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:42:17 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 1.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 41.9%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:42:17 [loggers.py:127] Engine 001: Avg prompt throughput: 14.9 tokens/s, Avg generation throughput: 0.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.4%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:42:27 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 41.9%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:42:27 [loggers.py:127] Engine 001: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:42:37 [loggers.py:127] Engine 001: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:42:47 [loggers.py:127] Engine 001: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:42:57 [loggers.py:127] Engine 001: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:43:07 [loggers.py:127] Engine 001: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:43:17 [loggers.py:127] Engine 001: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:43:27 [loggers.py:127] Engine 001: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:43:37 [loggers.py:127] Engine 001: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:43:47 [loggers.py:127] Engine 001: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.3%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:43:57 [loggers.py:127] Engine 001: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.3%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:44:07 [loggers.py:127] Engine 001: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.4%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:44:17 [loggers.py:127] Engine 001: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.6%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:44:27 [loggers.py:127] Engine 001: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.7%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:44:37 [loggers.py:127] Engine 001: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.7%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:44:47 [loggers.py:127] Engine 001: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 4.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.8%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO:     127.0.0.1:53738 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:44:57 [loggers.py:127] Engine 000: Avg prompt throughput: 23.1 tokens/s, Avg generation throughput: 4.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 27.9%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:44:57 [loggers.py:127] Engine 001: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.1 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:45:07 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 27.9%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:45:07 [loggers.py:127] Engine 001: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=178162)[0;0m INFO 11-04 10:45:17 [loggers.py:127] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 27.9%
